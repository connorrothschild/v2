[{"authors":["admin"],"categories":null,"content":"I’m a senior at Rice University studying Social Policy Analysis \u0026amp; Political Science and minoring in data science. I’m interested in data visualization and public policy (and their intersection!), and my go-to tools for exploring those topics are D3.js and R.\nRight now, I\u0026rsquo;m working as a data science intern with the US Special Operations Command through a fellowship with Coding it Forward.\nPreviously, I\u0026rsquo;ve worked with the Texas Policy Lab as a data scientist, the Religion and Public Life Program as an undergraduate fellow, and the Baker Instute for Public Policy as a research assistant.\n","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1591045505,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/connor-rothschild/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/connor-rothschild/","section":"authors","summary":"I’m a senior at Rice University studying Social Policy Analysis \u0026amp; Political Science and minoring in data science. I’m interested in data visualization and public policy (and their intersection!), and my go-to tools for exploring those topics are D3.","tags":null,"title":"Connor Rothschild","type":"authors"},{"authors":null,"categories":null,"content":"","date":1589846400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"ff977f84c5572044bf2a4a8ddf3279e6","permalink":"/project/economist-table-replication/","publishdate":"2020-05-19T00:00:00Z","relpermalink":"/project/economist-table-replication/","section":"project","summary":"Use {reactable} to create publication-quality tables in R.","tags":["R","For Fun"],"title":"Recreating a Table by the Economist Using Reactable","type":"project"},{"authors":["Connor Rothschild"],"categories":["R"],"content":"       The Economist recently released a series of country-level datasets on ‘excess mortality’, a term used to describe ‘the gap between the total number of people who died from any cause, and the historical average for the same place and time of year.’ In simpler terms, the measure captures how many deaths are happening that shouldn’t be.\nIn the (free!) articles accompanying that data, I came across the following table:\n I thought the table was clean and sent a clear message. The addition of inline barcharts is not intrusive but still helps the reader takeaway insights about the data. It’s a rather pretty table. Having recently come across Greg Lin’s package reactable, I thought this could be a good opportunity to try my hand at recreating the above.\n(Coincidentally, while I was working on this project, Malcolm Barrett released a similar blog post documenting his recreation of a NYT table using gt. Check it out!)\nLoading packages Our process uses standard packages: reactable (obviously), htmltools as its buddy, lubridate for days and times, hrbrthemes for The Economist’s font, and tidyverse for general purpose data wrangling.\nlibrary(reactable) library(htmltools) library(lubridate) library(hrbrthemes) library(tidyverse)  Gather the data You can definitely skip this step if you’re not interested in the data collection and cleaning process.\nUnfortunately, one of the more time-consuming steps of this project was getting the data in the same format The Economist used in their article. The data they released comes in the form of a series of country-level CSVs; although helpful for country-level analysis, this meant that we have to modify the data into a joined format in order to create a table.\nLet’s begin by creating a function which reads in each individual CSV, selects relevant columns, and stores that specific dataframe in the global environment.\ncreate_dataframe \u0026lt;- function(country) { ## for URL (below) country \u0026lt;- str_replace(country, \u0026quot; \u0026quot;, \u0026quot;_\u0026quot;) ## read in CSV, given country parameter data \u0026lt;- readr::read_csv( paste0( \u0026#39;https://raw.githubusercontent.com/TheEconomist/covid-19-excess-deaths-tracker/master/output-data/excess-deaths/\u0026#39;, country, \u0026#39;_excess_deaths.csv\u0026#39; ) ) ## select relevant columns data \u0026lt;- data %\u0026gt;% select( country, region, start_date, end_date, population, total_deaths, covid_deaths, expected_deaths, excess_deaths, non_covid_deaths ) assign(country, rbind(data), envir = .GlobalEnv) } With that function created, we then want to loop it with each country The Economist has included.\nTo do so, we grab their list of sources from GitHub and pull each country into a list:\ncountry_names \u0026lt;- readr::read_csv( \u0026#39;https://raw.githubusercontent.com/TheEconomist/covid-19-excess-deaths-tracker/master/source-data/list_of_sources.csv\u0026#39; ) %\u0026gt;% select(country) %\u0026gt;% distinct() %\u0026gt;% mutate(country = stringr::str_to_lower(country)) %\u0026gt;% filter(country != \u0026#39;all\u0026#39;) %\u0026gt;% pull() Then, we loop!\nfor (country in country_names) { create_dataframe(country) } Now, we have a list of dataframes, with each containing one country’s data on excess mortality.\nFinally, we merge each of these new dataframes into one master dataset. Here, we are defining in dfs a list of all objects in the global environment that are of the structure data frame. Then, we rbind them all together!\ndfs = sapply(.GlobalEnv, is.data.frame) data \u0026lt;- do.call(rbind, mget(names(dfs)[dfs])) But unfortunately, that’s not all. We need to filter our data to only include the places that are in The Economist’s table. To make matters more difficult, the table’s identifying row is titled ‘Region/Country’, and includes data from two separate rows in the CSVs.\nLet’s begin by manually defining and filtering according to the countries and regions that The Economist includes. (This selection does not seem to have an order to it; as such, it has to be manual).\ngood_countries \u0026lt;- c(\u0026quot;Britain\u0026quot;, \u0026quot;Spain\u0026quot;, \u0026quot;Italy\u0026quot;, \u0026quot;France\u0026quot;, \u0026quot;Netherlands\u0026quot;, \u0026quot;Belgium\u0026quot;, \u0026quot;Sweden\u0026quot;, \u0026quot;Austria\u0026quot;) good_regions \u0026lt;- c(\u0026quot;New York City\u0026quot;, \u0026quot;Istanbul\u0026quot;, \u0026quot;Jakarta\u0026quot;) data_filtered_countries \u0026lt;- data %\u0026gt;% filter(country %in% good_countries) %\u0026gt;% filter(country == region) Because the table only has one row for country/region, and groups them accordingly, we can go ahead and replace the country variable in the data_filtered_regions dataframe with region.\ndata_filtered_regions \u0026lt;- data %\u0026gt;% filter(region %in% good_regions) %\u0026gt;% # replace for the sake of the table mutate(country = region) And merge:\ndata_filtered \u0026lt;- rbind(data_filtered_countries, data_filtered_regions) Next, we notice that the table title says ‘Excess mortality since region/country’s first 50 covid deaths.’ This means we need to exclude counts of excess deaths before a region had 50 COVID deaths.\ndata_filtered \u0026lt;- data_filtered %\u0026gt;% group_by(country) %\u0026gt;% mutate(csum = cumsum(covid_deaths)) At this point (after only selecting our relevant columns), our data looks like this:\ndata_filtered %\u0026gt;% select(country, start_date, end_date, covid_deaths, excess_deaths, covid_deaths, csum) %\u0026gt;% reactable()  {\"x\":{\"tag\":{\"name\":\"Reactable\",\"attribs\":{\"data\":{\"country\":[\"Britain\",\"Britain\",\"Britain\",\"Britain\",\"Britain\",\"Britain\",\"Britain\",\"Britain\",\"Britain\",\"Britain\",\"Britain\",\"Britain\",\"Britain\",\"Britain\",\"Britain\",\"Britain\",\"Britain\",\"Britain\",\"Spain\",\"Spain\",\"Spain\",\"Spain\",\"Spain\",\"Spain\",\"Spain\",\"Spain\",\"Spain\",\"Spain\",\"Spain\",\"Spain\",\"Spain\",\"Spain\",\"Spain\",\"Spain\",\"Spain\",\"Spain\",\"Sweden\",\"Sweden\",\"Sweden\",\"Sweden\",\"Sweden\",\"Sweden\",\"Sweden\",\"Sweden\",\"Sweden\",\"Sweden\",\"Sweden\",\"Sweden\",\"Sweden\",\"Sweden\",\"Sweden\",\"Sweden\",\"Sweden\",\"Netherlands\",\"Netherlands\",\"Netherlands\",\"Netherlands\",\"Netherlands\",\"Netherlands\",\"Netherlands\",\"Netherlands\",\"Netherlands\",\"Netherlands\",\"Netherlands\",\"Netherlands\",\"Netherlands\",\"Netherlands\",\"Netherlands\",\"Netherlands\",\"Netherlands\",\"Netherlands\",\"Italy\",\"Italy\",\"Italy\",\"Italy\",\"Italy\",\"Italy\",\"Italy\",\"Italy\",\"Italy\",\"Italy\",\"Italy\",\"Italy\",\"Italy\",\"France\",\"France\",\"France\",\"France\",\"France\",\"France\",\"France\",\"France\",\"France\",\"France\",\"France\",\"France\",\"France\",\"France\",\"France\",\"France\",\"France\",\"Belgium\",\"Belgium\",\"Belgium\",\"Belgium\",\"Belgium\",\"Belgium\",\"Belgium\",\"Belgium\",\"Belgium\",\"Austria\",\"Austria\",\"Austria\",\"Austria\",\"Austria\",\"Austria\",\"Austria\",\"Austria\",\"Austria\",\"Austria\",\"Jakarta\",\"Jakarta\",\"Jakarta\",\"Jakarta\",\"New York City\",\"New York City\",\"New York City\",\"New York City\",\"New York City\",\"New York City\",\"New York City\",\"New York City\",\"New York City\",\"New York City\",\"New York City\",\"New York City\",\"New York City\",\"New York City\",\"New York City\",\"New York City\",\"New York City\",\"Istanbul\",\"Istanbul\",\"Istanbul\",\"Istanbul\",\"Istanbul\",\"Istanbul\",\"Istanbul\",\"Istanbul\",\"Istanbul\",\"Istanbul\",\"Istanbul\",\"Istanbul\",\"Istanbul\",\"Istanbul\",\"Istanbul\",\"Istanbul\",\"Istanbul\",\"Istanbul\",\"Istanbul\"],\"start_date\":[\"2020-01-04\",\"2020-01-11\",\"2020-01-18\",\"2020-01-25\",\"2020-02-01\",\"2020-02-08\",\"2020-02-15\",\"2020-02-22\",\"2020-02-29\",\"2020-03-07\",\"2020-03-14\",\"2020-03-21\",\"2020-03-28\",\"2020-04-04\",\"2020-04-11\",\"2020-04-18\",\"2020-04-25\",\"2020-05-02\",\"2020-01-01\",\"2020-01-08\",\"2020-01-15\",\"2020-01-22\",\"2020-01-29\",\"2020-02-05\",\"2020-02-12\",\"2020-02-19\",\"2020-02-26\",\"2020-03-04\",\"2020-03-11\",\"2020-03-18\",\"2020-03-25\",\"2020-04-01\",\"2020-04-08\",\"2020-04-15\",\"2020-04-22\",\"2020-04-29\",\"2020-01-01\",\"2020-01-08\",\"2020-01-15\",\"2020-01-22\",\"2020-01-29\",\"2020-02-05\",\"2020-02-12\",\"2020-02-19\",\"2020-02-26\",\"2020-03-04\",\"2020-03-11\",\"2020-03-18\",\"2020-03-25\",\"2020-04-01\",\"2020-04-08\",\"2020-04-15\",\"2020-04-22\",\"2020-01-06\",\"2020-01-13\",\"2020-01-20\",\"2020-01-27\",\"2020-02-03\",\"2020-02-10\",\"2020-02-17\",\"2020-02-24\",\"2020-03-02\",\"2020-03-09\",\"2020-03-16\",\"2020-03-23\",\"2020-03-30\",\"2020-04-06\",\"2020-04-13\",\"2020-04-20\",\"2020-04-27\",\"2020-05-04\",\"2020-01-01\",\"2020-01-08\",\"2020-01-15\",\"2020-01-22\",\"2020-01-29\",\"2020-02-05\",\"2020-02-12\",\"2020-02-19\",\"2020-02-26\",\"2020-03-04\",\"2020-03-11\",\"2020-03-18\",\"2020-03-25\",\"2020-01-01\",\"2020-01-08\",\"2020-01-15\",\"2020-01-22\",\"2020-01-29\",\"2020-02-05\",\"2020-02-12\",\"2020-02-19\",\"2020-02-26\",\"2020-03-04\",\"2020-03-11\",\"2020-03-18\",\"2020-03-25\",\"2020-04-01\",\"2020-04-08\",\"2020-04-15\",\"2020-04-22\",\"2020-02-24\",\"2020-03-02\",\"2020-03-09\",\"2020-03-16\",\"2020-03-23\",\"2020-03-30\",\"2020-04-06\",\"2020-04-13\",\"2020-04-20\",\"2020-01-27\",\"2020-02-03\",\"2020-02-10\",\"2020-02-17\",\"2020-02-24\",\"2020-03-02\",\"2020-03-09\",\"2020-03-16\",\"2020-03-23\",\"2020-03-30\",\"2020-01-01\",\"2020-02-01\",\"2020-03-01\",\"2020-04-01\",\"2019-12-29\",\"2020-01-05\",\"2020-01-12\",\"2020-01-19\",\"2020-01-26\",\"2020-02-02\",\"2020-02-09\",\"2020-02-16\",\"2020-02-23\",\"2020-03-01\",\"2020-03-08\",\"2020-03-15\",\"2020-03-22\",\"2020-03-29\",\"2020-04-05\",\"2020-04-12\",\"2020-04-19\",\"2020-01-01\",\"2020-01-08\",\"2020-01-15\",\"2020-01-22\",\"2020-01-29\",\"2020-02-05\",\"2020-02-12\",\"2020-02-19\",\"2020-02-26\",\"2020-03-04\",\"2020-03-11\",\"2020-03-18\",\"2020-03-25\",\"2020-04-01\",\"2020-04-08\",\"2020-04-15\",\"2020-04-22\",\"2020-04-29\",\"2020-05-06\"],\"end_date\":[\"2020-01-10\",\"2020-01-17\",\"2020-01-24\",\"2020-01-31\",\"2020-02-07\",\"2020-02-14\",\"2020-02-21\",\"2020-02-28\",\"2020-03-06\",\"2020-03-13\",\"2020-03-20\",\"2020-03-27\",\"2020-04-03\",\"2020-04-10\",\"2020-04-17\",\"2020-04-24\",\"2020-05-01\",\"2020-05-08\",\"2020-01-07\",\"2020-01-14\",\"2020-01-21\",\"2020-01-28\",\"2020-02-04\",\"2020-02-11\",\"2020-02-18\",\"2020-02-25\",\"2020-03-03\",\"2020-03-10\",\"2020-03-17\",\"2020-03-24\",\"2020-03-31\",\"2020-04-07\",\"2020-04-14\",\"2020-04-21\",\"2020-04-28\",\"2020-05-05\",\"2020-01-07\",\"2020-01-14\",\"2020-01-21\",\"2020-01-28\",\"2020-02-04\",\"2020-02-11\",\"2020-02-18\",\"2020-02-25\",\"2020-03-03\",\"2020-03-10\",\"2020-03-17\",\"2020-03-24\",\"2020-03-31\",\"2020-04-07\",\"2020-04-14\",\"2020-04-21\",\"2020-04-28\",\"2020-01-12\",\"2020-01-19\",\"2020-01-26\",\"2020-02-02\",\"2020-02-09\",\"2020-02-16\",\"2020-02-23\",\"2020-03-01\",\"2020-03-08\",\"2020-03-15\",\"2020-03-22\",\"2020-03-29\",\"2020-04-05\",\"2020-04-12\",\"2020-04-19\",\"2020-04-26\",\"2020-05-03\",\"2020-05-10\",\"2020-01-07\",\"2020-01-14\",\"2020-01-21\",\"2020-01-28\",\"2020-02-04\",\"2020-02-11\",\"2020-02-18\",\"2020-02-25\",\"2020-03-03\",\"2020-03-10\",\"2020-03-17\",\"2020-03-24\",\"2020-03-31\",\"2020-01-07\",\"2020-01-14\",\"2020-01-21\",\"2020-01-28\",\"2020-02-04\",\"2020-02-11\",\"2020-02-18\",\"2020-02-25\",\"2020-03-03\",\"2020-03-10\",\"2020-03-17\",\"2020-03-24\",\"2020-03-31\",\"2020-04-07\",\"2020-04-14\",\"2020-04-21\",\"2020-04-28\",\"2020-03-01\",\"2020-03-08\",\"2020-03-15\",\"2020-03-22\",\"2020-03-29\",\"2020-04-05\",\"2020-04-12\",\"2020-04-19\",\"2020-04-26\",\"2020-02-02\",\"2020-02-09\",\"2020-02-16\",\"2020-02-23\",\"2020-03-01\",\"2020-03-08\",\"2020-03-15\",\"2020-03-22\",\"2020-03-29\",\"2020-04-05\",\"2020-01-31\",\"2020-02-29\",\"2020-03-31\",\"2020-04-30\",\"2020-01-04\",\"2020-01-11\",\"2020-01-18\",\"2020-01-25\",\"2020-02-01\",\"2020-02-08\",\"2020-02-15\",\"2020-02-22\",\"2020-02-29\",\"2020-03-07\",\"2020-03-14\",\"2020-03-21\",\"2020-03-28\",\"2020-04-04\",\"2020-04-11\",\"2020-04-18\",\"2020-04-25\",\"2020-01-07\",\"2020-01-14\",\"2020-01-21\",\"2020-01-28\",\"2020-02-04\",\"2020-02-11\",\"2020-02-18\",\"2020-02-25\",\"2020-03-03\",\"2020-03-10\",\"2020-03-17\",\"2020-03-24\",\"2020-03-31\",\"2020-04-07\",\"2020-04-14\",\"2020-04-21\",\"2020-04-28\",\"2020-05-05\",\"2020-05-12\"],\"covid_deaths\":[0,0,0,0,0,0,0,0,0,5,114,610,3812,6899,9509,9024,6684,4429,0,0,0,0,0,0,0,0,0,35,461,2211,5026,5486,4372,3691,2540,1797,0,0,0,0,0,0,0,0,0,0,8,73,251,532,668,629,550,0,0,0,0,0,0,0,0,3,17,159,592,995,971,947,791,581,384,0,0,0,0,0,0,0,10,69,552,1857,4238,5462,0,0,0,0,0,0,1,0,3,29,142,925,2423,6805,5401,5067,2864,0,0,0,18,180,745,1550,2125,1717,0,0,0,0,0,0,1,15,70,118,0,0,84,297,0,0,0,0,0,0,0,0,0,0,4,176,1198,3754,5218,4125,2720,0,0,0,0,0,0,0,0,0,0,0,22,85,255.5,339,428,366.5,264,187],\"excess_deaths\":[84,-325.6,-1090,-794.6,-942.200000000001,-923,-717.4,-345.799999999999,-724,-187.799999999999,-207,1112.8,7122.2,8979.2,12731.4,12358.2,8457.6,3840.6,-621.25,-41,177.5,282.25,286,-560.5,-728.5,-704,-601.5,-408.5,675,4198.75,8323.25,7937.5,5389,2947.75,1134,546,-109.6,-76,-165.2,-119.6,-114,-128.8,-106,-239,-212.8,-95.5999999999999,-102.4,79.8,258.2,615.6,819.6,675.6,484.2,9,-167.6,-247.8,-163.8,-117.4,-114.6,-385.4,-232.2,-236.4,-108,459.6,1380.4,2107.8,2047.6,1409,1085,612.4,294,-1525.8,-1509,-1294.6,-716.799999999999,-1119,-837,-758.799999999999,-499.4,-224.4,1738.8,5271,8758.8,8487,-563,-623,-766,-787.200000000001,-699,-1008.8,-961.4,-1343.6,-792.4,-308.200000000001,954.200000000001,2401.4,5644.2,7266.2,5523.2,3247.4,1061.8,-108,-122,-81,267,934,1789,2065,1489,853,132,-138,-48,-61,-34,0,8,252,123,207,585.5,-28.5,1375.5,1409.5,-182.2,-84,-22.2,-11,14.4000000000001,-40.2,-7.20000000000005,-49,-1,5,32,339.2,1694.6,4998,6573.6,4550.8,2572,-67.6666666666667,-23.6666666666667,16.3333333333333,26.3333333333333,-20.6666666666667,8.33333333333326,15.3333333333333,-84.3333333333333,-55.3333333333333,-57.3333333333333,88,283,444.333333333333,818.333333333333,782,629.333333333333,481.333333333333,374,287.333333333333],\"csum\":[0,0,0,0,0,0,0,0,0,5,119,729,4541,11440,20949,29973,36657,41086,0,0,0,0,0,0,0,0,0,35,496,2707,7733,13219,17591,21282,23822,25619,0,0,0,0,0,0,0,0,0,0,8,81,332,864,1532,2161,2711,0,0,0,0,0,0,0,0,3,20,179,771,1766,2737,3684,4475,5056,5440,0,0,0,0,0,0,0,10,79,631,2488,6726,12188,0,0,0,0,0,0,1,1,4,33,175,1100,3523,10328,15729,20796,23660,0,0,0,18,198,943,2493,4618,6335,0,0,0,0,0,0,1,16,86,204,0,0,84,381,0,0,0,0,0,0,0,0,0,0,4,180,1378,5132,10350,14475,17195,0,0,0,0,0,0,0,0,0,0,0,22,107,362.5,701.5,1129.5,1496,1760,1947]},\"columns\":[{\"accessor\":\"country\",\"name\":\"country\",\"type\":\"character\"},{\"accessor\":\"start_date\",\"name\":\"start_date\",\"type\":\"Date\"},{\"accessor\":\"end_date\",\"name\":\"end_date\",\"type\":\"Date\"},{\"accessor\":\"covid_deaths\",\"name\":\"covid_deaths\",\"type\":\"numeric\"},{\"accessor\":\"excess_deaths\",\"name\":\"excess_deaths\",\"type\":\"numeric\"},{\"accessor\":\"csum\",\"name\":\"csum\",\"type\":\"numeric\"}],\"defaultPageSize\":10,\"paginationType\":\"numbers\",\"showPageInfo\":true,\"minRows\":1,\"dataKey\":\"5845fe168655e5f6a72e9b9f636d6082\"},\"children\":[]},\"class\":\"reactR_markup\"},\"evals\":[],\"jsHooks\":[]} We need to group each country according to its total deaths related to COVID-19, and excess deaths. Then, using those two numbers, we calculate the percentage of excess deaths attributable to COVID-19. This can be used as a metric for underreporting of COVID-19 cases in a country.\ndata_for_table \u0026lt;- data_filtered %\u0026gt;% filter(excess_deaths \u0026gt; 0) %\u0026gt;% group_by(country) %\u0026gt;% summarise( excess_deaths = round(sum(excess_deaths)), covid_deaths = round(sum(covid_deaths)), perc = covid_deaths / excess_deaths ) %\u0026gt;% select(country, covid_deaths, excess_deaths, perc) reactable(data_for_table, pagination = FALSE)  {\"x\":{\"tag\":{\"name\":\"Reactable\",\"attribs\":{\"data\":{\"country\":[\"Austria\",\"Belgium\",\"Britain\",\"France\",\"Istanbul\",\"Italy\",\"Jakarta\",\"Netherlands\",\"New York City\",\"Spain\",\"Sweden\"],\"covid_deaths\":[204,6335,40967,23627,1947,12109,381,5420,17195,25584,2703],\"excess_deaths\":[722,7397,54686,26098,4254,24256,3370,9405,20780,31897,2933],\"perc\":[0.282548476454294,0.856428281735839,0.749131404747102,0.90531841520423,0.457686882933709,0.499216688654354,0.113056379821958,0.576289207868155,0.827478344562079,0.802081700473399,0.921581997954313]},\"columns\":[{\"accessor\":\"country\",\"name\":\"country\",\"type\":\"character\"},{\"accessor\":\"covid_deaths\",\"name\":\"covid_deaths\",\"type\":\"numeric\"},{\"accessor\":\"excess_deaths\",\"name\":\"excess_deaths\",\"type\":\"numeric\"},{\"accessor\":\"perc\",\"name\":\"perc\",\"type\":\"numeric\"}],\"defaultPageSize\":11,\"paginationType\":\"numbers\",\"showPageInfo\":true,\"minRows\":1,\"dataKey\":\"249cb3ef37824d809949c55e67461087\"},\"children\":[]},\"class\":\"reactR_markup\"},\"evals\":[],\"jsHooks\":[]} The only thing missing at this point is the date range. In order to find and display the dates, we need to find the first date after a given country/region hit 50 COVID-19 cases and the last date in the data for that country/region.\nHow do we do this? First, we’ll create a function called append_date_suffix which, according to a given day, appends the appropriate suffix.\nappend_date_suffix \u0026lt;- function(dates) { suff \u0026lt;- case_when( dates %in% c(11, 12, 13) ~ \u0026quot;th\u0026quot;, dates %% 10 == 1 ~ \u0026#39;st\u0026#39;, dates %% 10 == 2 ~ \u0026#39;nd\u0026#39;, dates %% 10 == 3 ~ \u0026#39;rd\u0026#39;, TRUE ~ \u0026quot;th\u0026quot; ) paste0(dates, suff) } We’ll then group by the country variable and find the min and max date (with the minimum only appearing after a country has seen 50 COVID deaths). Then, we do a lot of formatting of individual days and months, and append them all together with dashes in The Economist’s style. Sorry, there’s a lot going on here.\ndates_data \u0026lt;- data_filtered %\u0026gt;% # only looking at date ranges starting post-50 deaths filter(csum \u0026gt; 50) %\u0026gt;% group_by(country) %\u0026gt;% summarise(start_date = min(start_date), end_date = max(end_date)) %\u0026gt;% mutate( clean_start_day = format(start_date, \u0026quot;%d\u0026quot;), clean_start_day = append_date_suffix(as.numeric(clean_start_day)), clean_start_month = format(start_date, \u0026quot;%b\u0026quot;), clean_end_day = format(end_date, \u0026quot;%d\u0026quot;), clean_end_day = append_date_suffix(as.numeric(clean_end_day)), clean_end_month = format(end_date, \u0026quot;%b\u0026quot;) ) %\u0026gt;% mutate( clean_range = paste0( clean_start_month,\u0026quot; \u0026quot;, ## Mar clean_start_day, \u0026quot;-\u0026quot;, ## 6- clean_end_month, \u0026quot; \u0026quot;, ## May clean_end_day ## 18 ) ) %\u0026gt;% select(country, clean_range) This creates date ranges that look like this:\n {\"x\":{\"tag\":{\"name\":\"Reactable\",\"attribs\":{\"data\":{\"country\":[\"Austria\",\"Belgium\",\"Britain\",\"France\",\"Istanbul\",\"Italy\",\"Jakarta\",\"Netherlands\",\"New York City\",\"Spain\",\"Sweden\"],\"clean_range\":[\"Mar 23rd-Apr 5th\",\"Mar 23rd-Apr 26th\",\"Mar 14th-May 8th\",\"Mar 11th-Apr 28th\",\"Mar 25th-May 12th\",\"Feb 26th-Mar 31st\",\"Mar 1st-Apr 30th\",\"Mar 16th-May 10th\",\"Mar 15th-Apr 25th\",\"Mar 11th-May 5th\",\"Mar 18th-Apr 28th\"]},\"columns\":[{\"accessor\":\"country\",\"name\":\"country\",\"type\":\"character\"},{\"accessor\":\"clean_range\",\"name\":\"clean_range\",\"type\":\"character\"}],\"defaultPageSize\":11,\"paginationType\":\"numbers\",\"showPageInfo\":true,\"minRows\":1,\"dataKey\":\"944cb010b09fbd5dbf1363c55bf203a7\"},\"children\":[]},\"class\":\"reactR_markup\"},\"evals\":[],\"jsHooks\":[]} Join these dates with our existing data…\ndata_for_table \u0026lt;- data_filtered %\u0026gt;% filter(excess_deaths \u0026gt; 0) %\u0026gt;% group_by(country) %\u0026gt;% summarise( excess_deaths = round(sum(excess_deaths)), covid_deaths = round(sum(covid_deaths)), perc = covid_deaths / excess_deaths ) %\u0026gt;% left_join(dates_data, by = \u0026#39;country\u0026#39;) %\u0026gt;% select(country, clean_range, covid_deaths, excess_deaths, perc) and we get our finalized dataset:\n {\"x\":{\"tag\":{\"name\":\"Reactable\",\"attribs\":{\"data\":{\"country\":[\"Austria\",\"Belgium\",\"Britain\",\"France\",\"Istanbul\",\"Italy\",\"Jakarta\",\"Netherlands\",\"New York City\",\"Spain\",\"Sweden\"],\"clean_range\":[\"Mar 23rd-Apr 5th\",\"Mar 23rd-Apr 26th\",\"Mar 14th-May 8th\",\"Mar 11th-Apr 28th\",\"Mar 25th-May 12th\",\"Feb 26th-Mar 31st\",\"Mar 1st-Apr 30th\",\"Mar 16th-May 10th\",\"Mar 15th-Apr 25th\",\"Mar 11th-May 5th\",\"Mar 18th-Apr 28th\"],\"covid_deaths\":[204,6335,40967,23627,1947,12109,381,5420,17195,25584,2703],\"excess_deaths\":[722,7397,54686,26098,4254,24256,3370,9405,20780,31897,2933],\"perc\":[0.282548476454294,0.856428281735839,0.749131404747102,0.90531841520423,0.457686882933709,0.499216688654354,0.113056379821958,0.576289207868155,0.827478344562079,0.802081700473399,0.921581997954313]},\"columns\":[{\"accessor\":\"country\",\"name\":\"country\",\"type\":\"character\"},{\"accessor\":\"clean_range\",\"name\":\"clean_range\",\"type\":\"character\"},{\"accessor\":\"covid_deaths\",\"name\":\"covid_deaths\",\"type\":\"numeric\"},{\"accessor\":\"excess_deaths\",\"name\":\"excess_deaths\",\"type\":\"numeric\"},{\"accessor\":\"perc\",\"name\":\"perc\",\"type\":\"numeric\"}],\"defaultPageSize\":11,\"paginationType\":\"numbers\",\"showPageInfo\":true,\"minRows\":1,\"dataKey\":\"87a9a93568ca457a61d4bc6661464513\"},\"children\":[]},\"class\":\"reactR_markup\"},\"evals\":[],\"jsHooks\":[]}  Creating the table Finally, we’re ready to take that dataset and create our table. We can begin by defining some parameters that make the table easier to use and more aesthetically pleasing. Here, we sort according to excess deaths (but don’t include an arrow), make it compact, and show all results on one page.\nreactable( data_for_table, defaultSortOrder = \u0026#39;desc\u0026#39;, defaultSorted = \u0026#39;excess_deaths\u0026#39;, showSortIcon = FALSE, compact = TRUE, pagination = FALSE)  {\"x\":{\"tag\":{\"name\":\"Reactable\",\"attribs\":{\"data\":{\"country\":[\"Austria\",\"Belgium\",\"Britain\",\"France\",\"Istanbul\",\"Italy\",\"Jakarta\",\"Netherlands\",\"New York City\",\"Spain\",\"Sweden\"],\"clean_range\":[\"Mar 23rd-Apr 5th\",\"Mar 23rd-Apr 26th\",\"Mar 14th-May 8th\",\"Mar 11th-Apr 28th\",\"Mar 25th-May 12th\",\"Feb 26th-Mar 31st\",\"Mar 1st-Apr 30th\",\"Mar 16th-May 10th\",\"Mar 15th-Apr 25th\",\"Mar 11th-May 5th\",\"Mar 18th-Apr 28th\"],\"covid_deaths\":[204,6335,40967,23627,1947,12109,381,5420,17195,25584,2703],\"excess_deaths\":[722,7397,54686,26098,4254,24256,3370,9405,20780,31897,2933],\"perc\":[0.282548476454294,0.856428281735839,0.749131404747102,0.90531841520423,0.457686882933709,0.499216688654354,0.113056379821958,0.576289207868155,0.827478344562079,0.802081700473399,0.921581997954313]},\"columns\":[{\"accessor\":\"country\",\"name\":\"country\",\"type\":\"character\"},{\"accessor\":\"clean_range\",\"name\":\"clean_range\",\"type\":\"character\"},{\"accessor\":\"covid_deaths\",\"name\":\"covid_deaths\",\"type\":\"numeric\"},{\"accessor\":\"excess_deaths\",\"name\":\"excess_deaths\",\"type\":\"numeric\"},{\"accessor\":\"perc\",\"name\":\"perc\",\"type\":\"numeric\"}],\"defaultSortDesc\":true,\"defaultSorted\":[{\"id\":\"excess_deaths\",\"desc\":true}],\"defaultPageSize\":11,\"paginationType\":\"numbers\",\"showPageInfo\":true,\"minRows\":1,\"compact\":true,\"showSortIcon\":false,\"dataKey\":\"87a9a93568ca457a61d4bc6661464513\"},\"children\":[]},\"class\":\"reactR_markup\"},\"evals\":[],\"jsHooks\":[]} Style headers Next, let’s make the column headers stylistically similar to The Economist. We do so with reactable’s defaultColDef, where we define a colDef with styles for the header and regular cells. Here, we can include CSS (which you can find by inspecting the table at hand). Throughout this post, you’ll notice my constant references to font_es. This is from Bob Rudis’s hrbrthemes. It contains the font name for Economist Sans Condensed, which is the font that The Economist uses!\nreactable( data_for_table, defaultSortOrder = \u0026#39;desc\u0026#39;, defaultSorted = \u0026#39;excess_deaths\u0026#39;, showSortIcon = FALSE, compact = TRUE, pagination = FALSE, ######## NEW ######## defaultColDef = colDef( ### define header styling headerStyle = list( textAlign = \u0026quot;left\u0026quot;, fontSize = \u0026quot;11px\u0026quot;, lineHeight = \u0026quot;14px\u0026quot;, textTransform = \u0026quot;uppercase\u0026quot;, color = \u0026quot;#0c0c0c\u0026quot;, fontWeight = \u0026quot;500\u0026quot;, borderBottom = \u0026quot;2px solid #e9edf0\u0026quot;, paddingBottom = \u0026quot;3px\u0026quot;, verticalAlign = \u0026quot;bottom\u0026quot;, fontFamily = font_es ), ### define default column styling style = list( fontFamily = font_es, fontSize = \u0026quot;14px\u0026quot;, verticalAlign = \u0026quot;center\u0026quot;, align = \u0026quot;left\u0026quot; ) ) )  {\"x\":{\"tag\":{\"name\":\"Reactable\",\"attribs\":{\"data\":{\"country\":[\"Austria\",\"Belgium\",\"Britain\",\"France\",\"Istanbul\",\"Italy\",\"Jakarta\",\"Netherlands\",\"New York City\",\"Spain\",\"Sweden\"],\"clean_range\":[\"Mar 23rd-Apr 5th\",\"Mar 23rd-Apr 26th\",\"Mar 14th-May 8th\",\"Mar 11th-Apr 28th\",\"Mar 25th-May 12th\",\"Feb 26th-Mar 31st\",\"Mar 1st-Apr 30th\",\"Mar 16th-May 10th\",\"Mar 15th-Apr 25th\",\"Mar 11th-May 5th\",\"Mar 18th-Apr 28th\"],\"covid_deaths\":[204,6335,40967,23627,1947,12109,381,5420,17195,25584,2703],\"excess_deaths\":[722,7397,54686,26098,4254,24256,3370,9405,20780,31897,2933],\"perc\":[0.282548476454294,0.856428281735839,0.749131404747102,0.90531841520423,0.457686882933709,0.499216688654354,0.113056379821958,0.576289207868155,0.827478344562079,0.802081700473399,0.921581997954313]},\"columns\":[{\"accessor\":\"country\",\"name\":\"country\",\"type\":\"character\",\"style\":{\"fontFamily\":\"EconSansCndReg\",\"fontSize\":\"14px\",\"verticalAlign\":\"center\",\"align\":\"left\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"}},{\"accessor\":\"clean_range\",\"name\":\"clean_range\",\"type\":\"character\",\"style\":{\"fontFamily\":\"EconSansCndReg\",\"fontSize\":\"14px\",\"verticalAlign\":\"center\",\"align\":\"left\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"}},{\"accessor\":\"covid_deaths\",\"name\":\"covid_deaths\",\"type\":\"numeric\",\"style\":{\"fontFamily\":\"EconSansCndReg\",\"fontSize\":\"14px\",\"verticalAlign\":\"center\",\"align\":\"left\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"}},{\"accessor\":\"excess_deaths\",\"name\":\"excess_deaths\",\"type\":\"numeric\",\"style\":{\"fontFamily\":\"EconSansCndReg\",\"fontSize\":\"14px\",\"verticalAlign\":\"center\",\"align\":\"left\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"}},{\"accessor\":\"perc\",\"name\":\"perc\",\"type\":\"numeric\",\"style\":{\"fontFamily\":\"EconSansCndReg\",\"fontSize\":\"14px\",\"verticalAlign\":\"center\",\"align\":\"left\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"}}],\"defaultSortDesc\":true,\"defaultSorted\":[{\"id\":\"excess_deaths\",\"desc\":true}],\"defaultPageSize\":11,\"paginationType\":\"numbers\",\"showPageInfo\":true,\"minRows\":1,\"compact\":true,\"showSortIcon\":false,\"dataKey\":\"8ad8706dfbeacfc7871563a2bd901bf3\"},\"children\":[]},\"class\":\"reactR_markup\"},\"evals\":[],\"jsHooks\":[]}  Format columns Now, we can start to format the specific columns appropriately. The three easiest columns are Region/Country, Time Period, COVID-19 as % of Total. In each of these columns, we create a colDef which defines the column name, as well as some styling.\nYou’ll notice the addition of JS in our percent column. This allows us to include JavaScript in our columns and column headers. I use it to do something simple, like a line break. You can use JS for plenty of more complex purposes, some of which are documented here.\nreactable( data_for_table, defaultSortOrder = \u0026#39;desc\u0026#39;, defaultSorted = \u0026#39;excess_deaths\u0026#39;, showSortIcon = FALSE, compact = TRUE, pagination = FALSE, defaultColDef = colDef( headerStyle = list( textAlign = \u0026quot;left\u0026quot;, fontSize = \u0026quot;11px\u0026quot;, lineHeight = \u0026quot;14px\u0026quot;, textTransform = \u0026quot;uppercase\u0026quot;, color = \u0026quot;#0c0c0c\u0026quot;, fontWeight = \u0026quot;500\u0026quot;, borderBottom = \u0026quot;2px solid #e9edf0\u0026quot;, paddingBottom = \u0026quot;3px\u0026quot;, verticalAlign = \u0026quot;bottom\u0026quot;, fontFamily = font_es ), style = list( fontFamily = font_es, fontSize = \u0026quot;14px\u0026quot;, verticalAlign = \u0026quot;center\u0026quot;, align = \u0026quot;left\u0026quot; ) ), ####### NEW ####### columns = list( country = colDef( name = \u0026quot;Region / Country\u0026quot;, style = list(fontFamily = font_es, fontWeight = \u0026quot;400\u0026quot;) ), perc = colDef( html = TRUE, header = JS(\u0026quot; function(colInfo) { return \u0026#39;COVID-19 as\u0026lt;br\u0026gt;% of total\u0026#39; }\u0026quot;), name = \u0026quot;COVID-19 as % of Total\u0026quot;, align = \u0026quot;right\u0026quot;, maxWidth = 100, format = colFormat(percent = TRUE, digits = 0), style = list(fontFamily = font_es_bold), headerStyle = list( fontSize = \u0026quot;11px\u0026quot;, lineHeight = \u0026quot;14px\u0026quot;, textTransform = \u0026quot;uppercase\u0026quot;, color = \u0026quot;#0c0c0c\u0026quot;, fontWeight = \u0026quot;500\u0026quot;, borderBottom = \u0026quot;2px solid #e9edf0\u0026quot;, paddingBottom = \u0026quot;3px\u0026quot;, verticalAlign = \u0026quot;bottom\u0026quot;, fontFamily = font_es, textAlign = \u0026quot;right\u0026quot; ) ), clean_range = colDef( name = \u0026quot;Time Period\u0026quot;, style = list( color = \u0026#39;#3f5661\u0026#39;, fontSize = \u0026#39;12px\u0026#39;, fontFamily = font_es ) ) ) )  {\"x\":{\"tag\":{\"name\":\"Reactable\",\"attribs\":{\"data\":{\"country\":[\"Austria\",\"Belgium\",\"Britain\",\"France\",\"Istanbul\",\"Italy\",\"Jakarta\",\"Netherlands\",\"New York City\",\"Spain\",\"Sweden\"],\"clean_range\":[\"Mar 23rd-Apr 5th\",\"Mar 23rd-Apr 26th\",\"Mar 14th-May 8th\",\"Mar 11th-Apr 28th\",\"Mar 25th-May 12th\",\"Feb 26th-Mar 31st\",\"Mar 1st-Apr 30th\",\"Mar 16th-May 10th\",\"Mar 15th-Apr 25th\",\"Mar 11th-May 5th\",\"Mar 18th-Apr 28th\"],\"covid_deaths\":[204,6335,40967,23627,1947,12109,381,5420,17195,25584,2703],\"excess_deaths\":[722,7397,54686,26098,4254,24256,3370,9405,20780,31897,2933],\"perc\":[0.282548476454294,0.856428281735839,0.749131404747102,0.90531841520423,0.457686882933709,0.499216688654354,0.113056379821958,0.576289207868155,0.827478344562079,0.802081700473399,0.921581997954313]},\"columns\":[{\"accessor\":\"country\",\"name\":\"Region / Country\",\"type\":\"character\",\"style\":{\"fontFamily\":\"EconSansCndReg\",\"fontWeight\":\"400\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"}},{\"accessor\":\"clean_range\",\"name\":\"Time Period\",\"type\":\"character\",\"style\":{\"color\":\"#3f5661\",\"fontSize\":\"12px\",\"fontFamily\":\"EconSansCndReg\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"}},{\"accessor\":\"covid_deaths\",\"name\":\"covid_deaths\",\"type\":\"numeric\",\"style\":{\"fontFamily\":\"EconSansCndReg\",\"fontSize\":\"14px\",\"verticalAlign\":\"center\",\"align\":\"left\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"}},{\"accessor\":\"excess_deaths\",\"name\":\"excess_deaths\",\"type\":\"numeric\",\"style\":{\"fontFamily\":\"EconSansCndReg\",\"fontSize\":\"14px\",\"verticalAlign\":\"center\",\"align\":\"left\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"}},{\"accessor\":\"perc\",\"name\":\"COVID-19 as % of Total\",\"type\":\"numeric\",\"style\":{\"fontFamily\":\"EconSansCndBol\"},\"headerStyle\":{\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\",\"textAlign\":\"right\"},\"format\":{\"cell\":{\"digits\":0,\"percent\":true},\"aggregated\":{\"digits\":0,\"percent\":true}},\"header\":\"\\n function(colInfo) {\\n return 'COVID-19 as\n% of total'\\n }\",\"html\":true,\"maxWidth\":100,\"align\":\"right\"}],\"defaultSortDesc\":true,\"defaultSorted\":[{\"id\":\"excess_deaths\",\"desc\":true}],\"defaultPageSize\":11,\"paginationType\":\"numbers\",\"showPageInfo\":true,\"minRows\":1,\"compact\":true,\"showSortIcon\":false,\"dataKey\":\"a9245ac4442c2fd989f596473fa410d5\"},\"children\":[]},\"class\":\"reactR_markup\"},\"evals\":[\"tag.attribs.columns.4.header\"],\"jsHooks\":[]}  Add the barcharts We can now create the ‘deaths’ columns, which include barcharts.\nreactable makes the addition of barcharts to tables quite easy, thanks to its integration of JavaScript. Here, I pull from one example on reactable’s website, and use the following code:\nreactable( data_for_table, defaultSortOrder = \u0026#39;desc\u0026#39;, defaultSorted = \u0026#39;excess_deaths\u0026#39;, showSortIcon = FALSE, compact = TRUE, pagination = FALSE, defaultColDef = colDef( headerStyle = list( textAlign = \u0026quot;left\u0026quot;, fontSize = \u0026quot;11px\u0026quot;, lineHeight = \u0026quot;14px\u0026quot;, textTransform = \u0026quot;uppercase\u0026quot;, color = \u0026quot;#0c0c0c\u0026quot;, fontWeight = \u0026quot;500\u0026quot;, borderBottom = \u0026quot;2px solid #e9edf0\u0026quot;, paddingBottom = \u0026quot;3px\u0026quot;, verticalAlign = \u0026quot;bottom\u0026quot;, fontFamily = font_es ), style = list( fontFamily = font_es, fontSize = \u0026quot;14px\u0026quot;, verticalAlign = \u0026quot;center\u0026quot;, align = \u0026quot;left\u0026quot; ) ), columns = list( country = colDef( name = \u0026quot;Region / Country\u0026quot;, style = list(fontFamily = font_es, fontWeight = \u0026quot;400\u0026quot;) ), perc = colDef( html = TRUE, header = JS(\u0026quot; function(colInfo) { return \u0026#39;COVID-19 as\u0026lt;br\u0026gt;% of total\u0026#39; }\u0026quot;), name = \u0026quot;COVID-19 as % of Total\u0026quot;, align = \u0026quot;right\u0026quot;, maxWidth = 100, format = colFormat(percent = TRUE, digits = 0), style = list(fontFamily = font_es_bold), headerStyle = list( fontSize = \u0026quot;11px\u0026quot;, lineHeight = \u0026quot;14px\u0026quot;, textTransform = \u0026quot;uppercase\u0026quot;, color = \u0026quot;#0c0c0c\u0026quot;, fontWeight = \u0026quot;500\u0026quot;, borderBottom = \u0026quot;2px solid #e9edf0\u0026quot;, paddingBottom = \u0026quot;3px\u0026quot;, verticalAlign = \u0026quot;bottom\u0026quot;, fontFamily = font_es, textAlign = \u0026quot;right\u0026quot; ) ), clean_range = colDef( name = \u0026quot;Time Period\u0026quot;, style = list( color = \u0026#39;#3f5661\u0026#39;, fontSize = \u0026#39;12px\u0026#39;, fontFamily = font_es ) ), ###### NEW ###### covid_deaths = colDef( name = \u0026quot;COVID-19 Deaths\u0026quot;, cell = function(value) { width \u0026lt;- paste0(value * 100 / max(data_for_table$covid_deaths), \u0026quot;%\u0026quot;) value \u0026lt;- format(value, big.mark = \u0026quot;,\u0026quot;) value \u0026lt;- format(value, width = 10, justify = \u0026quot;right\u0026quot;) bar \u0026lt;- div( class = \u0026quot;bar-chart\u0026quot;, style = list(marginRight = \u0026quot;6px\u0026quot;), div( class = \u0026quot;bar\u0026quot;, style = list(width = width, backgroundColor = \u0026quot;#F15A3F\u0026quot;) ) ) div(class = \u0026quot;bar-cell\u0026quot;, span(class = \u0026quot;number\u0026quot;, value), bar) } ), excess_deaths = colDef( name = \u0026quot;Total Excess Deaths\u0026quot;, cell = function(value) { width \u0026lt;- paste0(value * 100 / max(data_for_table$excess_deaths), \u0026quot;%\u0026quot;) value \u0026lt;- format(value, big.mark = \u0026quot;,\u0026quot;) value \u0026lt;- format(value, width = 10, justify = \u0026quot;right\u0026quot;) bar \u0026lt;- div( class = \u0026quot;bar-chart\u0026quot;, style = list(marginRight = \u0026quot;6px\u0026quot;), div( class = \u0026quot;bar\u0026quot;, style = list(width = width, backgroundColor = \u0026quot;#3F5661\u0026quot;) ) ) div(class = \u0026quot;bar-cell\u0026quot;, span(class = \u0026quot;number\u0026quot;, value), bar) } ) ) ) Let’s break that down step-by-step, with a focus on covid_deaths.\nFirst, we need to define some CSS. reactable allows you to easily include CSS is RMarkdown documents, in chunks defined as css.\n.bar-cell { display: flex; align-items: center; } .number { font-size: 13.5px; white-space: pre; } .bar-chart { flex-grow: 1; margin-left: 6px; height: 22px; } .bar { height: 100%; } .bar-cell { display: flex; align-items: center; } .number { font-size: 13.5px; white-space: pre; } .bar-chart { flex-grow: 1; margin-left: 6px; height: 22px; } .bar { height: 100%; }  Now, let’s look at how we define covid_deaths:\n covid_deaths = colDef( ### define the name name = \u0026quot;COVID-19 Deaths\u0026quot;, ### create a \u0026#39;cell\u0026#39; function cell = function(value) { ### define the bar width according to the specified value width \u0026lt;- paste0(value * 100 / max(data_for_table$covid_deaths), \u0026quot;%\u0026quot;) ### add a comma to the label value \u0026lt;- format(value, big.mark = \u0026quot;,\u0026quot;) ### justify and provide padding with width value \u0026lt;- format(value, width = 10, justify = \u0026quot;right\u0026quot;) ### create the barchart div bar \u0026lt;- div( ### with a class of \u0026#39;bar-chart\u0026#39; class = \u0026quot;bar-chart\u0026quot;, ### give the bar a margin style = list(marginRight = \u0026quot;6px\u0026quot;), ### create the *actual* bar, with the red economist color div( class = \u0026quot;bar\u0026quot;, style = list(width = width, backgroundColor = \u0026quot;#F15A3F\u0026quot;) ) ) ### bring it all together, with the \u0026#39;value\u0026#39; (number) preceding the bar itself div(class = \u0026quot;bar-cell\u0026quot;, span(class = \u0026quot;number\u0026quot;, value), bar) } ) This creates a table that looks like this:\n {\"x\":{\"tag\":{\"name\":\"Reactable\",\"attribs\":{\"data\":{\"country\":[\"Austria\",\"Belgium\",\"Britain\",\"France\",\"Istanbul\",\"Italy\",\"Jakarta\",\"Netherlands\",\"New York City\",\"Spain\",\"Sweden\"],\"clean_range\":[\"Mar 23rd-Apr 5th\",\"Mar 23rd-Apr 26th\",\"Mar 14th-May 8th\",\"Mar 11th-Apr 28th\",\"Mar 25th-May 12th\",\"Feb 26th-Mar 31st\",\"Mar 1st-Apr 30th\",\"Mar 16th-May 10th\",\"Mar 15th-Apr 25th\",\"Mar 11th-May 5th\",\"Mar 18th-Apr 28th\"],\"covid_deaths\":[204,6335,40967,23627,1947,12109,381,5420,17195,25584,2703],\"excess_deaths\":[722,7397,54686,26098,4254,24256,3370,9405,20780,31897,2933],\"perc\":[0.282548476454294,0.856428281735839,0.749131404747102,0.90531841520423,0.457686882933709,0.499216688654354,0.113056379821958,0.576289207868155,0.827478344562079,0.802081700473399,0.921581997954313]},\"columns\":[{\"accessor\":\"country\",\"name\":\"Region / Country\",\"type\":\"character\",\"style\":{\"fontFamily\":\"EconSansCndReg\",\"fontWeight\":\"400\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"}},{\"accessor\":\"clean_range\",\"name\":\"Time Period\",\"type\":\"character\",\"style\":{\"color\":\"#3f5661\",\"fontSize\":\"12px\",\"fontFamily\":\"EconSansCndReg\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"}},{\"accessor\":\"covid_deaths\",\"name\":\"COVID-19 Deaths\",\"type\":\"numeric\",\"style\":{\"fontFamily\":\"EconSansCndReg\",\"fontSize\":\"14px\",\"verticalAlign\":\"center\",\"align\":\"left\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"},\"cell\":[{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 204\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"0.49796177411087%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 6,335\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"15.4636658774135%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 40,967\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"100%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 23,627\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"57.6732492005761%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 1,947\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"4.75260575585227%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 12,109\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"29.5579368760222%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 381\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"0.930016842824713%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 5,420\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"13.230160861181%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 17,195\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"41.972807381551%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 25,584\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"62.4502648473161%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 2,703\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"6.59799350696902%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]}]},{\"accessor\":\"excess_deaths\",\"name\":\"Total Excess Deaths\",\"type\":\"numeric\",\"style\":{\"fontFamily\":\"EconSansCndReg\",\"fontSize\":\"14px\",\"verticalAlign\":\"center\",\"align\":\"left\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"},\"cell\":[{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 722\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"1.32026478440552%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 7,397\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"13.5263138646089%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 54,686\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"100%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 26,098\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"47.7233661266138%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 4,254\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"7.77895622279925%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 24,256\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"44.3550451669532%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 3,370\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"6.16245474161577%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 9,405\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"17.1981860073876%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 20,780\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"37.9987565373222%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 31,897\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"58.327542698314%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 2,933\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"5.36334710894927%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]}]},{\"accessor\":\"perc\",\"name\":\"COVID-19 as % of Total\",\"type\":\"numeric\",\"style\":{\"fontFamily\":\"EconSansCndBol\"},\"headerStyle\":{\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\",\"textAlign\":\"right\"},\"format\":{\"cell\":{\"digits\":0,\"percent\":true},\"aggregated\":{\"digits\":0,\"percent\":true}},\"header\":\"\\n function(colInfo) {\\n return 'COVID-19 as\n% of total'\\n }\",\"html\":true,\"maxWidth\":100,\"align\":\"right\"}],\"defaultSortDesc\":true,\"defaultSorted\":[{\"id\":\"excess_deaths\",\"desc\":true}],\"defaultPageSize\":11,\"paginationType\":\"numbers\",\"showPageInfo\":true,\"minRows\":1,\"compact\":true,\"showSortIcon\":false,\"dataKey\":\"7fed8502c33f575f68606f21c78d769a\"},\"children\":[]},\"class\":\"reactR_markup\"},\"evals\":[\"tag.attribs.columns.4.header\"],\"jsHooks\":[]}  Add a title Finally, we can add the table title and subtitle. We do so by storing the above table in our environment. (This is the final table code!)\ntable \u0026lt;- reactable( data_for_table, defaultSortOrder = \u0026#39;desc\u0026#39;, defaultSorted = \u0026#39;excess_deaths\u0026#39;, showSortIcon = FALSE, compact = TRUE, pagination = FALSE, defaultColDef = colDef( headerStyle = list( textAlign = \u0026quot;left\u0026quot;, fontSize = \u0026quot;11px\u0026quot;, lineHeight = \u0026quot;14px\u0026quot;, textTransform = \u0026quot;uppercase\u0026quot;, color = \u0026quot;#0c0c0c\u0026quot;, fontWeight = \u0026quot;500\u0026quot;, borderBottom = \u0026quot;2px solid #e9edf0\u0026quot;, paddingBottom = \u0026quot;3px\u0026quot;, verticalAlign = \u0026quot;bottom\u0026quot;, fontFamily = font_es ), style = list( fontFamily = font_es, fontSize = \u0026quot;14px\u0026quot;, verticalAlign = \u0026quot;center\u0026quot;, align = \u0026quot;left\u0026quot; ) ), columns = list( country = colDef( name = \u0026quot;Region / Country\u0026quot;, style = list(fontFamily = font_es, fontWeight = \u0026quot;400\u0026quot;) ), covid_deaths = colDef( name = \u0026quot;COVID-19 Deaths\u0026quot;, # align = \u0026quot;left\u0026quot;, cell = function(value) { width \u0026lt;- paste0(value * 100 / max(data_for_table$covid_deaths), \u0026quot;%\u0026quot;) value \u0026lt;- format(value, big.mark = \u0026quot;,\u0026quot;) # value \u0026lt;- str_pad(value, 6, pad = \u0026quot;\u0026quot;) value \u0026lt;- format(value, width = 10, justify = \u0026quot;right\u0026quot;) bar \u0026lt;- div( class = \u0026quot;bar-chart\u0026quot;, style = list(marginRight = \u0026quot;6px\u0026quot;), div( class = \u0026quot;bar\u0026quot;, style = list(width = width, backgroundColor = \u0026quot;#F15A3F\u0026quot;) ) ) div(class = \u0026quot;bar-cell\u0026quot;, span(class = \u0026quot;number\u0026quot;, value), bar) } ), excess_deaths = colDef( name = \u0026quot;Total Excess Deaths\u0026quot;, # align = \u0026quot;left\u0026quot;, cell = function(value) { width \u0026lt;- paste0(value * 100 / max(data_for_table$excess_deaths), \u0026quot;%\u0026quot;) value \u0026lt;- format(value, big.mark = \u0026quot;,\u0026quot;) value \u0026lt;- format(value, width = 10, justify = \u0026quot;right\u0026quot;) bar \u0026lt;- div( class = \u0026quot;bar-chart\u0026quot;, style = list(marginRight = \u0026quot;6px\u0026quot;), div( class = \u0026quot;bar\u0026quot;, style = list(width = width, backgroundColor = \u0026quot;#3F5661\u0026quot;) ) ) div(class = \u0026quot;bar-cell\u0026quot;, span(class = \u0026quot;number\u0026quot;, value), bar) } ), perc = colDef( html = TRUE, header = JS(\u0026quot; function(colInfo) { return \u0026#39;COVID-19 as\u0026lt;br\u0026gt;% of total\u0026#39; }\u0026quot;), name = \u0026quot;COVID-19 as % of Total\u0026quot;, align = \u0026quot;right\u0026quot;, maxWidth = 100, format = colFormat(percent = TRUE, digits = 0), style = list(fontFamily = font_es_bold), headerStyle = list( fontSize = \u0026quot;11px\u0026quot;, lineHeight = \u0026quot;14px\u0026quot;, textTransform = \u0026quot;uppercase\u0026quot;, color = \u0026quot;#0c0c0c\u0026quot;, fontWeight = \u0026quot;500\u0026quot;, borderBottom = \u0026quot;2px solid #e9edf0\u0026quot;, paddingBottom = \u0026quot;3px\u0026quot;, verticalAlign = \u0026quot;bottom\u0026quot;, fontFamily = font_es, textAlign = \u0026quot;right\u0026quot; ) ), clean_range = colDef( name = \u0026quot;Time Period\u0026quot;, style = list( color = \u0026#39;#3f5661\u0026#39;, fontSize = \u0026#39;12px\u0026#39;, fontFamily = font_es ) ) ), ) Now, we can include a title and subtitle above the table. We use some htmltools functions to create divs, headers, and paragraphs.\ndiv( div( h2(\u0026quot;Excess mortality since region/country’s first 50 covid deaths\u0026quot;), p( ### create the \u0026#39;Updated on ...\u0026#39; and make it dynamic paste0( \u0026quot;Updated on \u0026quot;, format(Sys.Date(), \u0026quot;%B \u0026quot;), append_date_suffix(as.numeric(format(Sys.Date(), \u0026quot;%d\u0026quot;))), \u0026quot; \u0026quot;, strftime(Sys.time(), format = \u0026quot;%H:%M\u0026quot;), \u0026quot; UCT\u0026quot; ) ), ), table)   Excess mortality since region/country’s first 50 covid deaths Updated on May 24th 12:25 UCT\n  {\"x\":{\"tag\":{\"name\":\"Reactable\",\"attribs\":{\"data\":{\"country\":[\"Austria\",\"Belgium\",\"Britain\",\"France\",\"Istanbul\",\"Italy\",\"Jakarta\",\"Netherlands\",\"New York City\",\"Spain\",\"Sweden\"],\"clean_range\":[\"Mar 23rd-Apr 5th\",\"Mar 23rd-Apr 26th\",\"Mar 14th-May 8th\",\"Mar 11th-Apr 28th\",\"Mar 25th-May 12th\",\"Feb 26th-Mar 31st\",\"Mar 1st-Apr 30th\",\"Mar 16th-May 10th\",\"Mar 15th-Apr 25th\",\"Mar 11th-May 5th\",\"Mar 18th-Apr 28th\"],\"covid_deaths\":[204,6335,40967,23627,1947,12109,381,5420,17195,25584,2703],\"excess_deaths\":[722,7397,54686,26098,4254,24256,3370,9405,20780,31897,2933],\"perc\":[0.282548476454294,0.856428281735839,0.749131404747102,0.90531841520423,0.457686882933709,0.499216688654354,0.113056379821958,0.576289207868155,0.827478344562079,0.802081700473399,0.921581997954313]},\"columns\":[{\"accessor\":\"country\",\"name\":\"Region / Country\",\"type\":\"character\",\"style\":{\"fontFamily\":\"EconSansCndReg\",\"fontWeight\":\"400\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"}},{\"accessor\":\"clean_range\",\"name\":\"Time Period\",\"type\":\"character\",\"style\":{\"color\":\"#3f5661\",\"fontSize\":\"12px\",\"fontFamily\":\"EconSansCndReg\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"}},{\"accessor\":\"covid_deaths\",\"name\":\"COVID-19 Deaths\",\"type\":\"numeric\",\"style\":{\"fontFamily\":\"EconSansCndReg\",\"fontSize\":\"14px\",\"verticalAlign\":\"center\",\"align\":\"left\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"},\"cell\":[{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 204\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"0.49796177411087%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 6,335\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"15.4636658774135%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 40,967\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"100%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 23,627\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"57.6732492005761%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 1,947\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"4.75260575585227%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 12,109\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"29.5579368760222%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 381\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"0.930016842824713%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 5,420\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"13.230160861181%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 17,195\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"41.972807381551%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 25,584\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"62.4502648473161%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 2,703\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"6.59799350696902%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]}]},{\"accessor\":\"excess_deaths\",\"name\":\"Total Excess Deaths\",\"type\":\"numeric\",\"style\":{\"fontFamily\":\"EconSansCndReg\",\"fontSize\":\"14px\",\"verticalAlign\":\"center\",\"align\":\"left\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"},\"cell\":[{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 722\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"1.32026478440552%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 7,397\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"13.5263138646089%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 54,686\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"100%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 26,098\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"47.7233661266138%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 4,254\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"7.77895622279925%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 24,256\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"44.3550451669532%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 3,370\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"6.16245474161577%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 9,405\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"17.1981860073876%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 20,780\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"37.9987565373222%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 31,897\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"58.327542698314%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 2,933\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"5.36334710894927%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]}]},{\"accessor\":\"perc\",\"name\":\"COVID-19 as % of Total\",\"type\":\"numeric\",\"style\":{\"fontFamily\":\"EconSansCndBol\"},\"headerStyle\":{\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\",\"textAlign\":\"right\"},\"format\":{\"cell\":{\"digits\":0,\"percent\":true},\"aggregated\":{\"digits\":0,\"percent\":true}},\"header\":\"\\n function(colInfo) {\\n return 'COVID-19 as\n% of total'\\n }\",\"html\":true,\"maxWidth\":100,\"align\":\"right\"}],\"defaultSortDesc\":true,\"defaultSorted\":[{\"id\":\"excess_deaths\",\"desc\":true}],\"defaultPageSize\":11,\"paginationType\":\"numbers\",\"showPageInfo\":true,\"minRows\":1,\"compact\":true,\"showSortIcon\":false,\"dataKey\":\"7fed8502c33f575f68606f21c78d769a\"},\"children\":[]},\"class\":\"reactR_markup\"},\"evals\":[\"tag.attribs.columns.4.header\"],\"jsHooks\":[]}  Yikes! Those font sizes don’t quite line up with The Economist’s. Let’s add classes to our divs to match their style.\n.table { margin: 0 auto; width: 675px; } .tableTitle { margin: 6px 0; font-size: 16px; font-family: \u0026#39;Econ Sans Cnd\u0026#39; } .tableTitle h2 { font-size: 16px; font-weight: bold; font-family: \u0026#39;Econ Sans Cnd\u0026#39; } .tableTitle p { font-size: 14px; font-weight: 500; } .table { margin: 0 auto; width: 675px; } .tableTitle { margin: 6px 0; font-size: 16px; font-family: 'Econ Sans Cnd' } .tableTitle h2 { font-size: 16px; font-weight: bold; font-family: 'Econ Sans Cnd' } .tableTitle p { font-size: 14px; font-weight: 500; }  div(class = \u0026quot;tableTitle\u0026quot;, div( class = \u0026quot;title\u0026quot;, h2(\u0026quot;Excess mortality since region/country’s first 50 covid deaths\u0026quot;), p( paste0(\u0026quot;Updated on \u0026quot;, format(Sys.Date(),\u0026quot;%B \u0026quot;), append_date_suffix(as.numeric(format(Sys.Date(), \u0026quot;%d\u0026quot;))), \u0026quot; \u0026quot;, strftime(Sys.time(), format = \u0026quot;%H:%M\u0026quot;), \u0026quot; UCT\u0026quot; ) ), ), table) Excess mortality since region/country’s first 50 covid deaths Updated on May 24th 12:25 UCT\n  {\"x\":{\"tag\":{\"name\":\"Reactable\",\"attribs\":{\"data\":{\"country\":[\"Austria\",\"Belgium\",\"Britain\",\"France\",\"Istanbul\",\"Italy\",\"Jakarta\",\"Netherlands\",\"New York City\",\"Spain\",\"Sweden\"],\"clean_range\":[\"Mar 23rd-Apr 5th\",\"Mar 23rd-Apr 26th\",\"Mar 14th-May 8th\",\"Mar 11th-Apr 28th\",\"Mar 25th-May 12th\",\"Feb 26th-Mar 31st\",\"Mar 1st-Apr 30th\",\"Mar 16th-May 10th\",\"Mar 15th-Apr 25th\",\"Mar 11th-May 5th\",\"Mar 18th-Apr 28th\"],\"covid_deaths\":[204,6335,40967,23627,1947,12109,381,5420,17195,25584,2703],\"excess_deaths\":[722,7397,54686,26098,4254,24256,3370,9405,20780,31897,2933],\"perc\":[0.282548476454294,0.856428281735839,0.749131404747102,0.90531841520423,0.457686882933709,0.499216688654354,0.113056379821958,0.576289207868155,0.827478344562079,0.802081700473399,0.921581997954313]},\"columns\":[{\"accessor\":\"country\",\"name\":\"Region / Country\",\"type\":\"character\",\"style\":{\"fontFamily\":\"EconSansCndReg\",\"fontWeight\":\"400\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"}},{\"accessor\":\"clean_range\",\"name\":\"Time Period\",\"type\":\"character\",\"style\":{\"color\":\"#3f5661\",\"fontSize\":\"12px\",\"fontFamily\":\"EconSansCndReg\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"}},{\"accessor\":\"covid_deaths\",\"name\":\"COVID-19 Deaths\",\"type\":\"numeric\",\"style\":{\"fontFamily\":\"EconSansCndReg\",\"fontSize\":\"14px\",\"verticalAlign\":\"center\",\"align\":\"left\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"},\"cell\":[{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 204\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"0.49796177411087%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 6,335\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"15.4636658774135%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 40,967\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"100%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 23,627\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"57.6732492005761%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 1,947\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"4.75260575585227%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 12,109\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"29.5579368760222%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 381\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"0.930016842824713%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 5,420\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"13.230160861181%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 17,195\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"41.972807381551%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 25,584\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"62.4502648473161%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 2,703\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"6.59799350696902%\",\"backgroundColor\":\"#F15A3F\"},\"className\":\"bar\"},\"children\":[]}]}]}]},{\"accessor\":\"excess_deaths\",\"name\":\"Total Excess Deaths\",\"type\":\"numeric\",\"style\":{\"fontFamily\":\"EconSansCndReg\",\"fontSize\":\"14px\",\"verticalAlign\":\"center\",\"align\":\"left\"},\"headerStyle\":{\"textAlign\":\"left\",\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\"},\"cell\":[{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 722\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"1.32026478440552%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 7,397\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"13.5263138646089%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 54,686\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"100%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 26,098\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"47.7233661266138%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 4,254\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"7.77895622279925%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 24,256\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"44.3550451669532%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 3,370\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"6.16245474161577%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 9,405\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"17.1981860073876%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 20,780\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"37.9987565373222%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 31,897\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"58.327542698314%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]},{\"name\":\"div\",\"attribs\":{\"className\":\"bar-cell\"},\"children\":[{\"name\":\"span\",\"attribs\":{\"className\":\"number\"},\"children\":[\" 2,933\"]},{\"name\":\"div\",\"attribs\":{\"style\":{\"marginRight\":\"6px\"},\"className\":\"bar-chart\"},\"children\":[{\"name\":\"div\",\"attribs\":{\"style\":{\"width\":\"5.36334710894927%\",\"backgroundColor\":\"#3F5661\"},\"className\":\"bar\"},\"children\":[]}]}]}]},{\"accessor\":\"perc\",\"name\":\"COVID-19 as % of Total\",\"type\":\"numeric\",\"style\":{\"fontFamily\":\"EconSansCndBol\"},\"headerStyle\":{\"fontSize\":\"11px\",\"lineHeight\":\"14px\",\"textTransform\":\"uppercase\",\"color\":\"#0c0c0c\",\"fontWeight\":\"500\",\"borderBottom\":\"2px solid #e9edf0\",\"paddingBottom\":\"3px\",\"verticalAlign\":\"bottom\",\"fontFamily\":\"EconSansCndReg\",\"textAlign\":\"right\"},\"format\":{\"cell\":{\"digits\":0,\"percent\":true},\"aggregated\":{\"digits\":0,\"percent\":true}},\"header\":\"\\n function(colInfo) {\\n return 'COVID-19 as\n% of total'\\n }\",\"html\":true,\"maxWidth\":100,\"align\":\"right\"}],\"defaultSortDesc\":true,\"defaultSorted\":[{\"id\":\"excess_deaths\",\"desc\":true}],\"defaultPageSize\":11,\"paginationType\":\"numbers\",\"showPageInfo\":true,\"minRows\":1,\"compact\":true,\"showSortIcon\":false,\"dataKey\":\"7fed8502c33f575f68606f21c78d769a\"},\"children\":[]},\"class\":\"reactR_markup\"},\"evals\":[\"tag.attribs.columns.4.header\"],\"jsHooks\":[]}  Let’s compare that to the table we’re attempting to replicate. Note that some of the data has changed in the time between The Economist published their table and I created mine.\n   ","date":1589760000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"bf05f1f6e264032fd3100abdd8e7d294","permalink":"/post/economist-table-replication-using-reactable/","publishdate":"2020-05-18T00:00:00Z","relpermalink":"/post/economist-table-replication-using-reactable/","section":"post","summary":"Recreating a table by The Economist entirely in R, using {reactable}.","tags":["r","visualization","interactive","table","replication"],"title":"Recreating a Table by The Economist Using Reactable","type":"post"},{"authors":null,"categories":null,"content":"","date":1587513600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"1dad6fa02b3a0bf8fa08b4572cabbae4","permalink":"/project/mapping-police-violence/","publishdate":"2020-04-22T00:00:00Z","relpermalink":"/project/mapping-police-violence/","section":"project","summary":"An interactive force diagram built in D3, featured on the [Mapping Police Violence](https://mappingpoliceviolence.org/) homepage.","tags":["D3","For Work"],"title":"Mapping Police Violence","type":"project"},{"authors":null,"categories":null,"content":"","date":1587513600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"306147eb14df9d47e53c83bf8ab7ea7c","permalink":"/project/coronavirus-houston-response-projects/","publishdate":"2020-04-22T00:00:00Z","relpermalink":"/project/coronavirus-houston-response-projects/","section":"project","summary":"An interactive Shiny dashboard presenting trends in mobility during COVID-19. Winner of the Data 2 Knowledge Lab’s COVID-19 Houston Response Projects competition.","tags":["R","D3","For Work"],"title":"Mobility and Predictors of Movement During COVID-19","type":"project"},{"authors":null,"categories":null,"content":"","date":1585353600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"4a20d21aa670fff2f8315550397fa4bf","permalink":"/project/multiple-views-covid-19/","publishdate":"2020-03-28T00:00:00Z","relpermalink":"/project/multiple-views-covid-19/","section":"project","summary":"An interactive D3 visualization of COVID-19 cases across counties and over time.","tags":["D3","For Fun"],"title":"Multiple Views: Recorded COVID-19 Cases, by County","type":"project"},{"authors":null,"categories":null,"content":"","date":1584230400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"91b9a363e0367f36c714d0a62999f907","permalink":"/project/covid-has-become-a-partisan-issue/","publishdate":"2020-03-15T00:00:00Z","relpermalink":"/project/covid-has-become-a-partisan-issue/","section":"project","summary":"And, how (and why) to create dumbbell plots in R.","tags":["R","For Fun"],"title":"COVID-19 Has Become a Partisan Issue","type":"project"},{"authors":null,"categories":["R"],"content":"The coronavirus (also known as COVID-19) is a pandemic. As of this writing, nearly 6000 people have died and another 150,000 have been infected. All signs seem to show that the virus is only growing.\nBut some groups are less worried about COVID-19 than others. Recent polling from Quinnipiac University suggests that worries about coronavirus are related to one’s partisan identity, age, and race.\nLet’s visualize that to see just how stark the differences are. I use dumbbell dot plots because they’re some of the most powerful tools for visualizing differences between two groups (e.g. Republicans and Democrats).\nPolitical Affiliation Republicans tend to be significantly less worried about coronavirus than Democrats. This is true in two regards. First, with respect to concern for becoming infected:\nIt’s also true when we look at concern than COVID-19 will disrupt an individual’s life:\nLooking at the first plot, we notice that Republicans are 3x more likely than Democrats to say that they are ’not concerned at all’ by the prospect of coronavirus infecting them or someone they know. By contrast, Democrats are nearly 3x as likely as Republicans to say that they are ‘very concerned’ by the same risk.\nThe second plot shows us similar trends for fears of disruption: 3 in 4 Democrats are concerned (very or somewhat) that COVID-19 will disrupt their daily lives, compared to only 38% of Republicans. While 26% of Democrats are not worried about disruption, the same is true for 61% of Republicans.\nAge There is also a relationship between age and fears related to the coronavirus.\nThese plots show that there are significant differences in worry by age, but that fears of disruption are felt more universally than fears of infection. The first plot shows that every age group fears that COVID-19 will disrupt their daily lives; although younger people express this sentiment less frequently. The second plot the majority of people under age 50 are unconcerned by the prospect of COVID-19 infection. The opposite is true for older respondents; those aged 65 years and old are significantly more likely to be concerned by the risk of infection (62% vs 37%).\nWhy Dumbbell Plots? Dumbbell plots are an alternative to grouped barcharts. Like barcharts, they show differences between populations and they more powerfully represent the distances between two groups. They are frequently used by survey research firms such as the Pew Research Center, as seen in this example:\nWhile a barchart would require eight bars to visualize each datapoint above, a dumbbell dot plot shows eight dots on four lines, reducing clutter and emphasizing the differences between groups.\nHere’s another example, this time from Axios (visualizing changes in presidential disapproval between January and October 2017):\nThis pseudo-dumbbell plot (dumbbells with weird endpoints; don’t pick up that side!) has 50 ‘groups’ (US states), but only two outcomes (January and October). A dumbbell plot is far superior to a grouped bar chart in this case because it emphasizes the difference is between two periods of time, and it does so with fewer objects (50 lines rather than 100 bars) than a barchart would use.\nOne key lesson from the examples above: If the comparison of interest is between two groups (e.g. Republicans and Democrats), or if the outcome of interest is two-fold (e.g. ‘concerned’ and ‘not concerned’), dot plots are a superior way to visualize your data.\nLet’s Make It In R! Now it\u0026rsquo;s time to make your own dumbbell dot plot. We’ll be creating this viz:\nFor reference, the data I’m using looks like this:\nPretty simple, right? It comes from here, by the way.\nThe process relies on Bob Rudis’s ggalt package and the geom_dumbbell function, which does most of the heavy lifting. This tutorial is mostly a step-by-step recreation of Rudis’s code found here.\nFor convenience, let\u0026rsquo;s define a few things before we get started:\nblue \u0026lt;- \u0026quot;#0171CE\u0026quot; red \u0026lt;- \u0026quot;#DE4433\u0026quot;  In addition to the colors, we create a hack-y function which allows us to selectively label points (thanks to Bob Rudis for this, again):\npercent_first \u0026lt;- function(x) { x \u0026lt;- sprintf(\u0026quot;%d%%\u0026quot;, round(x*100)) x[2:length(x)] \u0026lt;- sub(\u0026quot;%$\u0026quot;, \u0026quot;\u0026quot;, x[2:length(x)]) x }  Step 1: Barebones We begin with a basic ggplot object. In geom_segment, we define the pseudo-grid lines (one for each ‘level’ of concern).\nlibrary(ggplot2) library(ggalt) library(tidyverse) ggplot() + geom_segment(data=infected, aes(y=concerned, yend=concerned, x=0, xend=.5), color=\u0026quot;#b2b2b2\u0026quot;, size=0.15)  Here, geom_segment creates grey lines with a size of 0.15. The lines span from 0 to 0.5. This changes according to your data; because the largest number we are dealing with is .43 (representing 43% of Democrats), our bound on the right side can be 0.5; this also leaves room for the difference column which we create later.\nThen, geom_dumbbell reads in our data and creates the dumbbells: we specify the beginning (x) of each dumbbell to represent Republicans and the end (xend) to correspond to Democrats. Other specifications affect the accompanying line and points.\ngeom_dumbbell(data=infected, aes(y=concerned, x=rep, xend=dem), size=1.5, color=\u0026quot;#b2b2b2\u0026quot;, size_x=3, size_xend = 3, colour_x = red, colour_xend = blue)  That code creates the following plot:\nAlready, we can begin to see the barebones for the finished version: each dumbbell represents a level of concern, and visualizes Republicans and Democrats’ proportions for that level.\nStep 2: Labels The next step is creating the “Republican” and “Democrat” labels (in case colors aren’t enough, or the image is seen in black and white!).\nWe can create labels with the following code:\ngeom_text(data=filter(infected, concerned==\u0026quot;Very concerned\u0026quot;), aes(x=dem, y=concerned, label=\u0026quot;Democrats\u0026quot;), color=blue, size=3, vjust=-1.5, fontface=\u0026quot;bold\u0026quot;, family=\u0026quot;Lato\u0026quot;) + geom_text(data=filter(infected, concerned==\u0026quot;Very concerned\u0026quot;), aes(x=rep, y=concerned, label=\u0026quot;Republicans\u0026quot;), color=red, size=3, vjust=-1.5, fontface=\u0026quot;bold\u0026quot;, family=\u0026quot;Lato\u0026quot;)  This code is hopefully quite intuitive. Since we are only showing the labels once, we specify a filter in the data argument of geom_text. If we instead wanted to show the labels for only the bottom level of concern, we would specify data=filter(infected, concerned==\u0026quot;Not concerned at all”).\nWe label each point at its respective political affiliation, and we specify color according to the point color. The rest is just minor beautification for the text.\nWe also have to add direct labels for values, so that the exact percentages for each group are clear:\ngeom_text(data=infected, aes(x=rep, y=concerned, label=percent_first(rep)), color=red, size=2.75, vjust=2.5, family=\u0026quot;Lato\u0026quot;) + geom_text(data=infected, color=blue, size=2.75, vjust=2.5, family=\u0026quot;Lato\u0026quot;, aes(x=dem, y=concerned, label=percent_first(dem)))  Here, we utilize the function percent_first we defined earlier, because we only want percentages to appear on the first numbers (to reduce clutter). The rest of the labels are just numbers which represent percentages. The syntax here is simple syntax that should be familiar to ggplot users. It creates this output:\nStep 3: A Differences Column Finally, we want to help our viewers see how stark the differences between Democrats and Republicans really is. We do so with a differences column.\ngeom_rect(data=infected, aes(xmin=.5, xmax=.6, ymin=-Inf, ymax=Inf), fill=\u0026quot;grey\u0026quot;) + geom_text(data=infected, aes(label=paste0(diff*100, \u0026quot;%\u0026quot;), y=concerned, x=.55), fontface=\u0026quot;bold\u0026quot;, size=3, family=\u0026quot;Lato\u0026quot;) + geom_text(data=filter(infected, concerned==\u0026quot;Very concerned\u0026quot;), aes(x=.55, y=concerned, label=\u0026quot;Difference\u0026quot;), color=\u0026quot;black\u0026quot;, size=3.1, vjust=-2, fontface=\u0026quot;bold\u0026quot;, family=\u0026quot;Lato\u0026quot;) + scale_x_continuous(expand=c(0,0), limits=c(0, .625)) + scale_y_discrete(expand=c(0.2,0))  Here, we first create a grey rectangle with geom_rect. It spans the entire chart vertically, hence why ymin and ymax range from negative to positive infinity. Next, we create labels according to the differences column. We position each of them according to the degree of concern (our y-axis). Finally, we expand the bounds of the chart so its a bit prettier:\nStep 4: Titles, Labels \u0026amp; Captions Finally, let’s add our title, subtitle, caption, and axis labels:\nlabs(x=NULL, y=NULL, title=\u0026quot;Republicans are less worried about COVID-19\u0026quot;, subtitle=\u0026quot;How concerned are you that you or someone you know will be infected with the coronavirus?\u0026quot;, caption=\u0026quot;Source: Quinnipiac University Poll, March 9, 2020. Q27 \\n\\nDesign: Connor Rothschild\u0026quot;)  That’s our plot! Too bad its kinda ugly. Let’s fix that in our final step.\nStep 5: Beautification Beautification occurs using the theme argument.\ntheme_bw(base_family=\u0026quot;Lato\u0026quot;) + theme( panel.grid.major=element_blank(), panel.grid.minor=element_blank(), panel.border=element_blank(), axis.ticks=element_blank(), axis.text.x=element_blank(), plot.title=element_text(size = 16, face=\u0026quot;bold\u0026quot;), plot.title.position = \u0026quot;plot\u0026quot;, plot.subtitle=element_text(face=\u0026quot;italic\u0026quot;, size=12, margin=margin(b=12)), plot.caption=element_text(size=8, margin=margin(t=12), color=\u0026quot;#7a7d7e\u0026quot;) )  After specifying our base ggplot theme, theme_bw, we use theme() to specify a whole host of arguments.\nTo simplify, the above code:\n Removes grid lines (panel.grid.major, panel.grid.minor) Removes the panel border (panel.border) Removes axis ticks and axis text (axis.ticks, axis.text.x) Positions the axis plot, subtitle, and caption, and styles them as well (plot.title, plot.title.position,plot.subtitle,plot.caption).  Our final output:\nTo Summarize Our process looked like this:\nThe code for the above visualizations, as well as the underlying datasets and outputs, can be found here.\nThanks for reading!\n","date":1584230400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"c2f3c512713200c42c7acd0ab6fa1693","permalink":"/post/dumbbell-plots/","publishdate":"2020-03-15T00:00:00Z","relpermalink":"/post/dumbbell-plots/","section":"post","summary":"How to create dumbbell plots in R, using {ggalt}.","tags":["r","visualization"],"title":"Create Dumbbell Plots to Visualize Group Differences in R","type":"post"},{"authors":null,"categories":null,"content":"","date":1583366400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"0f572b2650959cdcd053c57249ebd6e5","permalink":"/project/are-you-smarter-than-compas/","publishdate":"2020-03-05T00:00:00Z","relpermalink":"/project/are-you-smarter-than-compas/","section":"project","summary":"A quick game to see if you are more intelligent than an algorithm used to sentence millions of Americans.","tags":["JavaScript","For Fun"],"title":"Are You Smarter Than a Criminal Justice Algorithm?","type":"project"},{"authors":null,"categories":null,"content":"","date":1581120000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"c2deb366c0048848b6bdebb4a1ff8525","permalink":"/project/what-are-you-doing/","publishdate":"2020-02-08T00:00:00Z","relpermalink":"/project/what-are-you-doing/","section":"project","summary":"Using data from the American Time Use Survey, let me guess what you’re doing. Right now.","tags":["JavaScript","For Fun"],"title":"Let Me Guess What You're Doing Right Now","type":"project"},{"authors":null,"categories":["R"],"content":"In previous projects, I\u0026rsquo;ve explored how migration has unfolded across places: where migrants travel, where they go missing, and where their journeys come to a fatal end.\nNext, I wanted to see how host countries have approached the migrant and refugee crisis, with a particular focus on the United States. In my mind, an effective visualization of the U.S.\u0026lsquo;s response to an increasing number of refugees needs to present two things: how refugee acceptance has changed over time and how refugee acceptance differs across states.\nAn effective way to present both of these trends is with a map of small multiple line charts. For aesthetic purposes, it would also be nice to arrange these multiples in a shape that vaguely resembles the United States. (This also makes it easier for readers to find their state of interest.)\nThere are examples of these types of small multiple maps across the internet. The Washington Post\u0026rsquo;s overview of the electoral college was visualized in the following way:\nYou can also find an overview of why they work, and some additional examples, on the PolicyViz blog:\nMaking it in R The process of creating a small multiple tile grid map is relatively easy in R (like most things done in R). It is considerably more difficult in D3.js; if you\u0026rsquo;re interested in that type of thing, you can take a look at this code for inspiration.\nStep 1: Build the basic line chart The first step (after obnoxious data merging and cleaning) is getting a feel for the basic line chart. To do so, we can visualize the macro-level trends of refugee acceptance across all states combined.\ndata %\u0026gt;% group_by(region_name_3) %\u0026gt;% summarise(textbox37 = sum(textbox37)) %\u0026gt;% ggplot(aes(x = region_name_3, y = textbox37)) + geom_line() + labs(title = \u0026quot;Refugee Acceptance on the Decline\u0026quot;, subtitle = \u0026quot;Number of refugees accepted annually, 2002 - 2019\u0026quot;, x = element_blank(), y = element_blank()) + scale_y_continuous(labels = scales::comma_format()) + scale_x_continuous(breaks = c(2002, 2019))  Now we have the answer to our first question: how has refugee acceptance changed over time? The answer: pretty drastically. The US accepted nearly 100,000 refugees in 2016; 2 years later, that number was barely over 20,000.\nStep 2: Make small multiples Next, we make 50 of these lines: one for each US state. We do so using Ryan Hafen\u0026rsquo;s geofacet package.\nIt\u0026rsquo;s as simple as adding one line of code to our previous plot:\nfacet_geo(~ state)  This makes a plot that looks like this:\nIt\u0026rsquo;s alright, but not perfect! There are a few improvements we can definitely make.\nFor one, the axis labels overlap. We already know the range of years is between 2002 and 2019 (its in our subtitle!). So we can remove our x axis labels.\ntheme( axis.text.x = element_blank(), axis.ticks.x = element_blank() )  Second, The axis lines (on both axes) seem unnecessary and (the x-axis specifically) can sometimes conceal trends for those states with lower values. Let\u0026rsquo;s remove those too!\ntheme( axis.line.x = element_blank(), axis.line.y = element_blank() )  Finally, I don\u0026rsquo;t like huge gray boxes around my axis labels. Could we make those transparent?\ntheme( strip.background = element_rect(color = \u0026quot;white\u0026quot;) )  Add it all together (and tweak the font size), and we get this:\ndata %\u0026gt;% group_by(region_name_3, state) %\u0026gt;% summarise(textbox37 = sum(textbox37)) %\u0026gt;% ggplot(aes(x = region_name_3, y = textbox37)) + geom_line(color = \u0026quot;black\u0026quot;) + scale_x_continuous(breaks = c(2002,2019)) + scale_y_continuous(breaks = c(0,12000)) + facet_geo(~ state, grid = \u0026quot;us_state_grid1\u0026quot;) + labs(title = \u0026quot;Refugee Acceptance on the Decline\u0026quot;, subtitle = \u0026quot;Number of refugees accepted annually, 2002 - 2019\u0026quot;, x = element_blank(), y = element_blank()) + theme( axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.line.x = element_blank(), axis.line.y = element_blank(), plot.title = element_text(size = 24), plot.subtitle = element_text(size = 18), strip.background = element_rect(color = \u0026quot;white\u0026quot;) )  Pretty good! Much better. But we can add some elements to take our visualization to the next level.\nBecause our data spans nearly 20 years (2002 to 2019), we can overlay our small multiples with other variables of interest, such as who was President during a given period.\nWe do so using geom_rect:\ngeom_rect(mapping=aes(xmin=2009, xmax=2017, ymin=0, ymax=12000), fill = \u0026quot;#ADD8E6\u0026quot;, alpha = .05) + geom_rect(mapping=aes(xmin=2017, xmax=2019, ymin=0, ymax=12000), fill = \u0026quot;#FF9999\u0026quot;, alpha = .05) +  The first line of code creates a blue box which spans 2009 to 2017 (Obama\u0026rsquo;s tenure). The second line creates a red box for Trump\u0026rsquo;s presidency (so far).\nBringing it all together, the code and output look like this:\ndata %\u0026gt;% group_by(region_name_3, state) %\u0026gt;% summarise(textbox37 = sum(textbox37)) %\u0026gt;% ggplot(aes(x = region_name_3, y = textbox37)) + geom_line(color = \u0026quot;black\u0026quot;) + geom_rect(mapping=aes(xmin=2009, xmax=2017, ymin=0, ymax=12000), fill = \u0026quot;#ADD8E6\u0026quot;, alpha = .05) + geom_rect(mapping=aes(xmin=2017, xmax=2019, ymin=0, ymax=12000), fill = \u0026quot;#FF9999\u0026quot;, alpha = .05) + scale_x_continuous(breaks = c(2002,2019)) + scale_y_continuous(breaks = c(0,12000)) + facet_geo(~ state, grid = \u0026quot;us_state_grid1\u0026quot;) + labs(title = \u0026quot;Refugee Acceptance on the Decline\u0026quot;, subtitle = \u0026quot;Number of refugees accepted annually, 2002 - 2019\u0026quot;, x = element_blank(), y = element_blank()) + theme( axis.text.x = element_blank(), axis.ticks.x = element_blank(), axis.line.x = element_blank(), axis.line.y = element_blank(), plot.title = element_text(size = 24), plot.subtitle = element_text(size = 18), strip.background = element_rect(color = \u0026quot;white\u0026quot;) )  I brought that plot to Illustrator and made it a lot prettier. Here\u0026rsquo;s the final version:\nWhat do we notice? A few key states (Texas, California, Florida, and Michigan) make up the vast majority of refugee acceptance, while other accept almost no refugees. Nearly every state has reduced their refugee acceptance since 2017, but the bulk of this decline has come from these larger states.\nWhile you\u0026rsquo;re here, take a look at my project Mapping Missing Migrants.\n","date":1580515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"19741118028a576e083d4d7dfee520c8","permalink":"/post/refugee-trends/","publishdate":"2020-02-01T00:00:00Z","relpermalink":"/post/refugee-trends/","section":"post","summary":"Or, how a single line of code can create a beautiful small multiples US map.","tags":["r","visualization","small multiples"],"title":"Trends in Refugee Acceptance, 2002 to 2019","type":"post"},{"authors":null,"categories":null,"content":"","date":1580515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"176e032a8364215071f880d558736946","permalink":"/project/refugee-trends/","publishdate":"2020-02-01T00:00:00Z","relpermalink":"/project/refugee-trends/","section":"project","summary":"And, how (and why) to create small multiples maps in R.","tags":["R","For Fun"],"title":"Trends in Refugee Acceptance, 2002 to 2019","type":"project"},{"authors":["Connor Rothschild"],"categories":["Data Viz","Theory"],"content":"If our use of color in visualizations follows the Five Ws (and one H), we\u0026rsquo;re spending too much time on how, and not enough time on why. Color is too often seen as a tool to make pretty pictures, when it should be used to inform our audiences.\nFor one example, look at this \u0026ldquo;Color Emotion Guide\u0026rdquo; from marketing site TapClicks (one of the top results when you Google \u0026ldquo;color in data visualization\u0026rdquo; 🧐).\nThe implicit suggestion here is that we should use color\u0026ndash;whenever and however we can\u0026ndash;to capture some form of emotion. Not only is this specific categorization rather odd (Monster energy drinks are peaceful, Virgin Mobile embodies \u0026ldquo;bold excitement\u0026rdquo;, and Harley Davidson motorcycles just scream \u0026ldquo;cheerful friendliness\u0026rdquo; 🤩), it leads novice practitioners to believe that color should be used just for the sake of using color.\nExamples of gratuitous color use abound.\nThese examples illustrate my thesis: Too often, we ask how we can use color in our visualizations when we should be asking why we are using it.\nSome combination of 1) default software settings, 2) an obsession with pretty color palettes, and 3) a lack of emphasis on careful color consideration has led to a sloppy use of color in some of our most popular data visualizations.\nOne of the most common errors I see is the overuse of color. In the charts above, for example, it\u0026rsquo;s evident that there are far too many colors, with no apparent reason for the\nOften times, those creating visualizations will argue that they must include a 14 colors in their chart because the dataset has 14 data points of interest! It doesn\u0026rsquo;t help that the default settings of some of the most popular data viz tools (such as Excel) by default map categorical variables to colors.\nThe reality is, however, that if you need more than a handful of colors in your chart, you can probably present your data in a different way. Take this example from Datawrapper:\nThe takeaway? When you emphasize everything, you end up emphasizing nothing. That\u0026rsquo;s why its important that we stop uncritically asking how we can use color in our charts.\nA data visualization is nothing more than a pretty picture if it does not inform its viewer. And if your chart presents 14 different data points all mapped to different colors, what kind of story is it telling? I really like this from Apple\u0026rsquo;s data visualization practitioner Elijah Meeks:\n Rather than trying to find that impossible 20-color palette, stop using color when you have so many dimensions. It’s indistinguishable, it’s confusing and you’re just off-loading the complexity and decision-making to your reader.\n That\u0026rsquo;s why color should be used more sparingly and more thoughtfully. Color is one of the most important parts of our visualizations, yet their current use is far too often gratuitous and overwhelming.\nSo, how should you use color? Color is not the enemy. Rather, the (far too frequent) abuse and misuse of color is. So, how can you use color correctly? It depends on the purpose of your visualization, and, as a corollary, the purpose of color. You should ask: why am I using color?\n1) Color to differentiate One use of color is to draw attention to a data point of interest. This kind of color use would fall into the category of explanatory visualization, as opposed to its exploratory counterpart. If you\u0026rsquo;ve already explored, analyzed, and probed your data, you now need to deliver those insights to someone else (a supervisor, a client, or a curious friend). It would be a waste of time to present to them all of the exploratory work you did, which is why your presentation should make use of color to focus on your findings.\nAs practitioner Andy Kirk puts it, visualization practitioners in this stage of presentation should make grey their best friend. This is because the absence of color, not the excessive use of it, helps paint a picture and tell a story. By using grey as the primary color in a visualization, we automatically draw our viewers\u0026rsquo; eyes to whatever isn\u0026rsquo;t grey. That way, if we are interested in telling a story about one data point, we can do so quite easily.\nHere\u0026rsquo;s a quick example I made in R a while back:\nThe point of the visualization is not to show our audience the kindergarten vaccination rate of every county in Texas. It is instead to highlight the lowest rate\u0026ndash;Terry County. This visualization leverages the grey fill of every other bar to immediately draw the audiences\u0026rsquo; eyes to Terry County. Because we used only two colors, we can also highlight text in the subtitle to make the connection even clearer for our audience. Color\u0026ndash;if used prudently\u0026ndash;makes our visualizations more digestible and more informative.\nNow, imagine if I visualized that same data in the following way:\nOr, even worse:\nAfter seeing those eyesores, aren\u0026rsquo;t you thankful that we used color sparingly in the initial plot?\nPerhaps you\u0026rsquo;re interested in a county-by-county overview of 2016 election results. Although you might be tempted to code all counties according to their Trump/Clinton split, that\u0026rsquo;s prettier than it is insightful. What if, instead, we focused on those notable counties which flipped from one party to another between 2012 and 2016? From Kieran Healy\u0026rsquo;s book Data Visualization:\nAs we can see here, more counties flipped from majority-Democratic in 2012 to majority-Republican in 2016 than vice-versa. Because we\u0026rsquo;re focusing on only a fraction of all of the data points, we can also observe trends: The majority of counties that flipped had a small black population. No county that had over a ~53% black population flipped in either direction (annotation my own):\nWe also notice that flipping direction might be correlated with population size: nearly all of the flipping counties with a log population under 100,000 flipped to Republicans, while a greater proportion of all switching counties flipped toward the Democratic Party if their log population was greater than 100,000.\nColor can, and should, be used to focus on the key parts of your visualization that you want your audience to see. By using color strategically, we can reduce the cognitive load required to understand what a visualization is depicting. Kalyuga et al. found that color-coding \u0026ldquo;ameliorated split-attention effects, resulting in lower perceived difficulty.\u0026rdquo; Other researchers have reported reductions in cognitive load when experiment participants were provided color-coding.\nThe overuse of colors can have the opposite effect. In one 2019 paper, researchers found \u0026ldquo;task-irrelevant digit colour information hampers the learning process only in instances where it triggers a conflict with the semantic properties of the base-code words.\u0026rdquo; What does this mean? If color encoding conflicts with the objects it represents, it impedes learning and weakens understanding. You don\u0026rsquo;t have to understand what all this means (I don\u0026rsquo;t dully understand all of it). This point is simply to illustrate: we should care about color. Color can be confusing and complicated, which is why its use should be intentional and minimal. It should be used to draw attention to the important parts of our charts.\n2) Color to explore Color does not have to be used in contrast to plain old grey. It can also be used as a tool to showcase a variety of data points all mapped to different colors. The important note is that this usage should be sparing. Given our prior examples, we definitely don\u0026rsquo;t want a plot like this one (from Chapter 19 of Claus Wilke\u0026rsquo;s Fundamentals of Data Visualization):\nA more appropriate alternative may look something like this:\nThis way, the audience can still see general patterns in the data, but they don\u0026rsquo;t have to treat the fill legend like a lookup table! Most ideally, this chart would have some interactivity, so that a user could hover over a point to see its respective data.\nIn examples like this, where we are exploring rather than explaining, we leave the exploration to our users; they can see what they want to see and we give them the information they need to do exactly that.\nAnother common use of color for exploratory purposes is showing data progression across a gradient (e.g. low to high, bad to good, cold to warm).\nThese examples are most commonly found in choropleth maps, where the shade of color in a given state (or county, or region) corresponds to a value of interest. As an example, here\u0026rsquo;s a choropleth map I created using D3.js, which visualizes opioid-involved overdose deaths in the United States:\nAs we can see from the map, \u0026ldquo;rust belt\u0026rdquo; states are suffering from the opioid crisis to a much greater degree than those in western states. Choropleth maps utilize color to show regional variation and illustrate the power of color shading to represent the severity or extent of a given variable.\nHowever, color in this context can also be misused. Data may be mapped according to a categorical color scale, or a rainbow scale which makes it difficult to see progression. This chart from Claus O. Wilke is a good (bad) example:\nThis chart is pretty! When rainbow scales are used in the media or elsewhere, it may be because their creator asked \u0026ldquo;How can I use color to make a pretty picture?\u0026rdquo; But this use of a non-monotonic color scale means that the relative size of differences between data points are difficult to detect. As an illustration, see how long it takes you to answer this question: using the legend above, what is the percent difference between this color and this color? (The answer is ~70%.)\nIn 2019, a group of researchers asked climate scientists to evaluate maps depicting changes in climate, where maps were either rainbow (similar to the Texas map above) or monotonic (such as the opioid map earlier). The researchers found that evaluations of magnitude difference in these maps were significantly more accurate when they were encoded with monotonic luminance scales rather than traditional rainbow scales. Other research consistently finds that rainbow color scales are both harmful and popular. All this to say: color matters.\nSo, color can be used for exploratory purposes. That is to say, color doesn\u0026rsquo;t have to be used exclusively for focus, and it can be used in charts that have colors other than just grey! But exploratory color usage (as with all use of color) requires caution.\nConclusion Color is tricky. While it can take your plot to the next level, it can also ruin it. The difference? The questions we ask. Are we questioning how you can use color; which of the many palettes to use, and how we can map them across variables? These are important questions, but they have to be preceded by the question of why we use color in the first place. If color doesn\u0026rsquo;t serve the purpose of informing, clarifying, or guiding our audience, what purpose does it serve?\n","date":1578614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"1d2b114dfb1743da459caa3aa2858323","permalink":"/post/color-in-data-vis/","publishdate":"2020-01-10T00:00:00Z","relpermalink":"/post/color-in-data-vis/","section":"post","summary":"An overview of the use of color in data visualization.","tags":["visualization\"","theory","color"],"title":"Color in Data Visualization: Less How, More Why","type":"post"},{"authors":["Connor Rothschild"],"categories":["D3.js"],"content":"I think tooltips are one of the most underrated parts of a visualization. When users are initially confused by a visualization, they often hover over a data point of interest to get more information.\nUnfortunately, many tooltips fail to really illuminate much about our data. They often recapitulate what is already being presented without clarifying any of the confusing parts of the data. Most frequently, I see (and even create 😦) tooltips which present the most basic information (in a map, a tooltip would present the state name and the value of interest), and nothing else!\nOf course, there\u0026rsquo;s nothing wrong with these kinds of tooltips. But they are truly doing the bare minimum, and, as a result, they\u0026rsquo;re missing out on the full potential of tooltips. If users are actively seeking more information by hovering over data, we ought to reward them with the most helpful and interesting information we can.\nThat\u0026rsquo;s why I recently updated one of my tooltips from a static presentation of textual information to a line chart depicting change over time. In other words, I went from this:\nto this:\nWhy did I make that change? The former tooltip provided information which was rather uninteresting. Although it clarified the exact rate of overdose deaths in a given state at a given time, it didn\u0026rsquo;t do much else. It did provide the year currently in view, but this was also visible in the bottom right corner of the visualization! It also provided the state name, but most of my viewers have likely taken US geography in middle school.\nThus, this tooltip was rather redundant. At best, it provided the exact rate, so that a viewer could compare two states, or learn more information about a given state without solely relying on color encoding ( which can be somewhat unreliable when it comes to quantitative encoding, as is the case in a choropleth map).\nThe new tooltip shows a trend over time. It also shows the state name (just in case you skipped that day in US geography!), and also the most recent data on overdose deaths. Because this map is meant to show how the opioid crisis has evolved, showing a line chart for each state in my tooltip allows the user to explore state-by-state trends on hover! This is much easier than hovering on each state during each year and trying to keep track of the trends.\nFor example, hovering on West Virginia, which in 2017 seemed to have the highest opioid-involved overdose death rate (as indicated by it having the darkest shade of red), reveals that its also experienced one of the largest over-time increase in this rate since 1999:\nSo, how do you do it? Great question! It\u0026rsquo;s thankfully not that hard, but the payoff is huge. The shift from my old, boring tooltip to my new, sexy one took only a couple of hours, thanks to a few Stack Overflow answers and online examples.\nStep 1: Load d3-tip The process mostly relies on d3-tip, which you can learn more about here.\nYou can load d3-tipwith the following code:\n\u0026lt;script src=\u0026quot;https://cdnjs.cloudflare.com/ajax/libs/d3-tip/0.7.1/d3-tip.min.js\u0026quot;\u0026gt;\u0026lt;/script\u0026gt;  Step 2: Create a tooltip object Next, you initialize your tooltip, give it a class (for CSS styling), and provide the specified offset. In my example, I define my offset according to the user\u0026rsquo;s mouse position. That way, if a user hovers over an eastern state, the tooltip doesn\u0026rsquo;t disappear off the screen!\n// define the tooltip var tool_tip = d3.tip() .attr(\u0026quot;class\u0026quot;, \u0026quot;d3-tip\u0026quot;) // if the mouse position is greater than 650 (~ Kentucky/Missouri), offset tooltip to the left instead of the right .offset(function() {if(current_position[0] \u0026gt; 650) { return [-20,-120] } else { return [20,120]} }) // input the title, and include the div .html( \u0026quot;\u0026lt;p\u0026gt;Opioid-involved deaths over time in\u0026lt;/p\u0026gt;\u0026lt;div id='tipDiv'\u0026gt;\u0026lt;/div\u0026gt;\u0026quot; ); svg.call(tool_tip);  The most important part here is\n.html( \u0026quot;\u0026lt;p\u0026gt;Opioid-involved deaths over time in\u0026lt;/p\u0026gt;\u0026lt;div id='tipDiv'\u0026gt;\u0026lt;/div\u0026gt;\u0026quot; );  where we define the html that creates the tooltip itself. In our case, we provide a title, \u0026ldquo;Opioid-involved deaths over time\u0026rdquo;, and also specify the div that the tooltip should include.\nStep 3: Create the tipDiv object Finally, we can create the tipDiv object we referenced in the above code. The object will be created on mouseover of the group of interest (in my case, states). Thus, the code will look something like this:\nstates = svg.append(\u0026quot;g\u0026quot;) .attr(\u0026quot;class\u0026quot;, \u0026quot;states\u0026quot;) .selectAll(\u0026quot;path\u0026quot;) .data(topojson.feature(us, us.objects.states).features) .enter() .append(\u0026quot;path\u0026quot;) .attr(\u0026quot;d\u0026quot;, path) .on('mouseover', function(d) { // define and store the mouse position. this is used to define tooltip offset, seen above. current_position = d3.mouse(this); // define current state current_state = nameById[d.id] // show the tooltip tool_tip.show();  After that initialization and show function, we can define the tipDiv object:\nvar tipSVG = d3.select(\u0026quot;#tipDiv\u0026quot;) .append(\u0026quot;svg\u0026quot;) .attr(\u0026quot;width\u0026quot;, 220) .attr(\u0026quot;height\u0026quot;, 55); tipSVG.append(\u0026quot;path\u0026quot;) .datum(overdoses.filter(function(d) {return nameById[d.id] == current_state})) .style(\u0026quot;stroke\u0026quot;, function() { if (rateById[d.id] \u0026lt; 10) { return \u0026quot;grey\u0026quot; } else { return color(rateById[d.id]) } }) .style(\u0026quot;stroke-width\u0026quot;, 1.5) .style(\u0026quot;fill\u0026quot;, \u0026quot;none\u0026quot;) .attr(\u0026quot;d\u0026quot;, line) tipSVG.append(\u0026quot;circle\u0026quot;) .attr(\u0026quot;fill\u0026quot;, function() { if (rateById[d.id] \u0026lt; 10) { return \u0026quot;grey\u0026quot; } else { return color(rateById[d.id]) } }) .attr(\u0026quot;stroke\u0026quot;, \u0026quot;black\u0026quot;) .attr(\u0026quot;cx\u0026quot;, 130) .attr(\u0026quot;cy\u0026quot;, y_tooltip(rateById[d.id])) .attr(\u0026quot;r\u0026quot;, 3) tipSVG.append(\u0026quot;text\u0026quot;) .text(rateById[d.id] + \u0026quot; deaths\u0026quot;) .attr(\u0026quot;x\u0026quot;, 140) .attr(\u0026quot;y\u0026quot;, function() { if (y_tooltip(rateById[d.id]) \u0026lt; 15) { return 10 } else { return y_tooltip(rateById[d.id]) - 7 } }) tipSVG.append(\u0026quot;text\u0026quot;) .text(\u0026quot;per 100,000\u0026quot;) .attr(\u0026quot;x\u0026quot;, 140) .attr(\u0026quot;y\u0026quot;, function() { if (y_tooltip(rateById[d.id]) \u0026lt; 15) { return 24 } else { return y_tooltip(rateById[d.id]) + 7 } }) tipSVG.append(\u0026quot;text\u0026quot;) .text(current_state) .attr(\u0026quot;x\u0026quot;, 0) .attr(\u0026quot;y\u0026quot;, 15) .style(\u0026quot;font-size\u0026quot;, 18) .style(\u0026quot;font-weight\u0026quot;, 400) }) .on('mouseout', tool_tip.hide)  What\u0026rsquo;s happening here? Let\u0026rsquo;s look at one piece at a time.\nFirst, we define the object and name it tipSVG. tipSVG selects #tipDiv (defined in our d3-tip) and appends an SVG. We also define the width and height of the tooltip.\nvar tipSVG = d3.select(\u0026quot;#tipDiv\u0026quot;) .append(\u0026quot;svg\u0026quot;) .attr(\u0026quot;width\u0026quot;, 220) .attr(\u0026quot;height\u0026quot;, 55);  Next, we append a path to that SVG. This could be a circle, or a rectangle, or any other appendable shape. Because I am drawing a simple line, we use path.\ntipSVG.append(\u0026quot;path\u0026quot;) .datum(overdoses.filter(function(d) {return nameById[d.id] == current_state})) .style(\u0026quot;stroke\u0026quot;, function() { if (rateById[d.id] \u0026lt; 10) { return \u0026quot;grey\u0026quot; } else { return color(rateById[d.id]) } }) .style(\u0026quot;stroke-width\u0026quot;, 1.5) .style(\u0026quot;fill\u0026quot;, \u0026quot;none\u0026quot;) .attr(\u0026quot;d\u0026quot;, line)  In defining the d attribute, you see I use the phrase line. This is defined earlier in my code to return the x and y position of each data point, to create the path itself.\nvar x_tooltip = d3.scaleLinear() .domain(d3.extent(overdoses, function(d) { return d.year; })) .range([ 0, 130 ]); var y_tooltip = d3.scaleLinear() .domain([0, 60]) .range([ 50, 0 ]); var line = d3.line() .x(function(d) { return x_tooltip(d.year); }) .y(function(d) { return y_tooltip(+d.rate); })  Lastly, we add a circle at the end of the line to signify the final data point. We also add the text label for the year 2017.\ntipSVG.append(\u0026quot;circle\u0026quot;) .attr(\u0026quot;fill\u0026quot;, function() { if (rateById[d.id] \u0026lt; 10) { return \u0026quot;grey\u0026quot; } else { return color(rateById[d.id]) } }) .attr(\u0026quot;stroke\u0026quot;, \u0026quot;black\u0026quot;) .attr(\u0026quot;cx\u0026quot;, 130) .attr(\u0026quot;cy\u0026quot;, y_tooltip(rateById[d.id])) .attr(\u0026quot;r\u0026quot;, 3) tipSVG.append(\u0026quot;text\u0026quot;) .text(rateById[d.id] + \u0026quot; deaths\u0026quot;) .attr(\u0026quot;x\u0026quot;, 140) .attr(\u0026quot;y\u0026quot;, function() { if (y_tooltip(rateById[d.id]) \u0026lt; 15) { return 10 } else { return y_tooltip(rateById[d.id]) - 7 } }) tipSVG.append(\u0026quot;text\u0026quot;) .text(\u0026quot;per 100,000\u0026quot;) .attr(\u0026quot;x\u0026quot;, 140) .attr(\u0026quot;y\u0026quot;, function() { if (y_tooltip(rateById[d.id]) \u0026lt; 15) { return 24 } else { return y_tooltip(rateById[d.id]) + 7 } }) tipSVG.append(\u0026quot;text\u0026quot;) .text(current_state) .attr(\u0026quot;x\u0026quot;, 0) .attr(\u0026quot;y\u0026quot;, 15) .style(\u0026quot;font-size\u0026quot;, 18) .style(\u0026quot;font-weight\u0026quot;, 400) })  And finally, we hide the tooltip on mouseout:\n.on('mouseout', tool_tip.hide)  Thanks for reading! You can play around with the visualization and checkout the tooltip for yourself here (find the fullscreen version here):\n    @import url('https://rsms.me/inter/inter.css'); html { font-family: 'Inter', sans-serif; } @supports (font-variation-settings: normal) { html { font-family: 'Inter var', sans-serif; } } .states :hover { stroke: white; stroke-width: 8px; } .year.label { font: 300 2.5em \"Inter\"; fill: gray; } .helper.label { font: 150 1em \"Inter\"; fill: gray; } .overlay { fill: none; pointer-events: all; cursor: ew-resize; } .caption { font: 150 1.1em \"Inter\"; } .d3-tip { padding-right: 6px; padding-left: 6px; padding-bottom: 6px; padding-top: 0; background: #fff; border: 1px solid black; font-size: 12px; pointer-events: none !important; } /* .my_chart { width: 90%; padding-left: 15%; padding-right: 10%; } */        /* This viz was made a lot easier thanks to the following code: * animation using TweenYear http://bl.ocks.org/jgujgu/bfbb41f5e8b90ff09d7805f71ef2538e * choropleth map of us states (using json fips state ids) https://bl.ocks.org/chucklam/f628765b873d707a3d0e44ffc78deab8 * another choropleth; although I didn't end up following its structure it was a helpful introduction https://bl.ocks.org/wboykinm/dbbe50d1023f90d4e241712395c27fb3 A special thanks to Robert Hosbach for his viz here (and his willingness to respond to my email!): https://rahosbach.github.io/2018-10-27-d3UnemploymentChoropleth/ */ var svg = d3.select(\"svg\") .attr(\"class\", \"my_chart\") // resize plot when window is resized (see below) .call(responsivefy); var path = d3.geoPath(); var format = d3.format(\"\"); var height = 600; var width = 960; // thanks to https://brendansudol.com/writing/responsive-d3 for this function! function responsivefy(svg) { // container will be the DOM element // that the svg is appended to // we then measure the container // and find its aspect ratio const container = d3.select(svg.node().parentNode), width = parseInt(svg.style('width'), 10), height = parseInt(svg.style('height'), 10), aspect = width / height; // set viewBox attribute to the initial size // control scaling with preserveAspectRatio // resize svg on inital page load svg.attr('viewBox', `0 0 ${width} ${height}`) .attr('preserveAspectRatio', 'xMinYMid') .call(resize); // add a listener so the chart will be resized // when the window resizes // multiple listeners for the same event type // requires a namespace, i.e., 'click.foo' // api docs: https://goo.gl/F3ZCFr d3.select(window).on( 'resize.' + container.attr('id'), resize ); // this is the code that resizes the chart // it will be called on load // and in response to window resizes // gets the width of the container // and resizes the svg to fill it // while maintaining a consistent aspect ratio function resize() { const w = parseInt(container.style('width')); svg.attr('width', w); svg.attr('height', Math.round(w / aspect)); } } // options for color scheme: https://github.com/d3/d3-scale-chromatic var colorScheme = d3.schemeReds[9]; colorScheme.unshift(\"#eee\"); // building the legend at the top var color = d3.scaleQuantize() .domain([0, 50]) .range(colorScheme); var x = d3.scaleLinear() .domain(d3.extent(color.domain())) // the range specifies the x position of the legend .rangeRound([600,860]); var g = svg.append(\"g\") .attr(\"transform\", \"translate(0,40)\"); // legend boxes g.selectAll(\"rect\") .data(color.range().map(function(d){ return color.invertExtent(d); })) .enter() .append(\"rect\") .attr(\"height\", 8) .attr(\"x\", function(d){ return x(d[0]); }) .attr(\"width\", function(d){ return x(d[1]) - x(d[0]); }) .attr(\"fill\", function(d){ return color(d[0]); }); // legend title g.append(\"text\") .attr(\"class\", \"caption\") .attr(\"x\", x.range()[0]) .attr(\"y\", -6) .attr(\"fill\", \"#000\") .attr(\"text-anchor\", \"start\") .attr(\"font-weight\", 30) .text(\"Overdose Death Rate (Per 100,000)\"); // legend ticks g.call(d3.axisBottom(x) .tickSize(13) .tickFormat(format) .tickValues(color.range().slice(1).map(function(d){ return color.invertExtent(d)[0]; }))) .select(\".domain\") .remove(); // create tooltip var div = d3.select(\"body\") .append(\"div\") .attr(\"class\", \"tooltip\") .style(\"opacity\", 0); // label positions labely = height - 50 labelx = width - 280 // Add the year label; the value is set on transition. var label = svg.append(\"text\") .attr(\"class\", \"year label\") .attr(\"text-anchor\", \"middle\") // position the label .attr(\"y\", labely) .attr(\"x\", labelx) .text(1999); var helperlabel = svg.append(\"text\") .attr(\"class\", \"helper label\") .attr(\"text-anchor\", \"middle\") // position the label .attr(\"y\", labely + 20) .attr(\"x\", labelx) .text(\"Hover to change year\"); queue() // read in JSON which includes all of the complicated shape data for states/counties/etc. .defer(d3.json, \"https://d3js.org/us-10m.v1.json\") // read in opioid data .defer(d3.csv, \"figures/overdoses.csv\") /* NOTE ON OVERDOSE DATA: This CSV file was created via pulling data from CDC's WONDER database. I pulled all deaths from the National Vital Statistics System's multiple cause-of-death mortality files which had one of the following causes of death: opioids (T40.0, T40.1, T40.2, T40.3, T40.4, or T40.6)**; natural/semisynthetic opioids (T40.2); methadone (T40.3); heroin (T40.1); synthetic opioids other than methadone (T40.4); cocaine (T40.5). I followed the methodology of this paper: https://www.cdc.gov/mmwr/volumes/67/wr/mm675152e1.htm?s_cid=mm675152e1_w. Deaths may include multiple opioids as a cause and thus are not mutually exclusive. You can replicate the data pull on CDC WONDER with this link: https://wonder.cdc.gov/mcd-icd10.html Source: Multiple Cause of Death 1999–2017 on CDC Wide-ranging Online Data for Epidemiologic Research (CDC WONDER). Atlanta, GA: CDC, National Center for Health Statistics. 2018. Available at http://wonder.cdc.gov. */ .await(ready); function ready(error, us, overdoses) { if (error) throw error; // Initialize data to 1990 var currentYear = 1999; var rateById = {}; var nameById = {}; // var yearById = {}; //console.table(overdoses) overdoses.forEach(function(d){ rateById[d.id] = +d.rate; nameById[d.id] = d.state; d.year = d.year; }); console.table(overdoses) // Add an overlay for the year label. var box = label.node().getBBox(); var overlay = svg.append(\"rect\") .attr(\"class\", \"overlay\") .attr(\"x\", box.x) .attr(\"y\", box.y) .attr(\"width\", box.width) .attr(\"height\", box.height) .on(\"mouseover\", enableInteraction); var x_tooltip = d3.scaleLinear() .domain(d3.extent(overdoses, function(d) { return d.year; })) .range([ 0, 130 ]); var y_tooltip = d3.scaleLinear() .domain([0, 60]) .range([ 50, 0 ]); // define line function var line = d3.line() .x(function(d) { return x_tooltip(d.year); }) .y(function(d) { return y_tooltip(+d.rate); }) var tool_tip = d3.tip() .attr(\"class\", \"d3-tip\") // if the mouse position is greater than 650 (~ Kentucky/Missouri), // offset tooltip to the left instead of the right // credit https://stackoverflow.com/questions/28536367/in-d3-js-how-to-adjust-tooltip-up-and-down-based-on-the-screen-position .offset(function() {if(current_position[0]  650) { return [-20,-120] } else { return [20,120]} }) .html( \"Opioid-involved deaths over time in\n\" ); svg.call(tool_tip); // Start a transition that interpolates the data based on year. svg.transition() .duration(10000) .ease(d3.easeLinear) .tween(\"year\", tweenYear); states = svg.append(\"g\") .attr(\"class\", \"states\") .selectAll(\"path\") .data(topojson.feature(us, us.objects.states).features) .enter() .append(\"path\") .attr(\"d\", path) // appending svg inside of tooltip for year by year change. // h/t https://bl.ocks.org/maelafifi/ee7fecf90bb5060d5f9a7551271f4397 // h/t https://stackoverflow.com/questions/43904643/add-chart-to-tooltip-in-d3 .on('mouseover', function(d) { // define and store the mouse position. this is used to define // tooltip offset, seen above. current_position = d3.mouse(this); //console.log(current_position[0]) current_state = nameById[d.id] tool_tip.show(); var tipSVG = d3.select(\"#tipDiv\") .append(\"svg\") .attr(\"width\", 220) .attr(\"height\", 55); tipSVG.append(\"path\") .datum(overdoses.filter(function(d) {return nameById[d.id] == current_state})) .style(\"stroke\", function() { if (rateById[d.id] State: ' + nameById[d.id] + // '\n' + // ' Year: ' + Math.round(currentYear) + // '\n' + // ' Rate: ' + rateById[d.id] + \" per 100,000\") // .style(\"left\", (d3.event.pageX) + \"px\") // .style(\"top\", (d3.event.pageY - 28) + \"px\");}) // // remove tooltip on mouse out // .on(\"mouseout\", function(d) { // div.transition() // .duration(500) // .style(\"opacity\", 0);}); // create the actual state objects svg.append(\"path\") .datum(topojson.mesh(us, us.objects.states, (a, b) = a !== b)) .attr(\"fill\", \"none\") .attr(\"stroke\", \"white\") // .attr(\"stroke-linejoin\", \"round\") .attr(\"d\", path) } // after the transition finishes, mouseover to change year. function enableInteraction() { var yearScale = d3.scaleLinear() .domain([1999, 2017]) .range([box.x + 10, box.x + box.width - 10]) .clamp(true); // Cancel the current transition, if any. svg.transition().duration(0); overlay .on(\"mouseover\", mouseover) .on(\"mouseout\", mouseout) .on(\"mousemove\", mousemove) .on(\"touchmove\", mousemove); function mouseover() { label.classed(\"active\", true); } function mouseout() { label.classed(\"active\", false); } function mousemove() { displayYear(yearScale.invert(d3.mouse(this)[0])); } } // Tweens the entire chart by first tweening the year, and then the data. // For the interpolated data, the dots and label are redrawn. function tweenYear() { var year = d3.interpolateNumber(1999, 2017); return function(t) { displayYear(year(t)); }; } // Updates the display to show the specified year. function displayYear(year) { currentYear = year; states.call(style,year) label.text(Math.round(year)); } // Interpolates the dataset for the given (fractional) year. function interpolateData(year) { return overdoses.filter(function(row) { return row['year'] == Math.round(year); }); } };  ","date":1578096000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"7ce30a726db4a9a053c015e72de29d9f","permalink":"/post/adding-a-chart-to-your-d3-tooltip/","publishdate":"2020-01-04T00:00:00Z","relpermalink":"/post/adding-a-chart-to-your-d3-tooltip/","section":"post","summary":"A few lines of code can make your D3 tooltips signficantly more informative.","tags":["D3.js","visualization","interactive","tooltips"],"title":"How (and Why) to Add a Chart to Your D3.js Tooltip","type":"post"},{"authors":["Connor Rothschild"],"categories":["R","D3.js"],"content":"      This project explores the relationships between different characters in the classic TV show The Office. Using transcript data newly released in Bradley H. Lindblad’s schrute package, I’d like to see who mentions who in the Office. Is one character more popular than the others?\nlibrary(schrute) library(tidyverse) library(cr) set_cr_theme() Let’s take a look at the transcripts:\ntranscripts \u0026lt;- schrute::theoffice knitr::kable(transcripts[1:3,])   index season episode episode_name director writer character text text_w_direction imdb_rating total_votes air_date    1 1 1 Pilot Ken Kwapis Ricky Gervais;Stephen Merchant;Greg Daniels Michael All right Jim. Your quarterlies look very good. How are things at the library? All right Jim. Your quarterlies look very good. How are things at the library? 7.6 3706 2005-03-24  2 1 1 Pilot Ken Kwapis Ricky Gervais;Stephen Merchant;Greg Daniels Jim Oh, I told you. I couldn’t close it. So… Oh, I told you. I couldn’t close it. So… 7.6 3706 2005-03-24  3 1 1 Pilot Ken Kwapis Ricky Gervais;Stephen Merchant;Greg Daniels Michael So you’ve come to the master for guidance? Is this what you’re saying, grasshopper? So you’ve come to the master for guidance? Is this what you’re saying, grasshopper? 7.6 3706 2005-03-24    By using tidytext, we can split the transcripts into their constituent parts (words).\ntranscripts_tokenized \u0026lt;- transcripts %\u0026gt;% tidytext::unnest_tokens(word, text) knitr::kable(transcripts_tokenized[1:3,])   index season episode episode_name director writer character text_w_direction imdb_rating total_votes air_date word    1 1 1 Pilot Ken Kwapis Ricky Gervais;Stephen Merchant;Greg Daniels Michael All right Jim. Your quarterlies look very good. How are things at the library? 7.6 3706 2005-03-24 all  1 1 1 Pilot Ken Kwapis Ricky Gervais;Stephen Merchant;Greg Daniels Michael All right Jim. Your quarterlies look very good. How are things at the library? 7.6 3706 2005-03-24 right  1 1 1 Pilot Ken Kwapis Ricky Gervais;Stephen Merchant;Greg Daniels Michael All right Jim. Your quarterlies look very good. How are things at the library? 7.6 3706 2005-03-24 jim    We can now use the text to see who mentions who. But first, let’s construct a vector with a list of characters to keep in the analysis. There are 485 characters in the transcripts, so its important we filter only those of relevance:\nkeep_characters \u0026lt;- transcripts %\u0026gt;% group_by(character) %\u0026gt;% count() %\u0026gt;% arrange(desc(n)) %\u0026gt;% head(9) %\u0026gt;% pull(character) knitr::kable(keep_characters)   x    Michael  Dwight  Jim  Pam  Andy  Angela  Kevin  Erin  Oscar    This is an optional decision. One may be interested in seeing which characters talk about Jim most, including those characters who are otherwise less relevant. I decide to filter according to the main cast so that comparisons between characters (e.g., through a chord diagram) is feasible.\nWho Mentions Who? Jim: A Case Study Who is talking to who in the Office?\nNow that we have keep_characters, we can filter according to it and spit out who mentions who among the most relevant Office characters.\ntranscripts_tokenized %\u0026gt;% filter(character %in% keep_characters) %\u0026gt;% mutate(jim = ifelse(word == \u0026quot;jim\u0026quot;, 1, 0)) %\u0026gt;% group_by(character) %\u0026gt;% summarise(jim = sum(jim)) %\u0026gt;% arrange(desc(jim)) %\u0026gt;% mutate(character = reorder(character, jim)) %\u0026gt;% ggplot(ggplot2::aes(character, jim)) + geom_col() + coord_flip() + fix_bars() + labs(title = \u0026quot;Who Mentions Jim?\u0026quot;, subtitle = \u0026quot;Counts of \u0026#39;Jim\u0026#39; in The Office Transcripts\u0026quot;, x = element_blank(), y = \u0026quot;Mentions\u0026quot;) The takeaway here is that Dwight mentions Jim the most, followed by Michael. No surprise there! What I find interesting is that only three characters really talk about/to Jim. After Dwight, Michael, and Pam (and Jim referencing himself, apparently), the mention rate for Jim’s name drops from over 200 to only 60 mentions. It seems as if the writers of the Office intentionally made Jim a subject of conversation among only a few characters!\n Replicate for the rest of the cast Next, we replicate that process for the rest of the cast. There is probably a better way to do this.\ndata_chord \u0026lt;- transcripts_tokenized %\u0026gt;% filter(character %in% keep_characters) %\u0026gt;% mutate(jim = ifelse(word == \u0026quot;jim\u0026quot;, 1, 0)) %\u0026gt;% mutate(michael = ifelse(word == \u0026quot;michael\u0026quot;, 1, 0)) %\u0026gt;% mutate(dwight = ifelse(word == \u0026quot;dwight\u0026quot;, 1, 0)) %\u0026gt;% mutate(pam = ifelse(word == \u0026quot;pam\u0026quot;, 1, 0)) %\u0026gt;% mutate(andy = ifelse(word == \u0026quot;andy\u0026quot;, 1, 0)) %\u0026gt;% mutate(angela = ifelse(word == \u0026quot;angela\u0026quot;, 1, 0)) %\u0026gt;% mutate(kevin = ifelse(word == \u0026quot;kevin\u0026quot;, 1, 0)) %\u0026gt;% mutate(erin = ifelse(word == \u0026quot;erin\u0026quot;, 1, 0)) %\u0026gt;% mutate(oscar = ifelse(word == \u0026quot;oscar\u0026quot;, 1, 0)) %\u0026gt;% # mutate(ryan = ifelse(word == \u0026quot;ryan\u0026quot;, 1, 0)) %\u0026gt;% # mutate(darryl = ifelse(word == \u0026quot;darryl\u0026quot;, 1, 0)) %\u0026gt;% # mutate(phyllis = ifelse(word == \u0026quot;phyllis\u0026quot;, 1, 0)) %\u0026gt;% # mutate(kelly = ifelse(word == \u0026quot;kelly\u0026quot;, 1, 0)) %\u0026gt;% # mutate(toby = ifelse(word == \u0026quot;toby\u0026quot;, 1, 0)) %\u0026gt;% group_by(character) %\u0026gt;% summarise_at(vars(jim:oscar), funs(sum))   Visualize Now, let’s make a chord diagram!\nWe first have to convert the data frame into a format chordDiagram will recognize.\ncirclize_data \u0026lt;- as.data.frame(data_chord) %\u0026gt;% pivot_longer(jim:oscar, names_to = \u0026quot;to\u0026quot;, values_to = \u0026quot;value\u0026quot;) %\u0026gt;% rename(from = \u0026#39;character\u0026#39;) %\u0026gt;% mutate(to = str_to_title(to)) This process pivots each row of data into a value-key combination, so that the data looks like this:\n  from to value    Andy Jim 48  Andy Michael 40  Andy Dwight 80  Andy Pam 34  Andy Andy 42  Andy Angela 33    Using that data, we can create a chord diagram quite easily, using a single command from the circlize library. This chapter is helpful.\nlibrary(circlize) chordDiagram(circlize_data, grid.col = c(\u0026quot;#B997C7\u0026quot;, \u0026quot;#824D99\u0026quot;, \u0026quot;#4E78C4\u0026quot;, \u0026quot;#57A2AC\u0026quot;, \u0026quot;#7EB875\u0026quot;, \u0026quot;#D0B541\u0026quot;, \u0026quot;#E67F33\u0026quot;, \u0026quot;#CE2220\u0026quot;, \u0026quot;#521A13\u0026quot;)) Make It Interactive With nine people, some of the data can get easily concealed (how often did Angela mention Michael’s name?). One way to fix this is to make the visualization interactive, so that a user can hover over chords to see relationships between characters.\nFirst, we conduct some data cleaning. I found that the rownames and column names have to be of the same order; let’s do a little manipulation to get there:\nint_chord \u0026lt;- as.data.frame(data_chord) rownames(int_chord) \u0026lt;- int_chord$character row.order \u0026lt;- c(\u0026quot;Jim\u0026quot;, \u0026quot;Michael\u0026quot;, \u0026quot;Dwight\u0026quot;, \u0026quot;Pam\u0026quot;, \u0026quot;Andy\u0026quot;, \u0026quot;Angela\u0026quot;, \u0026quot;Kevin\u0026quot;, \u0026quot;Erin\u0026quot;, \u0026quot;Oscar\u0026quot;) #, \u0026quot;Ryan\u0026quot;, \u0026quot;Darryl\u0026quot;, \u0026quot;Phyllis\u0026quot;, \u0026quot;Kelly\u0026quot;, \u0026quot;Toby\u0026quot;) int_chord \u0026lt;- int_chord[row.order,] Next, we load Matt Flor’s chorddiag package, and construct a matrix according to its function’s liking:\n# devtools::install_github(\u0026quot;mattflor/chorddiag\u0026quot;) library(chorddiag) m \u0026lt;- as.matrix(int_chord[-1]) dimnames(m) \u0026lt;- list(have = int_chord$character, prefer = str_to_title(colnames(int_chord[-1]))) Finally, we add a color palette and construct the diagram.\ngroupColors \u0026lt;- c(\u0026quot;#B997C7\u0026quot;, \u0026quot;#824D99\u0026quot;, \u0026quot;#4E78C4\u0026quot;, \u0026quot;#57A2AC\u0026quot;, \u0026quot;#7EB875\u0026quot;, \u0026quot;#D0B541\u0026quot;, \u0026quot;#E67F33\u0026quot;, \u0026quot;#CE2220\u0026quot;, \u0026quot;#521A13\u0026quot;) p \u0026lt;- chorddiag(m, groupColors = groupColors, groupnamePadding = 35, tickInterval = 50, groupnameFontsize = 12) p  {\"x\":{\"matrix\":[[47,181,258,189,53,18,19,3,14],[227,171,353,327,66,48,95,44,100],[294,282,106,104,61,59,41,21,29],[182,262,126,58,35,44,34,17,26],[48,40,80,34,42,33,20,78,19],[11,28,81,31,23,10,40,2,26],[39,71,12,39,19,22,23,7,36],[12,37,23,28,92,9,4,15,5],[16,65,22,22,29,37,34,9,6]],\"options\":{\"type\":\"directional\",\"width\":null,\"height\":null,\"margin\":100,\"showGroupnames\":true,\"groupNames\":[\"Jim\",\"Michael\",\"Dwight\",\"Pam\",\"Andy\",\"Angela\",\"Kevin\",\"Erin\",\"Oscar\"],\"groupColors\":[\"#B997C7\",\"#824D99\",\"#4E78C4\",\"#57A2AC\",\"#7EB875\",\"#D0B541\",\"#E67F33\",\"#CE2220\",\"#521A13\"],\"groupThickness\":0.1,\"groupPadding\":0.0349065850398866,\"groupnamePadding\":[35,35,35,35,35,35,35,35,35],\"groupnameFontsize\":12,\"groupedgeColor\":null,\"chordedgeColor\":\"#808080\",\"categoryNames\":null,\"categorynamePadding\":100,\"categorynameFontsize\":28,\"showTicks\":true,\"tickInterval\":50,\"ticklabelFontsize\":10,\"fadeLevel\":0.1,\"showTooltips\":true,\"showZeroTooltips\":true,\"tooltipNames\":[\"Jim\",\"Michael\",\"Dwight\",\"Pam\",\"Andy\",\"Angela\",\"Kevin\",\"Erin\",\"Oscar\"],\"tooltipFontsize\":12,\"tooltipUnit\":\"\",\"tooltipGroupConnector\":\" \u0026#x25B6; \",\"precision\":\"null\",\"clickAction\":null,\"clickGroupAction\":null}},\"evals\":[],\"jsHooks\":[]} # save the widget # library(htmlwidgets) # saveWidget(p, file=\u0026quot;chord_interactive.html\u0026quot;) Play around with the diagram here!\n  ","date":1576454400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"318b3ac8a1442d6c4d98216712445f2c","permalink":"/post/who-mentions-who-in-the-office/","publishdate":"2019-12-16T00:00:00Z","relpermalink":"/post/who-mentions-who-in-the-office/","section":"post","summary":"Who is the most popular character in the Office?","tags":["r","visualization","D3.js","interactive"],"title":"Who Mentions Who in the Office?","type":"post"},{"authors":["Connor Rothschild"],"categories":["R"],"content":" This weeks’s installment of Tidy Tuesday is all about replicating professional plots in R. Inspired by Rafael Irizarry’s post “You can replicate almost any plot with R”, the goal is to take otherwise professional publication-ready plots and make them in R (usually ggplot2).\nI was interested in this Tidy Tuesday because some of my past work has been dedicated to creating publication-ready plots. Because the first visualization I ever created was inspired by (a replication of?) this visualization from Bloomberg graphics, I decided to set out on a journey to make that plot as close as possible to the real thing.\nThe real goal of this week’s Tidy Tuesday is using the data that Rafael posted to create other cool visualizations; I took a slightly different approach to try to recreate another visualization entirely. What follows is an interactive recreation of the visualization above, using Shiny and plotly.\nlibrary(ggplot2) library(ggthemes) library(dplyr) library(ggrepel) library(tools) library(readxl) library(tidyverse) library(knitr) library(shiny) library(plotly) theme_set(theme_minimal()) Load and Clean Data First, we read in the data. This process was a bit complicated as I kind of had to guess where Bloomberg pulled their data from.\nI relied on three datasets:\nEducational attainment broke down by occupation, provided by BLS here\n Salaries, median hourly/annual wages broke down by occupation, provided by BLS here\n Risk of automation broken down by occupation, provided by Carl Benedikt Frey and Michael A. Osborne (but compiled here)\n  education \u0026lt;- read_excel(\u0026quot;data/education.xlsx\u0026quot;, skip=1) salary \u0026lt;- read_excel(\u0026quot;data/national_M2017_dl.xlsx\u0026quot;) automation \u0026lt;- read_excel(\u0026quot;data/raw_state_automation_data.xlsx\u0026quot;) In another post, I detail the data cleaning process. I’ll spare you the details here.\n Create the UI Now we create the UI, as is the case for any Shiny app. This is pretty simple: first, we add the title panel and beautify it with some CSS.\nui \u0026lt;- fluidPage( titlePanel( h1(\u0026quot;A College Degree Lowers Job Automation Risk\u0026quot;, style = \u0026quot;font-family: \u0026#39;Helvetica Neue\u0026#39;; font-size: 20px; font-weight: 400; line-height: 1.1;\u0026quot;), windowTitle = \u0026quot;Find Out If Your Job Will Be Automated\u0026quot; ), Next, we add the main panel, which includes a) the plot object, b) the footnote, and c) some CSS.\nmainPanel( fluidRow( div( plotlyOutput(\u0026quot;plot\u0026quot;, height = \u0026#39;600px\u0026#39;, width = \u0026#39;850px\u0026#39;) ),align=\u0026quot;left\u0026quot;), p(\u0026quot;DATA: FREY \u0026amp; OSBORNE, BUREAU OF LABOR STATISTICS\u0026quot;, style = \u0026quot;font-family: \u0026#39;Helvetica Neue\u0026#39;; font-size: 8px; font-weight: 500; line-height: 1.1;\u0026quot;) ) ) That’s it!\n Server Now we can define the server() function, where the real magic of this visualization happens.\nAll of the following takes place in the server \u0026lt;- function(input, output, session) {} function.\nCreate a ggplot Object We know we’re going to need a ggplot object. In my case, we’ll need a plot object which relies on probability, median income, and risk of automation.\nggplot(aes(x=probability, y=A_MEDIAN, size=TOT_EMP, fill=typicaled, text = text)) + geom_point(color = \u0026quot;black\u0026quot;, alpha = .97, stroke = .1) + scale_size(range = c(1, 10), guide = \u0026#39;legend\u0026#39;) This creates the base of the object.\nAdd a Tooltip We also know that, like the Bloomberg visualization we’re replicating, we’re going to want a tooltip.\nThat’s why we included text in the above code, which we define here:\ndata %\u0026gt;% mutate(text = glue::glue(\u0026#39;\u0026lt;span style=\u0026quot;font-size:16px;font-weight:bold\u0026quot;\u0026gt;{data$occupation}\u0026lt;/span\u0026gt;\u0026#39;, \u0026#39;\\n\u0026lt;b\u0026gt;Number employed:\u0026lt;/b\u0026gt; {scales::comma(data$TOT_EMP)}\u0026#39;, \u0026#39;\\n\u0026lt;b\u0026gt;Computerization prob:\u0026lt;/b\u0026gt; {data$probability}%\u0026#39;, \u0026#39;\\n\u0026lt;b\u0026gt;Education:\u0026lt;/b\u0026gt; {data$typicaled}\u0026#39;, sep = \u0026quot;\\n\u0026quot;)) This tooltip takes in some CSS, some HTML, and creates a pretty tooltip! The glue function is lovely.\n Axes and Labels The Bloomberg visualization is unique in that it has no axis lines. We can replicate that in ggplot2 via the following code:\ntheme(axis.line.x = ggplot2::element_blank(), axis.line.y = ggplot2::element_blank(), axis.text = element_text(colour = \u0026quot;black\u0026quot;, size = 8)) But that’s not all!\nThe Bloomberg visualization is also unique in that it doesn’t have axis titles. Moreover, the axis labels are a bit unique; the x axis increases sequentially by 10 until 90 where it transitions into ‘90%’ (the % is not present in the earlier numbers).\nWe can mimic that kind of styling with this code:\nxlab(\u0026quot;\u0026quot;) + ylab(\u0026quot;\u0026quot;) + labs(size= \u0026quot;\u0026quot;, alpha = \u0026quot;\u0026quot;, fill = \u0026quot;\u0026quot;) + scale_y_continuous(limits = c(-1000,240000), breaks = c(20000, 40000, 60000, 80000, 100000, 120000, 140000, 160000, 180000, 200000, 220000), labels = c(\u0026quot;20K\u0026quot;, \u0026quot;40K\u0026quot;, \u0026quot;60K\u0026quot;, \u0026quot;80K\u0026quot;, \u0026quot;100K\u0026quot;, \u0026quot;120K\u0026quot;, \u0026quot;140K\u0026quot;, \u0026quot;160K\u0026quot;, \u0026quot;180K\u0026quot;, \u0026quot;200K\u0026quot;, \u0026quot;220K\u0026quot;)) + scale_x_continuous(limits = c(0,100), breaks = c(10,20,30,40,50,60,70,80,90), labels = c(10,20,30,40,50,60,70,80,\u0026quot;90%\u0026quot;)) We create a bit of a buffer on the limits argument so that we can add annotations. We’ll get to that later!\n Colors To get as close as possible to Bloomberg’s plot, I’d also like to mimic their color scheme. I pulled the colors from their dotplot with this awesome Chrome plugin; then, I added them to R with the following:\ncols \u0026lt;- c(\u0026#39;No formal educational credential\u0026#39; = \u0026#39;#FA1A48\u0026#39;,\u0026#39;High school diploma or equivalent\u0026#39; = \u0026#39;#F79734\u0026#39;, \u0026quot;Postsecondary nondegree award\u0026quot; = \u0026#39;#FDFF1C\u0026#39;, \u0026quot;Associate\u0026#39;s degree\u0026quot; = \u0026#39;#1DDF50\u0026#39;, \u0026quot;Bachelor\u0026#39;s degree\u0026quot; = \u0026#39;#34D19D\u0026#39;, \u0026quot;Master\u0026#39;s degree\u0026quot; = \u0026#39;#1BC0E9\u0026#39;, \u0026quot;Doctoral or professional degree\u0026quot; = \u0026#39;#1B91FF\u0026#39;)  In the plot object, we reference this with the following:\nscale_fill_manual(values = cols, labels = c(\u0026#39;No formal educational credential\u0026#39;, \u0026#39;High school diploma or equivalent\u0026#39;, \u0026quot;Some college, no degree\u0026quot;, \u0026quot;Associate\u0026#39;s degree\u0026quot;, \u0026quot;Postsecondary nondegree award\u0026quot;, \u0026quot;Bachelor\u0026#39;s degree\u0026quot;, \u0026quot;Master\u0026#39;s degree\u0026quot;, \u0026quot;Doctoral or professional degree\u0026quot;)) This essentially creates a fill scale (manually) with specified hex codes for colors. I also tried to manipulate the order of the legend but that didn’t translate to plotly (a documented problem, I believe).\n Final Touches for the ggplot Finally, we do something really hacky: add a regression line with geom_segment. (I’m so sorry, R gods.)\ngeom_segment(aes(x = 0, y = 54000, xend = 100, yend = 58000), size = .1)  We now have the ggplot object created; let’s convert it to a plotly object.\n  Create a plotly Object This process relies on the ggplotly function, which reads in a previously defined ggplot object and converts into an interactive plotly one.\nintroPlot \u0026lt;- ggplotly(introggPlot, tooltip = \u0026#39;text\u0026#39;, sort = FALSE) After creating the base plotly object, we move to some more complicated steps:\nLegend Orientation We’d like the legend to orient horizontally, right above the plot. We do that with the following (inside the layout function):\nlegend = list(orientation = \u0026quot;h\u0026quot;, xanchor = \u0026quot;left\u0026quot;, x = 0, y = 100, traceorder = \u0026quot;normal\u0026quot;, itemsizing = \u0026quot;constant\u0026quot;, tracegroupgap = 0, font = list(size = 13)) This does a few things. First, it orients the legend horizontally. Second, it anchors the legend to the left. Third, it defines the location (using x-y pairs) of the legend. traceorder is meant to maintain the previous order from ggplot, but that didn’t work in my version. itemsizing is meant to keep the legend items with a constant size, as opposed to dynamic relative to the plot objects themselves. This also didn’t work. The last two arguments define the spacing between points and the font size of the legend text!\n Axes Revisited We also see the Bloomberg viz has a right-aligned Y-axis. We can add that to plotly via the following code:\nyaxis = list( tickfont = element_blank(), overlaying = \u0026quot;y\u0026quot;, side = \u0026quot;right\u0026quot;, title = \u0026quot;\u0026quot; )  Some Aesthetic Changes Finally, we add three commands to the layout function.\nfont = list(family = \u0026#39;Helvetica Neue\u0026#39;, color = \u0026quot;black\u0026quot;), margin = list(r=1, l=1,t=1,b=1,pad = 0), hoverlabel = list(bgcolor = \u0026#39;white\u0026#39;, color = \u0026#39;black\u0026#39;) This a) changes the font of the plot, b) adds a small margin, and c) stylizes the tooltip on hover.\n Annotations The last step is to mimic Bloomberg’s annotations. This is a little tough, specifically because it requires pretty specific x- and y-values.\nFirst, we’ll add their guiding annotations (that replace axis labels) that you can find in each corner:\nadd_annotations( x = 1, y = 7500, xref = \u0026quot;x\u0026quot;, yref = \u0026quot;y\u0026quot;, text = \u0026quot;\u0026lt;b\u0026gt;Low paid,\\nleast vulnerable\u0026lt;/b\u0026gt;\u0026quot;, xanchor = \u0026#39;center\u0026#39;, align = \u0026#39;left\u0026#39;, font = list(size = 10), showarrow = F ) %\u0026gt;% add_annotations( x = 100, y = 7500, xref = \u0026quot;x\u0026quot;, yref = \u0026quot;y\u0026quot;, text = \u0026quot;\u0026lt;b\u0026gt;Low paid,\\nmost vulnerable\u0026lt;/b\u0026gt;\u0026quot;, xanchor = \u0026#39;center\u0026#39;, align = \u0026#39;right\u0026#39;, font = list(size = 10), showarrow = F ) %\u0026gt;% add_annotations( x = 1, y = 230000, xref = \u0026quot;x\u0026quot;, yref = \u0026quot;y\u0026quot;, text = \u0026quot;\u0026lt;b\u0026gt;Best paid,\\nleast vulnerable\u0026lt;/b\u0026gt;\u0026quot;, xanchor = \u0026#39;center\u0026#39;, align = \u0026#39;left\u0026#39;, font = list(size = 10), showarrow = F ) %\u0026gt;% add_annotations( x = 100, y = 230000, xref = \u0026quot;x\u0026quot;, yref = \u0026quot;y\u0026quot;, text = \u0026quot;\u0026lt;b\u0026gt;Best paid,\\nmost vulnerable\u0026lt;/b\u0026gt;\u0026quot;, xanchor = \u0026#39;center\u0026#39;, align = \u0026#39;right\u0026#39;, font = list(size = 10), showarrow = F ) Next, we add annotations for ‘most and least likely to be automated’, as well as the y axis label.\nadd_annotations( x = -5, y = -5000, xref = \u0026quot;x\u0026quot;, yref = \u0026quot;y\u0026quot;, text = glue::glue(sprintf(\u0026#39;\\u2190\u0026#39;), \u0026quot;Least likely to be automated\u0026quot;), xanchor = \u0026#39;left\u0026#39;, align = \u0026#39;left\u0026#39;, font = list(size = 10), showarrow = F ) %\u0026gt;% add_annotations( x = 105, y = -5000, xref = \u0026quot;x\u0026quot;, yref = \u0026quot;y\u0026quot;, text = glue::glue(\u0026quot;Most likely to be automated\u0026quot;, sprintf(\u0026#39;\\u2192\u0026#39;)), xanchor = \u0026#39;right\u0026#39;, align = \u0026#39;right\u0026#39;, font = list(size = 10), showarrow = F ) %\u0026gt;% add_annotations( x = 99, y = 243000, xref = \u0026quot;x\u0026quot;, yref = \u0026quot;y\u0026quot;, text = \u0026quot;Average annual wage\u0026quot;, xanchor = \u0026#39;center\u0026#39;, align = \u0026#39;right\u0026#39;, font = list(size = 10), showarrow = F ) And finally, add a couple of plot annotations which label specific points. (We are not labelling a hundred occupations like Bloomberg did.)\nadd_annotations( x = subset(data$probability, data$occupation == \u0026quot;Chief Executives\u0026quot;), y = subset(data$A_MEDIAN, data$occupation == \u0026quot;Chief Executives\u0026quot;), text = \u0026quot;Chief Executives\u0026quot;, xref = \u0026quot;x\u0026quot;, yref = \u0026quot;y\u0026quot;, xanchor = \u0026#39;center\u0026#39;, align = \u0026#39;right\u0026#39;, font = list(size = 10), showarrow = TRUE, arrowhead = 0, ax = 50, ay = 25 ) %\u0026gt;% add_annotations( x = subset(data$probability, data$occupation == \u0026quot;Cashiers\u0026quot;), y = subset(data$A_MEDIAN, data$occupation == \u0026quot;Cashiers\u0026quot;), text = \u0026quot;Cashiers\u0026quot;, xref = \u0026quot;x\u0026quot;, yref = \u0026quot;y\u0026quot;, xanchor = \u0026#39;center\u0026#39;, align = \u0026#39;right\u0026#39;, font = list(size = 10), showarrow = TRUE, arrowhead = 0, ax = 40, ay = -50 ) Finalize the plotly object with\nconfig(displaylogo = F, showSendToCloud = F, displayModeBar = F) We’re done! Run the application with the following code:\nshinyApp(ui = ui, server = server) And we’re done! Find my interactive visualization here. Find the code, uninterrupted and (hopefully) reproducible, here.\nHere’s the Bloomberg visualization:\nAnd here’s mine:\n   ","date":1575936000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"e0eee213f378003c129a41696e52886c","permalink":"/post/tidy-tuesday-replication/","publishdate":"2019-12-10T00:00:00Z","relpermalink":"/post/tidy-tuesday-replication/","section":"post","summary":"Replicating a Bloomberg Graphics scatterplot using R Shiny.","tags":["r","visualization","replication","Tidy Tuesday"],"title":"Tidy Tuesday: Replication","type":"post"},{"authors":["Connor Rothschild"],"categories":["R"],"content":" In this post, I expand upon the wonderful Christian Burkhart’s wonderful ggplot2tor tutorial on streetmap creation using ggplot2. My process differs slightly from his in that I include text using geom_label, rather than PowerPoint, to create the text annotations. (This was much more difficult!)\nlibrary(tidyverse) library(gridExtra) library(grid) library(ggplot2) library(lattice) library(osmdata) library(sf) First, per the tutorial, we load street (and river, etc). data:\nstreets \u0026lt;- getbb(\u0026quot;Springfield Missouri\u0026quot;)%\u0026gt;% opq() %\u0026gt;% add_osm_feature(key = \u0026quot;highway\u0026quot;, value = c(\u0026quot;motorway\u0026quot;, \u0026quot;primary\u0026quot;, \u0026quot;secondary\u0026quot;, \u0026quot;tertiary\u0026quot;)) %\u0026gt;% osmdata_sf() small_streets \u0026lt;- getbb(\u0026quot;Springfield Missouri\u0026quot;)%\u0026gt;% opq() %\u0026gt;% add_osm_feature(key = \u0026quot;highway\u0026quot;, value = c(\u0026quot;residential\u0026quot;, \u0026quot;living_street\u0026quot;, \u0026quot;unclassified\u0026quot;, \u0026quot;service\u0026quot;, \u0026quot;footway\u0026quot;)) %\u0026gt;% osmdata_sf() river \u0026lt;- getbb(\u0026quot;Springfield Missouri\u0026quot;)%\u0026gt;% opq() %\u0026gt;% add_osm_feature(key = \u0026quot;waterway\u0026quot;, value = \u0026quot;river\u0026quot;) %\u0026gt;% osmdata_sf() Next, we define the plot limits, using the lat-long found in the last step.\nright = -93.175 left = -93.395 bottom = 37 top = 37.275 In my plot, I’m going to create a text box to hold the city, state, and lat/long combination.\nWe can create the parameters for this box through some manipulations of the existing plot limits:\ntop_rect = (top + bottom)/2.0035 bot_rect = bottom + .01 box_height = (top_rect + bot_rect)/2 mid_box = (left + right)/2 Finally, we can create a black and white plot. This follows the same structure as the ggplot2tor tutorial:\nplot_bw \u0026lt;- ggplot() + geom_sf(data = streets$osm_lines, inherit.aes = FALSE, color = \u0026quot;#000000\u0026quot;, size = .3, alpha = .8) + geom_sf(data = small_streets$osm_lines, inherit.aes = FALSE, color = \u0026quot;#000000\u0026quot;, size = .1, alpha = .6) + geom_sf(data = river$osm_lines, inherit.aes = FALSE, color = \u0026quot;#000000\u0026quot;, size = .2, alpha = .5) + coord_sf(xlim = c(left, right), ylim = c(bottom, top), expand = FALSE) + theme_void() + theme( plot.background = element_rect(fill = \u0026quot;#FFFFFF\u0026quot;), panel.background = element_rect(fill = \u0026quot;#FFFFFF\u0026quot;), plot.margin=unit(c(0,-0.5,0,0), \u0026quot;mm\u0026quot;) ) Finally, we can introduce our text elements using geom_text (as well as borders using geom_rect).\nmap_bw \u0026lt;- plot_bw + # big box geom_rect( aes( xmax = right - .005, xmin = left + .005, ymin = bottom + .005, ymax = top - .005 ), alpha = 0, color = \u0026quot;black\u0026quot;, size = 1 ) + # smaller, label box geom_rect( aes( xmax = right - .01, xmin = left + .01, ymin = bot_rect, ymax = top_rect ), alpha = .75, color = \u0026quot;black\u0026quot;, fill = \u0026quot;white\u0026quot;, size = .6 ) + # springfield geom_text( aes(x = mid_box, y = box_height + .002, label = \u0026quot;SPRINGFIELD\\n\u0026quot;), color = \u0026quot;black\u0026quot;, family = \u0026quot;Lato\u0026quot;, fontface = \u0026quot;bold\u0026quot;, size = 9 ) + # a line that goes behind \u0026#39;Missouri\u0026#39; geom_segment(aes( x = left + .03, y = (top_rect + bottom) / 2, xend = right - .03, yend = (top_rect + bottom) / 2 ), color = \u0026quot;black\u0026quot;) + # Missouri label geom_label( aes(x = mid_box, y = box_height - .005, label = \u0026quot;MISSOURI\u0026quot;), color = \u0026quot;black\u0026quot;, fill = \u0026quot;white\u0026quot;, # alpha = .9, label.size = 0, family = \u0026quot;Lato\u0026quot;, # fontface = \u0026quot;thin\u0026quot;, size = 7 ) + # coords geom_text( aes(x = mid_box, y = box_height - .02, label = \u0026quot;37.2090° N / 93.2923° W\u0026quot;), color = \u0026quot;black\u0026quot;, family = \u0026quot;Lato\u0026quot;, size = 4 ) + # me! geom_label( aes( x = left + .035, y = top_rect + .005, label = \u0026quot;Design: Connor Rothschild\u0026quot; ), size = 1.5, color = \u0026quot;black\u0026quot;, fill = \u0026quot;white\u0026quot;, label.size = 0, family = \u0026quot;Lato\u0026quot; ) map_bw Finally, save the plot:\nggsave(map_bw, filename = \u0026quot;bw_springfield_map.png\u0026quot;, width = 3.234, height = 5.016) Replicate that code with different colors:\nplot_gold \u0026lt;- ggplot() + geom_sf( data = streets$osm_lines, inherit.aes = FALSE, color = \u0026quot;steelblue\u0026quot;, size = .3, alpha = .8 ) + geom_sf( data = small_streets$osm_lines, inherit.aes = FALSE, color = \u0026quot;#ffbe7f\u0026quot;, size = .1, alpha = .6 ) + geom_sf( data = river$osm_lines, inherit.aes = FALSE, color = \u0026quot;#ffbe7f\u0026quot;, size = .2, alpha = .5 ) + coord_sf( xlim = c(left, right), ylim = c(bottom, top), expand = FALSE ) + theme_void() + theme( plot.background = element_rect(fill = \u0026quot;#282828\u0026quot;), panel.background = element_rect(fill = \u0026quot;#282828\u0026quot;), plot.margin = unit(c(0, -0.5, 0, 0), \u0026quot;mm\u0026quot;) ) map_gold \u0026lt;- plot_gold + geom_rect( aes( xmax = right - .005, xmin = left + .005, ymin = bottom + .005, ymax = top - .005 ), alpha = 0, color = \u0026quot;white\u0026quot;, size = 1 ) + geom_rect( aes( xmax = right - .01, xmin = left + .01, ymin = bot_rect, ymax = top_rect ), alpha = .5, color = \u0026quot;#ffbe7f\u0026quot;, fill = \u0026quot;#282828\u0026quot;, size = .5 ) + geom_text( aes(x = mid_box, y = box_height + .002, label = \u0026quot;SPRINGFIELD\\n\u0026quot;), color = \u0026quot;white\u0026quot;, family = \u0026quot;Lato\u0026quot;, fontface = \u0026quot;bold\u0026quot;, size = 9 ) + geom_segment(aes( x = left + .03, y = (top_rect + bottom) / 2, xend = right - .03, yend = (top_rect + bottom) / 2 ), color = \u0026quot;#ffbe7f\u0026quot;) + geom_label( aes(x = mid_box, y = box_height - .005, label = \u0026quot;MISSOURI\u0026quot;), color = \u0026quot;white\u0026quot;, fill = \u0026quot;#282828\u0026quot;, # alpha = .9, label.size = 0, family = \u0026quot;Lato\u0026quot;, # fontface = \u0026quot;thin\u0026quot;, size = 7 ) + geom_text( aes(x = mid_box, y = box_height - .02, label = \u0026quot;37.2090° N / 93.2923° W\u0026quot;), color = \u0026quot;white\u0026quot;, family = \u0026quot;Lato\u0026quot;, size = 4 ) + geom_label( aes( x = left + .035, y = top_rect + .005, label = \u0026quot;Design: Connor Rothschild\u0026quot; ), size = 1.5, color = \u0026quot;white\u0026quot;, fill = \u0026quot;#282828\u0026quot;, label.size = 0, family = \u0026quot;Lato\u0026quot; ) map_gold ggsave(map_gold, filename = \u0026quot;gold_springfield_map.png\u0026quot;, width = 3.234, height = 5.016) ","date":1574208000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"0d9c3f6297a1bf6797b0ac78b45d6975","permalink":"/post/map-springfield/","publishdate":"2019-11-20T00:00:00Z","relpermalink":"/post/map-springfield/","section":"post","summary":"Creating a beautiful streetmap of my hometown, exclusively in R!","tags":["r","visualization"],"title":"Creating a Streetmap of Springfield, MO","type":"post"},{"authors":["Connor Rothschild"],"categories":["R"],"content":" I’ve always been interested in data visualization, and my most recent sub-passion has been scrollytelling. I’ve seen numerous examples of amazing scrolling articles, from sites such as The Pudding, the New York Times, and FiveThirtyEight.\nAlthough most of these sites rely on the same high-powered visualization tools (such as D3.js) to create their stories, the learning curve for those are a bit too steep for a full-time college student to pursue (although I am trying!).\nThankfully, I came across some examples of scrollytelling in my language of choice, R.\nWhat follows is a scrollytelling recreation of the very first visualization I ever made.\nlibrary(shiny) library(scrollytell) library(shinyjs) library(ggvis) library(plotly) theme_set(theme_minimal()) Construct an Updating Plot Object Once the data (which can be found here) is already loaded and cleaned, we construct a plot object that will update as the user scrolls. (Other R users make multiple plots; either way is fine.)\nplot \u0026lt;- data %\u0026gt;% filter(if (add != 8) add \u0026gt;= reveal else reveal %in% c(1:8)) %\u0026gt;% ggplot() + geom_point(mapping=aes(x=A_MEDIAN, y=probability, size=TOT_EMP, alpha=ifelse(add == reveal, 1/5, 1/10), col=typicaled, text = glue::glue(\u0026#39;\u0026lt;b\u0026gt;Occupation\u0026lt;/b\u0026gt;: {occupation} \u0026lt;b\u0026gt;Probability of Automation\u0026lt;/b\u0026gt;: {probability}% \u0026lt;b\u0026gt;Median Income\u0026lt;/b\u0026gt;: ${A_MEDIAN} \u0026lt;b\u0026gt;Number of Workers\u0026lt;/b\u0026gt;: {TOT_EMP}\u0026#39;))) + scale_size(range = c(1, 20)) + xlab(\u0026quot;\\nMedian Income\u0026quot;) + ylab(\u0026quot;Probability of Automation\u0026quot;) + labs(size= \u0026quot;\u0026quot;, col= \u0026quot;\u0026quot;, alpha = \u0026quot;\u0026quot;) + scale_color_manual(values = cols, breaks = legend_ord) + scale_x_continuous(labels=scales::dollar_format(prefix=\u0026quot;$\u0026quot;), limits = c(25000,200000)) + scale_y_continuous(labels=scales::number_format(suffix=\u0026quot;%\u0026quot;), limits = c(0,100)) + # cr::drop_axis(axis = \u0026quot;y\u0026quot;) + theme(axis.line.x = ggplot2::element_line(colour = NULL, size = NULL, linetype = NULL, lineend = NULL), axis.line.y = ggplot2::element_blank(), panel.grid.major.x = element_blank()) But wait, what’s that second line of code?\nfilter(if (add != 8) add \u0026gt;= reveal else reveal %in% c(1:8)) This may make 0 sense right now, but here’s why we have it.\nThe important part (and somewhat difficult thing to understand) about this step is that your plot object has some data which corresponds to an updating variable. For me, I added a variable called reveal for each step of the visualization. For me, this meant having reveal correspond to a typical level of education for a given job.\ndata \u0026lt;- data %\u0026gt;% mutate(reveal = case_when( typicaled == \u0026quot;No formal educational credential\u0026quot; ~ 1, typicaled == \u0026quot;High school diploma or equivalent\u0026quot; ~ 2, typicaled == \u0026quot;Postsecondary nondegree award\u0026quot; ~ 3, typicaled == \u0026quot;Some college, no degree\u0026quot; ~ 0, typicaled == \u0026quot;Associate\u0026#39;s degree\u0026quot; ~ 4, typicaled == \u0026quot;Bachelor\u0026#39;s degree\u0026quot; ~ 5, typicaled == \u0026quot;Master\u0026#39;s degree\u0026quot; ~ 6, typicaled == \u0026quot;Doctoral or professional degree\u0026quot; ~ 7, )) What this means is that every time the post observes an event (a scroll), it will update according to the number in the reveal column.\nSo, when my plot object has a line of code which says:\nfilter(if (add != 8) add \u0026gt;= reveal else reveal %in% c(1:8)) That can be read as “Update the plot object to include all data points up until the current point encoded in reveal.”\nBut, it also depends on what level of add we are at; if add == 8 (the last data point, e.g. the concluding plot), then we want to show all data points.\n“Okay, okay. But what is add???”\nGood question. add is the variable I constructed to correspond to the user’s input (in this case, the scroll!). When we put it all together, we’re going to wrap our plot object into a rendering function inside the server function. Confusing? It looks like this:\nserver \u0026lt;- function(input, output, session) { output$plot \u0026lt;- renderPlotly({ add \u0026lt;- input$scr plot \u0026lt;- # static ggplot goes here ggplotly(plot) %\u0026gt;% # other ggplotly parameters go here }) # render the plot here output$scr \u0026lt;- renderScrollytell({scrollytell()}) renderText(paste0(\u0026quot;Section: \u0026quot;, input$scr)) observe({cat(\u0026quot;section:\u0026quot;, input$scr, \u0026quot;\\n\u0026quot;)}) } What’s happening here? Within the server function, we’re doing two things:\nFirst, we’re creating the plot object. Because we have the command add \u0026lt;- input\\(scr* **inside** the function `renderPlotly`, our plot object will be dynamically updated along with *input\\)scr.\nThis makes more sense when you connect it to the ui. In our ui function, we include a scrolly_container from the scrollytell package. Within that, we make our outputId correspond to the name of our updating input (in this case, scr).\nui \u0026lt;- fluidPage( # a bunch of introductory stuff, css stuff # scrollytelling plot scrolly_container(outputId = \u0026quot;scr\u0026quot;, scrolly_graph( ## this is the plot object that we made earlier: plotlyOutput(\u0026quot;plot\u0026quot;, height = \u0026#39;600px\u0026#39;) ), scrolly_sections( ## each of these sections corresponds to an update ## the number after id = corresponds to the `scr` update ## the render_text() function will be discussed later scrolly_section(id = 0, render_text(0)), scrolly_section(id = 1, render_text(1)), scrolly_section(id = 2, render_text(2)), scrolly_section(id = 3, render_text(3)), scrolly_section(id = 4, render_text(4)), scrolly_section(id = 5, render_text(5)), scrolly_section(id = 6, render_text(6)), scrolly_section(id = 7, render_text(7)), scrolly_section(id = 8, render_text(8)), # add a scrolly_section with nothing in it; # this buffer prevents the plot from disappearing while reading last section scrolly_section(id = \u0026quot;buffer\u0026quot;, br()) ) ), # a bunch of concluding stuff, other html ) So, the simplest way to think about this so far is:\nConstruct a plot object with some updating variable (in my case, reveal).\nfilter(if (add != 8) add \u0026gt;= reveal else reveal %in% c(1:8)) Make that variable correspond with some input variable (in my case add, which is created from the input$scr).\nserver \u0026lt;- function(input, output, session) { output$plot \u0026lt;- renderPlotly({ add \u0026lt;- input$scr #...  Render your plot object in scrolly_graph, and provide input updates via each scrolly_section.\nui \u0026lt;- fluidPage( # a bunch of introductory stuff, css stuff # scrollytelling plot scrolly_container(outputId = \u0026quot;scr\u0026quot;, scrolly_graph(plotlyOutput(\u0026quot;plot\u0026quot;, height = \u0026#39;600px\u0026#39;) ), scrolly_sections( scrolly_section(id = 0, render_text(0)), scrolly_section(id = 1, render_text(1)), # ... Render your plots in your server function.\nserver \u0026lt;- function(input, output, session) { output$plot \u0026lt;- #... }) output$scr \u0026lt;- renderScrollytell({scrollytell()}) renderText(paste0(\u0026quot;Section: \u0026quot;, input$scr)) observe({cat(\u0026quot;section:\u0026quot;, input$scr, \u0026quot;\\n\u0026quot;)}) } That’s (most of) it for the plot section. You can play around with other customizations too (for example, the alphas for my circles correspond to an ifelse around reveal, so old circles are faded out compared to new ones).\nCreate a Series of Text Reveals Next, we create text sections using HTML and some helper functions which beautify them.\nFirst, we create the text boxes for each section following a similar naming convention:\ntext1 \u0026lt;- HTML(\u0026quot;\u0026lt;H2\u0026gt; No education credentials \u0026lt;/H2\u0026gt; \u0026lt;br\u0026gt; \u0026lt;p\u0026gt; Workers with \u0026lt;font color=\u0026#39;#A00042\u0026#39;\u0026gt;no formal education credential\u0026lt;/font\u0026gt; have a median income of $25,636. \u0026lt;br\u0026gt; On average, those occupations have a \u0026lt;b\u0026gt;90% chance\u0026lt;/b\u0026gt; of job automation. \u0026lt;br\u0026gt;\u0026lt;br\u0026gt; There are 23,765,700 workers with \u0026lt;font color=\u0026#39;#A00042\u0026#39;\u0026gt;no formal education credential\u0026lt;/font\u0026gt;.\u0026lt;p\u0026gt;\u0026quot;) text2 \u0026lt;- HTML(\u0026quot;\u0026lt;H2\u0026gt; High school diplomas \u0026lt;/H2\u0026gt; \u0026lt;br\u0026gt; \u0026lt;p\u0026gt;Workers with \u0026lt;font color=\u0026#39;#F56C42\u0026#39;\u0026gt;high school diplomas\u0026lt;/font\u0026gt; have a median income of $25,636. \u0026lt;br\u0026gt; On average, those occupations have a \u0026lt;b\u0026gt;60% chance\u0026lt;/b\u0026gt; of job automation. \u0026lt;br\u0026gt;\u0026lt;br\u0026gt; There are 33,129,910 workers with a \u0026lt;font color=\u0026#39;#F56C42\u0026#39;\u0026gt;high school diploma\u0026lt;/font\u0026gt;.\u0026lt;p\u0026gt;\u0026quot;) # ...  Then, we create a function render_text which beautifies that HTML with CSS:\ntext \u0026lt;- function(num){ p( switch(num, text1, text2, text3, text4, text5, text6, text7, text8 ) ) } render_text \u0026lt;- function(num){ div( text(num), class = \u0026quot;text\u0026quot; ) } For all 8 of the above text_s, we’ve created a switch function which calls them depnding on the number passed to render_text. Then, we apply paragraph format, put them in their own div, and apply the text class in our CSS sheet.\nHow does this work?\nRecall that above, in our ui section, we had the following:\nscrolly_sections( HTML(\u0026#39;\u0026lt;center\u0026gt;\u0026#39;), scrolly_section(id = 0, render_text(0)), scrolly_section(id = 1, render_text(1)), # ... ) Here, our scrolly_sections take two inputs: our ID and our corresponding text. Rather than write out lengthy text boxes in each scrolly_section, we can construct them in a single file and then knit them all into the same format using render_text. This makes life a lot easier.\nSo, on each scroll (or observation), the app will update 1) the plot object, by adding add and updating according to reveal, and 2) the text, by running render_text which calls text which beautifies our HTML text.\n Final Touches Surprisingly, that’s about it. The rest of the app is built on fluidPage, and organizing via rows and columns in your shiny app. Your app should have a CSS style sheet (in the www folder). You may also include other plots (for my post, I have an introductory plot with a bit more context), which you will have to separately create and render in your server function.\nAll in all, my code looks like this:\nui \u0026lt;- fluidPage( # suppress warning messages while data is loading on-screen tags$style(type=\u0026quot;text/css\u0026quot;, \u0026quot;.shiny-output-error { visibility: hidden; }\u0026quot;, \u0026quot;.shiny-output-error:before { visibility: hidden; }\u0026quot;), tags$head( includeCSS(\u0026quot;www/style.css\u0026quot;) ), # article title \u0026amp; name fluidRow(HTML(\u0026quot;\u0026lt;center\u0026gt; \u0026lt;h1\u0026gt;Automation and Its Impact on Jobs\u0026lt;/h1\u0026gt; \u0026lt;p style=\u0026#39;font-size:26px\u0026#39;\u0026gt; by \u0026lt;a href=\u0026#39;https://connorrothschild.github.io/\u0026#39; target=\u0026#39;_blank\u0026#39;\u0026gt;Connor Rothschild\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; \u0026lt;/center\u0026gt;\u0026quot;) ), br(), fluidRow( column(1), column(10, # intro text fluidRow(id=\u0026#39;text\u0026#39;, column(1), column(10, br(), text0, hr(), h1( class = \u0026quot;instructions\u0026quot;, \u0026quot;How to read this chart:\u0026quot;, br(), br(), \u0026quot;The size of each\u0026quot;, icon(\u0026quot;circle\u0026quot;), \u0026quot;corresponds to the number of workers in that job.\u0026quot;, br(), \u0026quot;Hover over each\u0026quot;, icon(\u0026quot;circle\u0026quot;), \u0026quot;to see details on the occupation\u0026#39;s income and probability of automation.\u0026quot;, br(), \u0026quot;Double click on a\u0026quot;, icon(\u0026quot;circle\u0026quot;), \u0026quot;in the legend to focus on a specific level of education.\u0026quot; )), column(1)), # plot object for intro plotlyOutput(\u0026quot;introPlot\u0026quot;, height = \u0026#39;400px\u0026#39;) ), column(1), ), # scrollytelling plot scrolly_container(\u0026quot;scr\u0026quot; , scrolly_graph( br(), br(), textOutput(\u0026quot;section\u0026quot;), br(), HTML(\u0026#39;\u0026lt;center\u0026gt;\u0026#39;), plotlyOutput(\u0026quot;plot\u0026quot;, height = \u0026#39;600px\u0026#39;), HTML(\u0026#39;\u0026lt;/center\u0026gt;\u0026#39;) ) , scrolly_sections( HTML(\u0026#39;\u0026lt;center\u0026gt;\u0026#39;), scrolly_section(id = 0, render_text(0)), scrolly_section(id = 1, render_text(1)), scrolly_section(id = 2, render_text(2)), scrolly_section(id = 3, render_text(3)), scrolly_section(id = 4, render_text(4)), scrolly_section(id = 5, render_text(5)), scrolly_section(id = 6, render_text(6)), scrolly_section(id = 7, render_text(7)), scrolly_section(id = 8, render_text(8)), # add a scrolly_section with nothing in it; # this buffer prevents the plot from disappearing while reading last section scrolly_section(id = \u0026quot;buffer\u0026quot;, br()), HTML(\u0026#39;\u0026lt;/center\u0026gt;\u0026#39;) ) ), # concluding text div(fluidRow(id = \u0026#39;text\u0026#39;, column(2), column(8, concludingtext, br() ), column(2) ), style = \u0026#39;margin-top: -300px;\u0026#39;), br(), br(), br(), hr(), fluidRow( column(1), column(10, technicalnotes ), column(1) ), br(), br(), column(1) ) And the server looks like this:\nserver \u0026lt;- function(input, output, session) { output$plot \u0026lt;- renderPlotly({ add \u0026lt;- input$scr plot \u0026lt;- data %\u0026gt;% filter(typicaled != \u0026quot;Some college, no degree\u0026quot;) %\u0026gt;% filter(if (add != 8) add \u0026gt;= reveal else reveal %in% c(1:8)) %\u0026gt;% ggplot() + geom_point(mapping=aes(x=A_MEDIAN, y=probability, size=TOT_EMP, alpha=ifelse(add == reveal, 1/5, 1/10), col=typicaled, text = glue::glue(\u0026#39;\u0026lt;b\u0026gt;Occupation\u0026lt;/b\u0026gt;: {occupation} \u0026lt;b\u0026gt;Probability of Automation\u0026lt;/b\u0026gt;: {probability}% \u0026lt;b\u0026gt;Median Income\u0026lt;/b\u0026gt;: ${A_MEDIAN} \u0026lt;b\u0026gt;Number of Workers\u0026lt;/b\u0026gt;: {TOT_EMP}\u0026#39;))) + scale_size(range = c(1, 20)) + xlab(\u0026quot;\\nMedian Income\u0026quot;) + ylab(\u0026quot;Probability of Automation\u0026quot;) + labs(size= \u0026quot;\u0026quot;, col= \u0026quot;\u0026quot;, alpha = \u0026quot;\u0026quot;) + scale_color_manual(values = cols, breaks = legend_ord) + scale_x_continuous(labels=scales::dollar_format(prefix=\u0026quot;$\u0026quot;), limits = c(25000,200000)) + scale_y_continuous(labels=scales::number_format(suffix=\u0026quot;%\u0026quot;), limits = c(0,100)) + # cr::drop_axis(axis = \u0026quot;y\u0026quot;) + theme(axis.line.x = ggplot2::element_line(colour = NULL, size = NULL, linetype = NULL, lineend = NULL), axis.line.y = ggplot2::element_blank(), panel.grid.major.x = element_blank()) ggplotly(plot, tooltip = \u0026#39;text\u0026#39;) %\u0026gt;% layout( title = list(element_blank()), legend = list(x = 0.65, y = 0.925), font = list(family = \u0026#39;Lato\u0026#39;), margin=list(t=50), hoverlabel = list(bgcolor = \u0026#39;whitesmoke\u0026#39;, color = \u0026#39;DarkGray\u0026#39;)) %\u0026gt;% config(displaylogo = F, showSendToCloud = F, displayModeBar = F) }) output$introPlot \u0026lt;- renderPlotly({introPlot}) output$scr \u0026lt;- renderScrollytell({scrollytell()}) renderText(paste0(\u0026quot;Section: \u0026quot;, input$scr)) observe({cat(\u0026quot;section:\u0026quot;, input$scr, \u0026quot;\\n\u0026quot;)}) } # Run the application shinyApp(ui = ui, server = server)   The Output You can see the final output of my post here.\nYou can look at the code and all of its context on GitHub here.\n ","date":1572048000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"b20efe6bbaded30c9aa7661c38f58f92","permalink":"/post/automation-scrollytell/","publishdate":"2019-10-26T00:00:00Z","relpermalink":"/post/automation-scrollytell/","section":"post","summary":"Scrollytelling in R, because its easier than D3.","tags":["r","visualization","animation","scrollytelling"],"title":"How to Scrollytell in R: Automation and Its Impact on Jobs","type":"post"},{"authors":["Connor Rothschild"],"categories":["R"],"content":" library(ggplot2) library(tidyverse) library(ggtext) library(gifski) library(gganimate) library(cr) set_cr_theme(font = \u0026quot;lato\u0026quot;) Load and Clean Data First, read in the data from https://openpowerlifting.org/data:\n# df \u0026lt;- readr::read_csv(\u0026quot;openpowerlifting-2019-09-20.csv\u0026quot;) # # df_clean \u0026lt;- df %\u0026gt;% # janitor::clean_names() # # ipf_lifts \u0026lt;- df_clean %\u0026gt;% # select(name:weight_class_kg, starts_with(\u0026quot;best\u0026quot;), place, date, federation, meet_name) %\u0026gt;% # filter(!is.na(date)) %\u0026gt;% # filter(federation == \u0026quot;IPF\u0026quot;) ipf_lifts \u0026lt;- readr::read_csv(\u0026quot;data/ipf_lifts.csv\u0026quot;) Clean ipf_lifts, and reshape the three lifts into one column:\nipf_lifts \u0026lt;- ipf_lifts %\u0026gt;% mutate(year = lubridate::year(date)) ipf_lifts_reshape \u0026lt;- ipf_lifts %\u0026gt;% tidyr::pivot_longer(cols = c(\u0026quot;best3squat_kg\u0026quot;, \u0026quot;best3bench_kg\u0026quot;, \u0026quot;best3deadlift_kg\u0026quot;), names_to = \u0026quot;lift\u0026quot;) %\u0026gt;% select(name, sex, year, lift, value) For my visualization, I’m only concerned with the heaviest lifts from each year:\nipf_lifts_maxes \u0026lt;- ipf_lifts_reshape %\u0026gt;% group_by(year, sex, lift) %\u0026gt;% top_n(1, value) %\u0026gt;% ungroup %\u0026gt;% distinct(year, lift, value, .keep_all = TRUE) In order to construct a dumbbell plot, we need both male and female observations in the same row.\nmax_pivot \u0026lt;- ipf_lifts_maxes %\u0026gt;% spread(sex, value) Let’s try to construct a dataframe for each sex:\nmale_lifts \u0026lt;- max_pivot %\u0026gt;% select(-name) %\u0026gt;% filter(!is.na(M)) %\u0026gt;% group_by(year, lift) %\u0026gt;% summarise(male = mean(M)) female_lifts \u0026lt;- max_pivot %\u0026gt;% select(-name) %\u0026gt;% filter(!is.na(`F`)) %\u0026gt;% group_by(year, lift) %\u0026gt;% summarise(female = mean(`F`)) And join them:\nmax_lifts \u0026lt;- merge(male_lifts, female_lifts) max_lifts_final \u0026lt;- max_lifts %\u0026gt;% group_by(year, lift) %\u0026gt;% mutate(diff = male - female)  Visualize Finally, we can construct the visualization.\nFirst, a static viz (thanks to hrbrmaster’s ggalt package):\nmax_lifts_final %\u0026gt;% filter(year == 2019) %\u0026gt;% ggplot() + ggalt::geom_dumbbell(aes(y = lift, x = female, xend = male), colour = \u0026quot;grey\u0026quot;, size = 5, colour_x = \u0026quot;#D6604C\u0026quot;, colour_xend = \u0026quot;#395B74\u0026quot;) + labs(y = element_blank(), x = \u0026quot;Top Lift Recorded (kg)\u0026quot;, title = \u0026quot;How \u0026lt;span style=\u0026#39;color:#D6604C\u0026#39;\u0026gt;Women\u0026lt;/span\u0026gt; and \u0026lt;span style=\u0026#39;color:#395B74\u0026#39;\u0026gt;Men\u0026lt;/span\u0026gt; Differ in Top Lifts\u0026quot;, subtitle = \u0026quot;In 2019\u0026quot;) + theme(plot.title = element_markdown(lineheight = 1.1, size = 20), plot.subtitle = element_text(size = 15)) + scale_y_discrete(labels = c(\u0026quot;Bench\u0026quot;, \u0026quot;Deadlift\u0026quot;, \u0026quot;Squat\u0026quot;)) + drop_axis(axis = \u0026quot;y\u0026quot;) + geom_text(aes(x = female, y = lift, label = paste(female, \u0026quot;kg\u0026quot;)), color = \u0026quot;#D6604C\u0026quot;, size = 4, vjust = -2) + geom_text(aes(x = male, y = lift, label = paste(male, \u0026quot;kg\u0026quot;)), color = \u0026quot;#395B74\u0026quot;, size = 4, vjust = -2) + geom_rect(aes(xmin=430, xmax=470, ymin=-Inf, ymax=Inf), fill=\u0026quot;grey80\u0026quot;) + geom_text(aes(label=diff, y=lift, x=450), fontface=\u0026quot;bold\u0026quot;, size=4) + geom_text(aes(x=450, y=3, label=\u0026quot;Difference\u0026quot;), color=\u0026quot;grey20\u0026quot;, size=4, vjust=-3, fontface=\u0026quot;bold\u0026quot;) Finally, we animate, using Thomas Pedersen’s wonderful gganimate package:\nanimation \u0026lt;- max_lifts_final %\u0026gt;% ggplot() + ggalt::geom_dumbbell(aes(y = lift, x = female, xend = male), colour = \u0026quot;grey\u0026quot;, size = 5, colour_x = \u0026quot;#D6604C\u0026quot;, colour_xend = \u0026quot;#395B74\u0026quot;) + labs(y = element_blank(), x = \u0026quot;Top Lift Recorded (kg)\u0026quot;, title = \u0026quot;How \u0026lt;span style=\u0026#39;color:#D6604C\u0026#39;\u0026gt;Women\u0026lt;/span\u0026gt; and \u0026lt;span style=\u0026#39;color:#395B74\u0026#39;\u0026gt;Men\u0026lt;/span\u0026gt; Differ in Top Lifts\u0026quot;, subtitle=\u0026#39;\\nThis plot depicts the difference between the heaviest lifts for each sex at International Powerlifting Federation\\nevents over time. \\n \\n{closest_state}\u0026#39;) + theme(plot.title = element_markdown(lineheight = 1.1, size = 25, margin=margin(0,0,0,0)), plot.subtitle = element_text(size = 15, margin=margin(8,0,-30,0))) + scale_y_discrete(labels = c(\u0026quot;Bench\u0026quot;, \u0026quot;Deadlift\u0026quot;, \u0026quot;Squat\u0026quot;)) + drop_axis(axis = \u0026quot;y\u0026quot;) + geom_text(aes(x = female, y = lift, label = paste(female, \u0026quot;kg\u0026quot;)), color = \u0026quot;#D6604C\u0026quot;, size = 4, vjust = -2) + geom_text(aes(x = male, y = lift, label = paste(male, \u0026quot;kg\u0026quot;)), color = \u0026quot;#395B74\u0026quot;, size = 4, vjust = -2) + transition_states(year, transition_length = 4, state_length = 1) + ease_aes(\u0026#39;cubic-in-out\u0026#39;) a_gif \u0026lt;- animate(animation, fps = 10, duration = 25, width = 800, height = 400, renderer = gifski_renderer(\u0026quot;outputs/animation.gif\u0026quot;)) a_gif I’d like to include another GIF: a line chart of differences over time\nanimation2 \u0026lt;- max_lifts_final %\u0026gt;% ungroup %\u0026gt;% mutate(lift = case_when(lift == \u0026quot;best3bench_kg\u0026quot; ~ \u0026quot;Bench\u0026quot;, lift == \u0026quot;best3squat_kg\u0026quot; ~ \u0026quot;Squat\u0026quot;, lift == \u0026quot;best3deadlift_kg\u0026quot; ~ \u0026quot;Deadlift\u0026quot;)) %\u0026gt;% ggplot(aes(year, diff, group = lift, color = lift)) + geom_line(show.legend = FALSE) + geom_segment(aes(xend = 2019.1, yend = diff), linetype = 2, colour = \u0026#39;grey\u0026#39;, show.legend = FALSE) + geom_point(size = 2, show.legend = FALSE) + geom_text(aes(x = 2019.1, label = lift, color = \u0026quot;#000000\u0026quot;), hjust = 0, show.legend = FALSE) + drop_axis(axis = \u0026quot;y\u0026quot;) + transition_reveal(year) + coord_cartesian(clip = \u0026#39;off\u0026#39;) + theme(plot.title = element_text(size = 20)) + labs(title = \u0026#39;Difference over time\u0026#39;, y = \u0026#39;Difference (kg)\u0026#39;, x = element_blank()) + theme(plot.margin = margin(5.5, 40, 5.5, 5.5)) b_gif \u0026lt;- animate(animation2, fps = 10, duration = 25, width = 800, height = 200, renderer = gifski_renderer(\u0026quot;outputs/animation2.gif\u0026quot;)) b_gif Next, combine them using magick (thanks to this post):\nlibrary(magick) a_mgif \u0026lt;- image_read(a_gif) b_mgif \u0026lt;- image_read(b_gif) new_gif \u0026lt;- image_append(c(a_mgif[1], b_mgif[1]), stack = TRUE) for(i in 2:250){ combined \u0026lt;- image_append(c(a_mgif[i], b_mgif[i]), stack = TRUE) new_gif \u0026lt;- c(new_gif, combined) } new_gif  ","date":1570492800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"847b71e25b4239294ac7daf9c6e18225","permalink":"/post/tidy-tuesday-powerlifting/","publishdate":"2019-10-08T00:00:00Z","relpermalink":"/post/tidy-tuesday-powerlifting/","section":"post","summary":"Analyzing sex differences in top lifts at international powerlifting competitions.","tags":["r","visualization","animation","gganimate","Tidy Tuesday"],"title":"TidyTuesday: Powerlifting","type":"post"},{"authors":["Connor Rothschild"],"categories":["R"],"content":" Is there a connection between video games and gun violence, as Republicans suggest?\nLoad Packages library(readr) library(readxl) library(tidyverse) library(ggplot2) library(showtext) library(emojifont) library(cr) conflicted::conflict_prefer(\u0026quot;filter\u0026quot;, \u0026quot;dplyr\u0026quot;) conflicted::conflict_prefer(\u0026quot;scale_colour_discrete\u0026quot;, \u0026quot;cr\u0026quot;) set_cr_theme(font = \u0026quot;lato\u0026quot;)  Load Data Data regarding gun deaths per capita comes from the Institute for Health Metrics and Evaluation\nguns \u0026lt;- read_csv(\u0026quot;data/IHME-guns.csv\u0026quot;) guns \u0026lt;- guns %\u0026gt;% select(Location, Value) Data regarding video game sales per capita comes from this Google Spreadsheet which was pulled from NewZoo, a gaming analytics company.\ngames \u0026lt;- read_excel(\u0026quot;data/GameRevenueByCountry.xlsx\u0026quot;) games \u0026lt;- games %\u0026gt;% rename(revenue = `PER CAPITA REVENUE`) %\u0026gt;% select(Country, revenue)  Merge and Clean Data joined \u0026lt;- left_join(games, guns, by = c(\u0026quot;Country\u0026quot; = \u0026quot;Location\u0026quot;)) Next, we clean games dataset so that Country matches the Location column from guns.\ngames \u0026lt;- games %\u0026gt;% mutate(Country = case_when(Country == \u0026quot;Republic of Korea\u0026quot; ~ \u0026quot;South Korea\u0026quot;, Country == \u0026quot;Brunei Darussalam\u0026quot; ~ \u0026quot;Brunei\u0026quot;, #Country == \u0026quot;Macao\u0026quot; ~ , #Country == \u0026quot;Hong Kong, China\u0026quot; ~ , Country == \u0026quot;Lucembourg\u0026quot; ~ \u0026quot;Luxembourg\u0026quot;, Country == \u0026quot;Kuwair\u0026quot; ~ \u0026quot;Kuwait\u0026quot;, Country == \u0026quot;UAE\u0026quot; ~ \u0026quot;United Arab Emirates\u0026quot;, Country == \u0026quot;TFYR Macedonia\u0026quot; ~ \u0026quot;Macedonia\u0026quot;, Country == \u0026quot;Joran\u0026quot; ~ \u0026quot;Jordan\u0026quot;, Country == \u0026quot;Republic of Moldova\u0026quot; ~ \u0026quot;Moldova\u0026quot;, TRUE ~ as.character(Country))) joined \u0026lt;- left_join(games, guns, by = c(\u0026quot;Country\u0026quot; = \u0026quot;Location\u0026quot;)) There are 98 countries with full data present.\nWe should also create a dummy variable for each country depending on whether it is an OECD country or not.\nCountry \u0026lt;- c( \u0026quot;Austria\u0026quot;, \u0026quot;Belgium\u0026quot;, \u0026quot;Canada\u0026quot;, \u0026quot;Denmark\u0026quot;, \u0026quot;France\u0026quot;, \u0026quot;Greece\u0026quot;, \u0026quot;Iceland\u0026quot;, \u0026quot;Ireland\u0026quot;, \u0026quot;Italy\u0026quot;, \u0026quot;Luxembourg\u0026quot;, \u0026quot;Netherlands\u0026quot;, \u0026quot;Norway\u0026quot;, \u0026quot;Portugal\u0026quot;, \u0026quot;Spain\u0026quot;, \u0026quot;Sweden\u0026quot;, \u0026quot;Switzerland\u0026quot;, \u0026quot;Turkey\u0026quot;, \u0026quot;United Kingdom\u0026quot;, \u0026quot;United States\u0026quot;, \u0026quot;West Germany\u0026quot;, \u0026quot;Australia\u0026quot;, \u0026quot;Finland\u0026quot;, \u0026quot;Japan\u0026quot;, \u0026quot;New Zealand\u0026quot;) OECD \u0026lt;- \u0026quot;OECD\u0026quot; oecd \u0026lt;- data.frame(Country, OECD) oecd_joined \u0026lt;- left_join(joined, oecd, by = \u0026quot;Country\u0026quot;) oecd_joined \u0026lt;- oecd_joined %\u0026gt;% mutate(OECD = ifelse(is.na(OECD), \u0026quot;Not OECD\u0026quot;, \u0026quot;OECD\u0026quot;))  Visualize This allows us to plot each country in a scatterplot, with point colour corresponding to OECD status:\noecd_joined %\u0026gt;% ggplot(aes(x = revenue, y = Value, colour = factor(OECD))) + geom_point() + geom_text(aes(label = ifelse(Country == \u0026quot;United States\u0026quot;, as.character(Country),\u0026#39;\u0026#39;), vjust = -1), show.legend = FALSE) + geom_text(aes(label = ifelse(Value \u0026gt; 40, as.character(Country),\u0026#39;\u0026#39;), vjust = -1), show.legend = FALSE) + geom_text(aes(label = ifelse(revenue \u0026gt; 150, as.character(Country),\u0026#39;\u0026#39;), vjust = -1), show.legend = FALSE) + labs(x = \u0026quot;Video Game Revenue per Capita (US $)\u0026quot;, y = \u0026quot;Violent Gun Deaths per 100k\u0026quot;, title = \u0026quot;Gun Deaths vs Game Sales\u0026quot;, colour = element_blank(), caption = \u0026quot;\\nSources: Institute for Health Metrics and Evaluation, NewZoo\u0026quot;) + scale_y_continuous(limits = c(0, 45)) + theme(plot.caption = element_text(face = \u0026quot;italic\u0026quot;, hjust = 0), legend.position = \u0026quot;top\u0026quot;, legend.direction = \u0026quot;horizontal\u0026quot;) + drop_axis(axis = \u0026quot;y\u0026quot;) Finally, we can focus on only OECD countries:\noecd_joined %\u0026gt;% dplyr::filter(OECD == \u0026quot;OECD\u0026quot;) %\u0026gt;% ggplot(aes(x = revenue, y = Value)) + geom_point() + #geom_smooth() + geom_text(aes(label = ifelse(Country == \u0026quot;United States\u0026quot;, as.character(Country),\u0026#39;\u0026#39;), vjust = -1)) + labs(x = \u0026quot;Video Game Revenue per Capita (US $)\u0026quot;, y = \u0026quot;Violent Gun Deaths per 100k\u0026quot;, title = \u0026quot;Gun Deaths vs Game Sales\u0026quot;, subtitle = \u0026quot;OECD Countries\u0026quot;, caption = \u0026quot;\\nSources: Institute for Health Metrics and Evaluation, NewZoo\u0026quot;) + scale_y_continuous(limits = c(0, 5)) + theme(plot.caption = element_text(face = \u0026quot;italic\u0026quot;, hjust = 0)) + drop_axis(axis = \u0026quot;y\u0026quot;) To conclude, let’s add an emoji to fully capture our skepticism with the newfound argument linking video games to violence.\noecd_joined %\u0026gt;% dplyr::filter(OECD == \u0026quot;OECD\u0026quot;) %\u0026gt;% ggplot(aes(x = revenue, y = Value)) + geom_point() + #geom_smooth() + geom_text(aes(label = ifelse(Country == \u0026quot;United States\u0026quot;, as.character(Country),\u0026#39;\u0026#39;), vjust = -1)) + labs(x = \u0026quot;Video Game Revenue per Capita (US $)\u0026quot;, y = \u0026quot;Violent Gun Deaths per 100k\u0026quot;, title = \u0026quot;Gun Deaths vs Game Sales\u0026quot;, subtitle = \u0026quot;OECD Countries\u0026quot;, caption = \u0026quot;\\nSources: Institute for Health Metrics and Evaluation, NewZoo\u0026quot;) + scale_y_continuous(limits = c(0, 5)) + theme(plot.caption = element_text(face = \u0026quot;italic\u0026quot;, hjust = 0)) + drop_axis(axis = \u0026quot;y\u0026quot;) + geom_text(y = 4.85, x = 107.5, size = 7, label = emoji(\u0026#39;thinking\u0026#39;), family = \u0026quot;EmojiOne\u0026quot;)  ","date":1565568000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"cb23b7aa3b767d431986b151fb97712f","permalink":"/post/games-and-guns/","publishdate":"2019-08-12T00:00:00Z","relpermalink":"/post/games-and-guns/","section":"post","summary":"Is there a connection between video games and gun violence, as Republicans suggest?","tags":["r","visualization"],"title":"Games and Guns","type":"post"},{"authors":["Connor Rothschild"],"categories":["R"],"content":" I spent some time this weekend playing around with Shiny, RStudio’s tool for creating interactive web apps. In a nod to my humble beginnings, I wanted to bring some interactivity to my first R project (ever!).\nI finished the project roughly a year ago, in the summer between my freshman and sophomore year. It was an exercise in plotting multiple dimensions related to something of personal interest to me: automation and its impact on jobs. I wanted to use ggplot2 to recreate a visualization I came across on Bloomberg graphics. Here’s Bloomberg’s visualization and here’s mine.\nThere are some obvious differences in our visualizations (our axes are inverted, they likely used D3.js while I used ggplot2), but for the most part, our visualizations depict the same lesson: lower-paying jobs and less-educated jobs are more susceptible to job displacement from automation.\nA year later, there are some things about my first visualization I would definitely change (title and axis label size, unnecessary corner labels, a potentially misleading geom_smooth line), but what I really want to work on now is bringing my project closer to the Bloomberg visualization by making it interactive. (I’ve actually already made an interactive version of the visualization using Tableau, but I wanted to do it again in R to expand my skillset!)\nEnter Shiny, RStudio’s tool for creating interactive visualizations. By using Shiny with ggvis (ggplot2’s “successor” with interactive capabilities), I’m able to get pretty close to my initial inspiration.\nggvis’s commands are pretty similar to ggplot2, and so the learning curve wasn’t that steep (with the exception of setting the default size parameter for my points, which I finally solved with this fix). Shiny was a bit more difficult to learn, but RStudio’s online video tutorials make it a lot less daunting. All in all, the project only took one night (~3 hours) to complete. Another example of R’s accessibility and ease of use!\nClean/Prepare Data library(ggplot2) library(ggthemes) library(dplyr) library(ggrepel) library(tools) library(readxl) library(tidyverse) library(knitr) options(scipen=999) theme_set(theme_minimal()) education \u0026lt;- read_excel(\u0026quot;data/education.xlsx\u0026quot;, skip=1) salary \u0026lt;- read_excel(\u0026quot;data/national_M2017_dl.xlsx\u0026quot;) automation \u0026lt;- read_excel(\u0026quot;data/raw_state_automation_data.xlsx\u0026quot;) salary1 \u0026lt;- salary %\u0026gt;% group_by(OCC_TITLE) %\u0026gt;% mutate(natlwage = TOT_EMP * as.numeric(A_MEAN)) %\u0026gt;% filter(!is.na(TOT_EMP)) %\u0026gt;% filter(!is.na(A_MEAN)) %\u0026gt;% filter(!is.na(A_MEDIAN)) salary1$A_MEDIAN = as.numeric(as.character(salary1$A_MEDIAN)) salary2 \u0026lt;- select(salary1, OCC_TITLE, TOT_EMP, A_MEDIAN, natlwage) %\u0026gt;% distinct() library(plyr) education1 \u0026lt;- education %\u0026gt;% select(-...2) education1 \u0026lt;- rename(education1, c(\u0026quot;2016 National Employment Matrix title and code\u0026quot; = \u0026quot;occupation\u0026quot;, \u0026quot;Less than high school diploma\u0026quot; = \u0026quot;lessthanhs\u0026quot;, \u0026quot;High school diploma or equivalent\u0026quot; = \u0026quot;hsdiploma\u0026quot;, \u0026quot;Some college, no degree\u0026quot; = \u0026quot;somecollege\u0026quot;, \u0026quot;Associate\u0026#39;s degree\u0026quot; = \u0026quot;associates\u0026quot;, \u0026quot;Bachelor\u0026#39;s degree\u0026quot; = \u0026quot;bachelors\u0026quot;, \u0026quot;Master\u0026#39;s degree\u0026quot; = \u0026quot;masters\u0026quot;, \u0026quot;Doctoral or professional degree\u0026quot; = \u0026quot;professional\u0026quot;)) education2 \u0026lt;- education1 %\u0026gt;% group_by(occupation) %\u0026gt;% mutate(hsorless = lessthanhs + hsdiploma, somecollegeorassociates = somecollege + associates, postgrad = masters + professional) education2 \u0026lt;- education2 %\u0026gt;% drop_na() salary2 \u0026lt;- rename(salary2, c(\u0026quot;OCC_TITLE\u0026quot; = \u0026quot;occupation\u0026quot;)) salary2$occupation \u0026lt;- tolower(salary2$occupation) education2$occupation \u0026lt;- tolower(education2$occupation) edsal \u0026lt;- merge(as.data.frame(education2), as.data.frame(salary2), by=\u0026quot;occupation\u0026quot;) %\u0026gt;% drop_na() typicaleducation \u0026lt;- read_excel(\u0026quot;data/typicaleducation.xlsx\u0026quot;) typicaleducation2 \u0026lt;- typicaleducation %\u0026gt;% select(occupation,typicaled,workexp) typicaleducation2 \u0026lt;- typicaleducation2 %\u0026gt;% drop_na() typicaleducation2$occupation \u0026lt;- tolower(typicaleducation2$occupation) edsal2 \u0026lt;- merge(as.data.frame(edsal), as.data.frame(typicaleducation2), by=\u0026quot;occupation\u0026quot;) detach(package:plyr) edsal3 \u0026lt;- edsal2 %\u0026gt;% group_by(typicaled) %\u0026gt;% summarise(medianwage = mean(A_MEDIAN)) automationwstates \u0026lt;- automation %\u0026gt;% select(-soc) automation1 \u0026lt;- automationwstates %\u0026gt;% select(occupation,probability,total) automation1$occupation \u0026lt;- str_replace_all(automation1$occupation, \u0026quot;;\u0026quot;, \u0026quot;,\u0026quot;) automation1$occupation \u0026lt;- tolower(automation$occupation) data \u0026lt;- merge(as.data.frame(edsal2), as.data.frame(automation1), by=\u0026quot;occupation\u0026quot;) data$occupation \u0026lt;- toTitleCase(data$occupation)  Bring in Shiny library(shiny) # Define UI for application ui \u0026lt;- pageWithSidebar( headerPanel(\u0026quot;Automation\u0026quot;), sidebarPanel( wellPanel( h4(\u0026quot;Filter\u0026quot;), sliderInput(\u0026quot;TOT_EMP\u0026quot;, \u0026quot;Number of Workers\u0026quot;, 0, 4450000, 4450000, step = 10000), sliderInput(\u0026quot;A_MEDIAN\u0026quot;, \u0026quot;Median Income\u0026quot;, 0, 185150, 185150, step = 1000), sliderInput(\u0026quot;probability\u0026quot;, \u0026quot;Probability of Automation\u0026quot;, 0, 1, 1, step = .1), # sliderInput(\u0026quot;boxoffice\u0026quot;, \u0026quot;Dollars at Box Office (millions)\u0026quot;, # 0, 800, c(0, 800), step = 1), selectInput(\u0026quot;typicaled\u0026quot;, \u0026quot;Education Level\u0026quot;, c(\u0026quot;All\u0026quot;, \u0026quot;Bachelor\u0026#39;s degree\u0026quot;, \u0026quot;High school diploma or equivalent\u0026quot;, \u0026quot;Associate\u0026#39;s degree\u0026quot;, \u0026quot;Postsecondary nondegree award\u0026quot;, \u0026quot;No formal educational credential\u0026quot;, \u0026quot;Master\u0026#39;s degree\u0026quot;, \u0026quot;Doctoral or professional degree\u0026quot;, \u0026quot;Some college, no degree\u0026quot;) )) #textInput(\u0026quot;occupation\u0026quot;, \u0026quot;Occupation Name\u0026quot;)) ), mainPanel( plotOutput(\u0026quot;plot\u0026quot;) ) ) server \u0026lt;- function(input, output) { # defaultColors \u0026lt;- c(\u0026quot;#3366cc\u0026quot;, \u0026quot;#dc3912\u0026quot;, \u0026quot;#ff9900\u0026quot;, \u0026quot;#109618\u0026quot;, \u0026quot;#990099\u0026quot;, \u0026quot;#0099c6\u0026quot;, \u0026quot;#dd4477\u0026quot;) # series \u0026lt;- structure( # lapply(defaultColors, function(color) { list(color=color) }), # names = levels(data$typicaled) # ) dfInput \u0026lt;- reactive({ if (input$typicaled!=\u0026quot;All\u0026quot;) { data %\u0026gt;% filter(TOT_EMP \u0026lt;= input$TOT_EMP, A_MEDIAN \u0026lt;= input$A_MEDIAN, probability \u0026lt;= input$probability, typicaled %in% input$typicaled) #occupation == input$occupation) } else { data %\u0026gt;% filter(TOT_EMP \u0026lt;= input$TOT_EMP, A_MEDIAN \u0026lt;= input$A_MEDIAN, probability \u0026lt;= input$probability) } }) output$plot \u0026lt;- renderPlot({ data1 \u0026lt;- dfInput() ggplot(data1) + geom_point(mapping = aes(x = A_MEDIAN, y = probability, size = TOT_EMP, alpha=0.05, col = typicaled)) + # #geom_smooth(aes(x=A_MEDIAN, y=probability), method=\u0026quot;lm\u0026quot;, se=FALSE) + scale_size_area(max_size = 20) + scale_alpha(guide = \u0026#39;none\u0026#39;) + guides(size = \u0026quot;none\u0026quot;) + theme(legend.position = \u0026quot;bottom\u0026quot;) + guides(colour = guide_legend(override.aes = list(alpha = 1))) + ylim(-.05,1.05) + xlim(25000,200000) + xlab(\u0026quot;Median Income\u0026quot;) + ylab(\u0026quot;Probability of Automation\u0026quot;) + ggtitle(\u0026quot;Likelihood of Job Automation vs Median Income\u0026quot;) + labs(size=\u0026quot;Total Employment\u0026quot;, col=\u0026quot;Education Level\u0026quot;) }) } # shinyApp(ui = ui, server = server) You can find the Shiny app here!\n ","date":1564790400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"8e8ec36af2704353f10257879cc1eb48","permalink":"/post/building-my-first-shiny-app/","publishdate":"2019-08-03T00:00:00Z","relpermalink":"/post/building-my-first-shiny-app/","section":"post","summary":"Building my first Shiny app.","tags":["r","visualization","interactive","shiny"],"title":"Building my First Shiny App","type":"post"},{"authors":["Connor Rothschild"],"categories":["R"],"content":" A brief exploration of Texas vaccination rates among kindergartners. Also an attempt to use rayshader for the first time.\nLoad Packages library(readxl) library(tidyverse) library(stringr) library(dplyr) library(ggplot2) library(ggmap) library(maps) library(mapdata) library(scales) library(tpltheme) library(knitr) conflicted::conflict_prefer(\u0026quot;filter\u0026quot;, \u0026quot;dplyr\u0026quot;) set_tpl_theme(font = \u0026quot;lato\u0026quot;)  Read in Data tx_vac \u0026lt;- read_excel(\u0026quot;data/2018-2019 School Vaccination Coverage Levels - Kindergarten (XLS) .xlsx\u0026quot;, skip = 2) kable(head(tx_vac))   Facility Number School Type Facility Name Facility Address County DTP/DTaP/DT/Td Hepatitis A Hepatitis B MMR Polio Varicella    9057816000 Public ISD A W Brown Leadership Academy 5701 RED BIRD CTR DR, DALLAS, TX, 75237 Dallas 0.8317308 0.9086538 0.9471154 0.8509615 0.8413462 0.8509615  9057829000 Public ISD A+ Academy 8225 BRUTON RD, DALLAS, TX, 75217 Dallas 1.0000000 1.0000000 1.0000000 0.9909091 1.0000000 1.0000000  9109901000 Public ISD Abbott ISD P O BOX 226, ABBOTT, TX, 76621 Hill 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000  7101130101 Private School Abercrombie Academy 17102 Theiss Mail Road, Spring, TX, 77379 Harris 1.0000000 1.0000000 1.0000000 0.7500000 1.0000000 0.7500000  9095901000 Public ISD Abernathy ISD 505 7TH ST, ABERNATHY, TX, 79311 Hale 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000 1.0000000  7101220001 Private School Abiding Word Lutheran School 17123 Red Oak Drive, Houston, TX, 77090 Harris 0.7692308 0.7692308 0.7692308 0.7692308 0.6923077 0.7692308    The data contains information on six different vaccines split up by school. The set also contains information on the county of each school, allowing us to aggregate on the county level. By finding the average of the six vaccines listed in this dataset, we can see average vaccination rate by county:\ngrouped \u0026lt;- tx_vac %\u0026gt;% mutate(avgvac = (`DTP/DTaP/DT/Td`+`Hepatitis A`+`Hepatitis B`+MMR+Polio+Varicella)/6) %\u0026gt;% group_by(County) %\u0026gt;% summarize(avgvac = mean(avgvac, na.rm = TRUE)) %\u0026gt;% mutate(County = tolower(County)) %\u0026gt;% # rename to subregion so that we can later join with ggplot map data rename(\u0026quot;subregion\u0026quot; = County) %\u0026gt;% filter(subregion != \u0026quot;king\u0026quot;) kable(head(grouped))   subregion avgvac    anderson 0.9676797  andrews 0.9715335  angelina 0.9693150  aransas 0.9735294  archer 0.9915167  armstrong 0.9677419    Next, we read in the county-level data from ggplot2 and merge it with our vaccination data:\ncounties \u0026lt;- map_data(\u0026quot;county\u0026quot;) tx_county \u0026lt;- subset(counties, region == \u0026quot;texas\u0026quot;) merged \u0026lt;- left_join(tx_county, grouped, by = \u0026quot;subregion\u0026quot;)  Plot Construct the plot using geom_polygon(), and pay special attention to theme attributes (axes, panels, etc.).\nUnfortunately, theme_nothing() led to some conflicts with rayshader, so I essentially recreated it using theme() attributes.\ntx \u0026lt;- ggplot(data = merged, mapping = aes(x = long, y = lat, group = group, fill = avgvac*100)) + coord_fixed(1.3) + geom_polygon(color = \u0026quot;black\u0026quot;) + labs(fill = \u0026quot;Vaccination Rate\u0026quot;) + #theme_nothing(legend = TRUE) + theme(legend.title = element_text(), #legend.key.width = unit(.1, \u0026quot;in\u0026quot;), panel.border = element_blank(), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), axis.line = element_blank(), axis.text.x = element_blank(), axis.text.y = element_blank(), axis.ticks = element_blank(), panel.background = element_rect(fill = \u0026quot;white\u0026quot;), text = element_text(family = \u0026quot;Lato\u0026quot;), legend.position = \u0026quot;bottom\u0026quot;) + labs(x = element_blank(), y = element_blank(), title = \u0026quot;Texas Vaccination Rate by County\u0026quot;, subtitle = \u0026quot;Among Kindergartners\u0026quot;) + tpltheme::scale_fill_continuous() Here’s what the plot looks like before animation:\n Rayshader Load in rayshader and rgl. I’m not sure if rgl is necessary for all R users, but I ran into a few errors on my system (Mac) prior to its installation.\n#devtools::install_github(\u0026quot;tylermorganwall/rayshader\u0026quot;) library(rgl) options(rgl.useNULL = FALSE) library(rayshader) Lastly, create the plot_gg() object by following the comprehensive documentation on Wall’s README.\npar(mfrow = c(1,1)) rayshader::plot_gg(tx, width = 5, raytrace = TRUE, multicore = TRUE, height = 5, scale = 50) # create custom rotation parameters here phivechalf = 30 + 60 * 1/(1 + exp(seq(-7, 20, length.out = 180)/2)) phivecfull = c(phivechalf, rev(phivechalf)) thetavec = -90 + 60 * sin(seq(0,359,length.out = 360) * pi/180) zoomvec = 0.45 + 0.2 * 1/(1 + exp(seq(-5, 20, length.out = 180))) zoomvecfull = c(zoomvec, rev(zoomvec)) render_movie(filename = \u0026quot;outputs/tx_vac_vid\u0026quot;, type = \u0026quot;custom\u0026quot;, frames = 360, phi = phivecfull, zoom = zoomvecfull, theta = thetavec) \n  ","date":1563926400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"4fc9b6dc27504cf223ede9575a116129","permalink":"/post/tx-vaccination-rates-rayshader/","publishdate":"2019-07-24T00:00:00Z","relpermalink":"/post/tx-vaccination-rates-rayshader/","section":"post","summary":"A brief exploration of Texas vaccination rates among kindergartners, and an attempt to use rayshader for the first time.","tags":["r","visualization","animation","rayshader"],"title":"Texas Vaccination Rates (How to Use Rayshader)","type":"post"},{"authors":["Connor Rothschild"],"categories":["R"],"content":" I’ve spent the majority of the summer as an intern with the Texas Policy Lab, working on primarily data science-related matters such as data cleaning and visualization. Most recently, I sought to create a custom theme in ggplot2 for TPL.\nThe project was my first experience in developing my own R package. Prior to this project, the most familiarity I had with packages were from the install.packages() and library() commands.\nHadley Wickham’s book R Packages was enormously helpful in introducing package development to me. I ran into (a lot of) issues in building the package, specifically encountering problems related to local file paths and logo placement on plots.\nCreating your own package is a great exercise in trial and error, and taught me a lot about programming in R that I wouldn’t have learned otherwise. I was also struck by how remarkably easy it was to create one’s own package (seriously, it requires the same amount of clicks as starting a new R project), and how thorough online resources were.\nInspiration The catalyst for creating this package was coming across the Urban Institute’s urbnthemes package on GitHub. I also gathered a lot of inspiration (and borrowed some code) from ggthemes (Jeffrey Arnold), bbplot (BBC News), and hrbrthemes (Bob Rudis). I was impressed by the fact that these organizations were able to use R to create publication-ready plots despite the fact that base ggplot figures can look rather ugly (if we’re being honest).\nBecause the organization I intern with is still in its infancy, I thought it would be a perfect time to create a standardized theme for figures made in the future. So long as future employees adopt the theme, this package has the potential to create figures specific to our publications, lending TPL organizational credibility and creating cross-report consistency.\nI thought a lot about some basic tenets of design, such as font readability, text size, and color contrast. I learned a lot about visual and aesthetic design I wouldn’t know otherwise (Kieran Healy’s section on how graphs can deceive the reader–intentionally or not–opened my eyes to a lot of important visual concepts.\n Overview Here’s an overview of some of the packages key features:\nInstallation and Usage You can install the package via GitHub:\nlibrary(ggplot2) library(tidyverse) #devtools::install_github(\u0026quot;connorrothschild/tpltheme\u0026quot;) library(tpltheme) Always load library(tpltheme) after library(ggplot2) and/or library(tidyverse).\nThe package creates a standardized formats for plots to be used in reports created by the Texas Policy Lab. It primarily relies on set_tpl_theme(), which allows the user to specify whether the plot theme should align with a standard plot (style = \u0026quot;print\u0026quot;), or one specially created for plotting geographical data (style = \u0026quot;Texas\u0026quot;). Calling set_tpl_theme() after library(tpltheme) does most of the work for this package!\nset_tpl_theme() ggplot(iris, aes(x=Species, y=Sepal.Width, fill=Species)) + geom_bar(stat=\u0026quot;summary\u0026quot;, fun.y=\u0026quot;mean\u0026quot;, show.legend = FALSE) + scale_y_continuous(expand = expand_scale(mult = c(0, 0.001))) + labs(x=\u0026quot;Species\u0026quot;, y=\u0026quot;Mean Sepal Width (cm)\u0026quot;, fill=\u0026quot;Species\u0026quot;, title=\u0026quot;Iris Dataset\u0026quot;) Fonts The user is able to specify whether they want to use Lato or Adobe Caslon Pro in their figures.\nTo ensure that these fonts are installed and registered, use tpl_font_test(). If fonts are not properly installed, install both fonts online and then run tpl_font_install().\ntpl_font_test() tpl_font_install() Here are some examples of sample TPL plots with different specifications for style and font.\nset_tpl_theme(style = \u0026quot;print\u0026quot;, font = \u0026quot;lato\u0026quot;) ggplot(iris, aes(x=jitter(Sepal.Width), y=jitter(Sepal.Length), col=Species, size = Petal.Length)) + geom_point() + labs(x=\u0026quot;Sepal Width (cm)\u0026quot;, y=\u0026quot;Sepal Length (cm)\u0026quot;, col=\u0026quot;Species\u0026quot;, size = \u0026quot;Petal Length\u0026quot;, title=\u0026quot;Iris Dataset\u0026quot;) By specifying style = \u0026quot;Texas\u0026quot; within set_tpl_theme, the user may also create Texas-specific plots.\ntx_vac \u0026lt;- readr::read_csv(\u0026quot;https://raw.githubusercontent.com/connorrothschild/tpltheme/master/data/tx_vac_example.csv\u0026quot;) set_tpl_theme(style = \u0026quot;Texas\u0026quot;, font = \u0026quot;adobe\u0026quot;) ggplot(data = tx_vac, mapping = aes(x = long, y = lat, group = group, fill = avgvac*100)) + coord_fixed(1.3) + scale_fill_continuous(limits = c(78.3,100)) + geom_polygon(color = \u0026quot;black\u0026quot;) + labs(title = \u0026quot;Texas Vaccination Rate by County\u0026quot;, subtitle = \u0026quot;Among Kindergarteners\u0026quot;, fill = \u0026quot;Percent\\nVaccinated\u0026quot;, caption = \u0026quot;Source: Texas DSHS\u0026quot;) And it also works for categorical variables:\nset_tpl_theme(style = \u0026quot;Texas\u0026quot;, font = \u0026quot;lato\u0026quot;) tx_vac %\u0026gt;% dplyr::mutate(cat = factor(dplyr::case_when(avgvac*100 \u0026gt; 99 ~ \u0026quot;Great\u0026quot;, avgvac*100 \u0026gt; 90 ~ \u0026quot;Average\u0026quot;, avgvac*100 \u0026lt; 90 ~ \u0026quot;Bad\u0026quot;))) %\u0026gt;% ggplot(mapping = aes(x = long, y = lat, group = group, fill = cat)) + coord_fixed(1.3) + geom_polygon(color = \u0026quot;black\u0026quot;) + labs(title = \u0026quot;Texas Vaccination Rate by County\u0026quot;, subtitle = \u0026quot;Among Kindergarteners\u0026quot;, fill = \u0026quot;Vaccination Rating\u0026quot;, caption = \u0026quot;Source: Texas DSHS\u0026quot;) If the number of colors exceeds the number of colors in the TPL palette (9), the function tpl_color_pal() will drop the TPL color palette and return the greatest number of unique colors possible within the RColorBrewer’s “Paired” palette (for more information on the use of RColorBrewer palettes, see this chapter).\ntx_vac %\u0026gt;% ggplot(mapping = aes(x = long, y = lat, group = group, fill = subregion)) + coord_fixed(1.3) + geom_polygon(color = \u0026quot;black\u0026quot;, show.legend = FALSE) + labs(title = \u0026quot;Texas Counties\u0026quot;) # default to print afterwards set_tpl_theme(style = \u0026quot;print\u0026quot;)  TPL Branding Logo The user also has the option to include the TPL logo in single plots. This may be preferred for those reports being made especially public, or to serve as a pseudo-watermark in proprietary plots.\nThe user can specify the position of the logo as well as its scale. The scale argument refers to the size of the logo object, with the specified number corresponding to a multiplication with the normal logo size. In other words, scale = 2 will double the size of the logo. The logo defaults to 1/7th of the size of the plot.\nplot \u0026lt;- ggplot(iris, aes(x=Species, y=Sepal.Width, fill=Species)) + geom_bar(stat=\u0026quot;summary\u0026quot;, fun.y=\u0026quot;mean\u0026quot;, show.legend = FALSE) + scale_y_continuous(expand = expand_scale(mult = c(0, 0.001))) + labs(x=\u0026quot;Species\u0026quot;, y=\u0026quot;Mean Sepal Width (cm)\u0026quot;, fill=\u0026quot;Species\u0026quot;, title=\u0026quot;Iris Dataset\u0026quot;) add_tpl_logo(plot, position = \u0026quot;top right\u0026quot;, scale = 1.5)  Logo Text There may be some instances when an all-out logo is not warranted or preferred. If that is the case and the user would still like to watermark their figures, they can use the function add_tpl_logo_text() to add text to an existing plot object:\nplot \u0026lt;- ggplot(iris, aes(x=jitter(Sepal.Width), y=jitter(Sepal.Length), col=Species, size = Petal.Length)) + geom_point() + labs(x=\u0026quot;Sepal Width (cm)\u0026quot;, y=\u0026quot;Sepal Length (cm)\u0026quot;, col=\u0026quot;Species\u0026quot;, size = \u0026quot;Petal Length\u0026quot;, title=\u0026quot;Iris Dataset\u0026quot;) add_tpl_logo_text(plot) The user may also need to specify align, which moves the plot horizontally across the bottom of the page.\nplot \u0026lt;- ggplot(iris, aes(x=Species, y=Sepal.Width, fill=Species)) + geom_boxplot(show.legend = FALSE) + labs(x=\u0026quot;Species\u0026quot;, y=\u0026quot;Sepal Width (cm)\u0026quot;, fill=\u0026quot;Species\u0026quot;, title=\u0026quot;Iris Dataset\u0026quot;, subtitle =\u0026quot;When specifying align = 1\u0026quot;) add_tpl_logo_text(plot, align = 1)    Additional Functions Drop Axes In the event that the user wishes to drop an axis, they may do so with drop_axis(). The function may drop any combination of axes depending on the user’s input (drop = \u0026quot;x\u0026quot;, drop = \u0026quot;y\u0026quot;, drop = \u0026quot;both\u0026quot;, drop = \u0026quot;neither\u0026quot;).\nUnlike add_tpl_logo(), drop_axis() should be added to an existing plot object:\nggplot(iris, aes(x=jitter(Sepal.Width), y=jitter(Sepal.Length), col=Species, size = Petal.Length)) + geom_point() + labs(x=\u0026quot;Sepal Width (cm)\u0026quot;, y=\u0026quot;Sepal Length (cm)\u0026quot;, col=\u0026quot;Species\u0026quot;, size = \u0026quot;Petal Length\u0026quot;, title=\u0026quot;Iris Dataset\u0026quot;) + drop_axis(axis = \u0026quot;y\u0026quot;)   Colors I also put a lot of time into creating a color palette which was both aesthetically pleasing and accessible to color-blind viewers. This was somewhat difficult because there are quite a few types of colorblindness. Thankfully, my boss is colorblind, making test cases a lot more accessible!\nThe function view_palette plots base color palettes included in tpltheme. All TPL color palettes are led by the notation palette_tpl_* and therefore can be easily autocompleted within RStudio.\np1 \u0026lt;- view_palette(palette = palette_tpl_main) + ggtitle(\u0026quot;Categorical\u0026quot;) p2 \u0026lt;- view_palette(palette = palette_tpl_diverging) + ggtitle(\u0026quot;Diverging\u0026quot;) p3 \u0026lt;- view_palette(palette = palette_tpl_sequential) + ggtitle(\u0026quot;Sequential\u0026quot;) gridExtra::grid.arrange(p1, p2, p3, nrow = 1) These palettes were created using http://colorbrewer2.org and http://coloors.co and are colorblind friendly.\nThe diverging and sequential color palettes are from http://colorbrewer2.org and the categorical palette is composed of a variety of colors from https://coolors.co/ and the TPL website.\nIn action, the color palette looks like this:\nnormal \u0026lt;- diamonds %\u0026gt;% group_by(clarity) %\u0026gt;% summarise(price = mean(price)) %\u0026gt;% mutate(clarity = forcats::fct_reorder(clarity, price)) %\u0026gt;% ggplot() + geom_col(aes(x = clarity, y = price, fill = clarity), show.legend = FALSE) + labs(title = \u0026quot;TPL Color Palette\u0026quot;, subtitle = \u0026quot;in action\u0026quot;, x = \u0026quot;Clarity\u0026quot;, y = \u0026quot;Price\u0026quot;, fill = element_blank()) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) + coord_flip() + scale_fill_discrete() + scale_y_continuous(expand = expand_scale(mult = c(0, 0.001))) + drop_axis(axis = \u0026quot;x\u0026quot;) reversed \u0026lt;- normal + labs(subtitle = \u0026quot;(reversed)\u0026quot;) + scale_fill_discrete(reverse = TRUE) gridExtra::grid.arrange(normal, reversed) The user may specify the color palette in the scale_fill_* or scale_color_* functions in a ggplot call. Specifically, the user can specify the palette (categorical, diverging, sequential) and whether the palette should be reversed.\nset_tpl_theme(style = \u0026quot;print\u0026quot;, font = \u0026quot;lato\u0026quot;) normal \u0026lt;- ggplot(diamonds) + geom_bar(aes(x = cut, fill = clarity)) + labs(title = \u0026quot;TPL Color Palette\u0026quot;, subtitle = \u0026quot;On sample data\u0026quot;, x = \u0026quot;Cut\u0026quot;, y = \u0026quot;Count\u0026quot;, fill = \u0026quot;Clarity\u0026quot;) + scale_y_continuous(expand = expand_scale(mult = c(0, 0.001))) + theme(axis.text.x = element_text(angle = 45, hjust = 1)) reversed \u0026lt;- normal + labs(subtitle = \u0026quot;(reversed)\u0026quot;) + scale_fill_discrete(reverse = TRUE) gridExtra::grid.arrange(normal, reversed, nrow = 1) data \u0026lt;- gapminder::gapminder %\u0026gt;% dplyr::filter(gapminder::gapminder$country %in% c(\u0026quot;France\u0026quot;, \u0026quot;Germany\u0026quot;, \u0026quot;Ireland\u0026quot;, \u0026quot;Italy\u0026quot;, \u0026quot;Japan\u0026quot;, \u0026quot;Norway\u0026quot;, \u0026quot;Mexico\u0026quot;, \u0026quot;United States\u0026quot;)) %\u0026gt;% dplyr::mutate(year = as.Date(paste(year, \u0026quot;-01-01\u0026quot;, sep = \u0026quot;\u0026quot;, format=\u0026#39;%Y-%b-%d\u0026#39;))) ggplot(data = data, aes(x = year, y = gdpPercap, fill = country)) + geom_area(alpha = 0.8) + scale_x_date(expand = c(0,0)) + scale_y_continuous(expand = c(0, 0), labels = scales::dollar) + labs(title = \u0026quot;GDP Per Capita Over Time\u0026quot;, subtitle = \u0026quot;Using the TPL Color Palette\u0026quot;, x = element_blank(), y = \u0026quot;GDP Per Capita\u0026quot;, fill = \u0026quot;Country\u0026quot;) + theme(axis.text.x = element_text(angle = 45, hjust = 1))  Restore Defaults By calling undo_tpl_theme, you are able to remove TPL-specific theme settings and restores to ggplot defaults (but why would you want to do that?).\nundo_tpl_theme() ## [1] \u0026quot;All TPL defaults were removed and the tpltheme package has been effectively detached from the current environment. To restore TPL defaults, use set_tpl_theme().\u0026quot; ggplot(iris, aes(x=jitter(Sepal.Width), y=jitter(Sepal.Length), col=Species, size = Petal.Length)) + geom_point() + labs(x=\u0026quot;Sepal Width (cm)\u0026quot;, y=\u0026quot;Sepal Length (cm)\u0026quot;, col=\u0026quot;Species\u0026quot;, size = \u0026quot;Petal Length\u0026quot;, title=\u0026quot;Iris Dataset\u0026quot;) To restore the TPL theme, simply call set_tpl_theme():\nset_tpl_theme() last_plot()    ","date":1563840000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"df4d35a76c328fc2bbf0f581284b400a","permalink":"/post/introducing-tpltheme/","publishdate":"2019-07-23T00:00:00Z","relpermalink":"/post/introducing-tpltheme/","section":"post","summary":"Introducing tpltheme, a toolkit to create publication-ready plots in the style of the Texas Policy Lab.","tags":["r","package","Texas Policy Lab"],"title":"My First Package! Introducing 'tpltheme'","type":"post"},{"authors":["Connor Rothschild"],"categories":["R"],"content":" The goal of this post is to explore how baby names have changed over time.\nMore specifically, I’m focusing on the decision to name one’s baby after a Biblical figure. I’m curious if the popularity of Biblically-inspired baby names has changed over time. We’re able to explore this question using the babynames package in R, which contains historical data from the U.S. Social Security Administration ranging back to 1880. It contains information on the number of babies born with a certain name in a given year, the sex of those babies, the year they were born, and their name (obviously).\nlibrary(babynames) library(knitr) library(readxl) library(tidyverse) library(ggplot2) library(cr) conflicted::conflict_prefer(\u0026quot;filter\u0026quot;, \u0026quot;dplyr\u0026quot;) set_cr_theme(font = \u0026quot;lato\u0026quot;) kable(head(babynames))   year sex name n prop    1880 F Mary 7065 0.0723836  1880 F Anna 2604 0.0266790  1880 F Emma 2003 0.0205215  1880 F Elizabeth 1939 0.0198658  1880 F Minnie 1746 0.0178884  1880 F Margaret 1578 0.0161672    In order to determine the popularity of “Bible babies,” we need a list of names found in the Bible in order to search the babynames dataset. I pulled a random list of Bible baby names from babycentre.co.uk. The list likely doesn’t include all names found in the Bible (only popular baby names), but that’s probably no big deal considering few, if any, parents name their child Athaliah.\nbiblenames \u0026lt;- read_excel(\u0026quot;data/biblebabynames.xlsx\u0026quot;) boybible \u0026lt;- biblenames %\u0026gt;% select(boynames) %\u0026gt;% rename(names = boynames) girlbible \u0026lt;- biblenames %\u0026gt;% filter(!is.na(girlnames)) %\u0026gt;% select(girlnames) %\u0026gt;% rename(names = girlnames) biblenamesbind \u0026lt;- rbind(boybible, girlbible) # use the %in% operator to match names with those in biblenamesbind babynames \u0026lt;- babynames %\u0026gt;% mutate(biblepercent = ifelse(name %in% biblenamesbind$names, prop, 0))  Popularity of Biblical Baby Names over Time One initial question is whether the popularity of “Bible babies” has declined over time. Given that Christian identity and religiosity more generally have experienced declines in recent years, one may assume that the decision to name one’s baby after a Biblical figure has also become less popular.\nbabynames %\u0026gt;% group_by(year) %\u0026gt;% summarise(sum = sum(biblepercent)) %\u0026gt;% ggplot(aes(x=year, y=sum)) + geom_line() + scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + labs(title = \u0026quot;Bible Babies over Time\u0026quot;, subtitle=\u0026quot;Percent of babies born with names found in the Bible\u0026quot;, x=\u0026quot;Year\u0026quot;, y=\u0026quot;Percent\u0026quot;, caption = \u0026quot;Source: U.S. Social Security Administration \\n Design: www.connorrothschild.com\u0026quot;) Biblical names have become significantly less popular over time. We can split up the trend by sex to see if it is primarily driven by one group of babies.\nbabynames %\u0026gt;% group_by(year, sex) %\u0026gt;% summarise(sum = sum(biblepercent)) %\u0026gt;% ungroup %\u0026gt;% group_by(sex) %\u0026gt;% ggplot(aes(x=year, y=sum, col=sex)) + geom_line() + scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + labs(title = \u0026quot;Bible Babies over Time\u0026quot;, subtitle=\u0026quot;Percent of babies born with names found in the Bible\u0026quot;, x=\u0026quot;Year\u0026quot;, y=\u0026quot;Percent\u0026quot;, color=\u0026quot;Sex\u0026quot;, caption = \u0026quot;Source: U.S. Social Security Administration \\n Design: www.connorrothschild.com\u0026quot;) Indeed, much of the departure from Biblically-inspired baby names has been driven by girls. While 13% of boys born in 2017 shared a name with some biblical figure, the same was true of only 4% of girls.\n Exploring Popular Names over Time Using gganimate Finally, we can incorporate Thomas Lin Pedersen’s gganimate package to explore the popularity of specific Bible names over time. This was inspired by Kieran Healy’s similar visualization depicting changes in the structure of babies’ names over time. The below code creates a GIF showing the shifting popularity of boys’ names over time.\nlibrary(gganimate) # make male rank variable malebabynames \u0026lt;- babynames %\u0026gt;% filter(sex==\u0026quot;M\u0026quot;) %\u0026gt;% group_by(year) %\u0026gt;% mutate(rank = min_rank(-biblepercent) * 1) %\u0026gt;% filter(rank \u0026lt;= 10) %\u0026gt;% ungroup() # plot male animation maleanimation \u0026lt;- malebabynames %\u0026gt;% filter(sex==\u0026quot;M\u0026quot;) %\u0026gt;% ggplot(aes(rank, group = name, fill = as.factor(name), color = as.factor(name))) + geom_tile(aes(y = biblepercent/2, height = biblepercent, width = 0.9), alpha = 0.8, color = NA) + geom_text(aes(y = 0, label = paste(name, \u0026quot; \u0026quot;)), vjust = 0.2, hjust = 1) + coord_flip(clip = \u0026quot;off\u0026quot;, expand = FALSE) + scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + scale_x_reverse() + guides(color = FALSE, fill = FALSE) + labs(title=\u0026quot;Most Popular Biblical Baby Names for Males\u0026quot;, subtitle=\u0026#39;in {closest_state}\u0026#39;, x = element_blank(), y = \u0026quot;Percent of Names\u0026quot;, caption = \u0026quot;Source: U.S. Social Security Administration \\n Design: www.connorrothschild.com\u0026quot;) + theme(plot.title = element_text(hjust = 0, size = 22), plot.subtitle = element_text(hjust = 0, size = 16), axis.ticks.y = element_blank(), axis.text.y = element_blank(), plot.margin = margin(1,1,1,4, \u0026quot;cm\u0026quot;)) + transition_states(year, transition_length = 4, state_length = 1) + ease_aes(\u0026#39;cubic-in-out\u0026#39;) animate(maleanimation, fps = 25, nframes = 500, width = 800, height = 600)  #, renderer = gifski_renderer(\u0026quot;boybiblebabies.gif\u0026quot;)) Replicating that code with minor tweaks creates the same animation for girls’ names:\n# make rank variable femalebabynames \u0026lt;- babynames %\u0026gt;% filter(sex==\u0026quot;F\u0026quot;) %\u0026gt;% group_by(year) %\u0026gt;% mutate(rank = min_rank(-biblepercent) * 1) %\u0026gt;% filter(rank \u0026lt;= 10) %\u0026gt;% ungroup() # plot animation femaleanimation \u0026lt;- femalebabynames %\u0026gt;% filter(sex==\u0026quot;F\u0026quot;) %\u0026gt;% ggplot(aes(rank, group = name, fill = as.factor(name), color = as.factor(name))) + geom_tile(aes(y = biblepercent/2, height = biblepercent, width = 0.9), alpha = 0.8, color = NA) + geom_text(aes(y = 0, label = paste(name, \u0026quot; \u0026quot;)), vjust = 0.2, hjust = 1) + coord_flip(clip = \u0026quot;off\u0026quot;, expand = FALSE) + scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + scale_x_reverse() + guides(color = FALSE, fill = FALSE) + labs(title=\u0026quot;Most Popular Biblical Baby Names for Females\u0026quot;, subtitle=\u0026#39;in {closest_state}\u0026#39;, x = element_blank(), y = \u0026quot;Percent of Names\u0026quot;, caption = \u0026quot;Source: U.S. Social Security Administration\\n Design: www.connorrothschild.com\u0026quot;) + theme(plot.title = element_text(hjust = 0, size = 22), plot.subtitle = element_text(hjust = 0, size = 16), axis.ticks.y = element_blank(), axis.text.y = element_blank(), plot.margin = margin(1,1,1,4, \u0026quot;cm\u0026quot;)) + transition_states(year, transition_length = 4, state_length = 1) + ease_aes(\u0026#39;cubic-in-out\u0026#39;) animate(femaleanimation, fps = 25, nframes = 500, width = 800, height = 600)  #, renderer = gifski_renderer(\u0026quot;girlbiblebabies.gif\u0026quot;)) Finally, we can combine some of the insights from our earlier plot (depicting the popularity of Biblical names by sex) to show which boys’ names are responsible for their sex’s relative dominance over girls’ Biblically-inspired names.\n# make rank variable babynamesrank \u0026lt;- babynames %\u0026gt;% group_by(year) %\u0026gt;% mutate(rank = min_rank(-biblepercent) * 1) %\u0026gt;% filter(rank \u0026lt;= 10) %\u0026gt;% ungroup() # plot animation babyanimation \u0026lt;- babynamesrank %\u0026gt;% ggplot(aes(rank, group = name, fill = as.factor(sex), color = as.factor(sex))) + geom_tile(aes(y = biblepercent/2, height = biblepercent, width = 0.9), alpha = 0.8, color = NA) + geom_text(aes(y = 0, label = paste(name, \u0026quot; \u0026quot;)), vjust = 0.2, hjust = 1) + coord_flip(clip = \u0026quot;off\u0026quot;, expand = FALSE) + scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + scale_x_reverse() + guides(color = FALSE, fill = FALSE) + labs(title=\u0026quot;Most Popular Biblical Baby Names\u0026quot;, subtitle=\u0026#39;in {closest_state}\u0026#39;, x = element_blank(), y = \u0026quot;Percent of Names\u0026quot;, caption = \u0026quot;Source: U.S. Social Security Administration \\n Design: www.connorrothschild.com\u0026quot;) + theme(plot.title = element_text(hjust = 0, size = 22), plot.subtitle = element_text(hjust = 0, size = 16), axis.ticks.y = element_blank(), axis.text.y = element_blank(), plot.margin = margin(1,1,1,4, \u0026quot;cm\u0026quot;)) + transition_states(year, transition_length = 4, state_length = 1) + ease_aes(\u0026#39;cubic-in-out\u0026#39;) animate(babyanimation, fps = 25, nframes = 500, width = 800, height = 600)  #, renderer = gifski_renderer(\u0026quot;combinedbiblebabies.gif\u0026quot;))  ","date":1560297600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"159c967ca86d0fe1c5d0bfccf5651c92","permalink":"/post/bible-babies/","publishdate":"2019-06-12T00:00:00Z","relpermalink":"/post/bible-babies/","section":"post","summary":"How has the distribution of Biblically-inspired baby names changed over time?","tags":["r","visualization","animation","gganimate"],"title":"Bible Babies: Exploring Biblically-Inspired Baby Names over Time","type":"post"},{"authors":["Connor Rothschild"],"categories":["R"],"content":" In this post, I explore which presidential candidates are discussed most frequently in the American news media.\nNote: This post has become somewhat outdated since it’s original publication because the dataset (linked via FiveThirtyEight’s GitHub) has changed variable names and some of the data has changed.\nYou can find a less technical version of this post without code on my blog.\nOverview In this post, I explore which presidential candidates are discussed most frequently in the American news media. I do so using the GDELT Television API, which pulls data from the TV News Archive. For sake of convenience, I use an existing dataset found on FiveThirtyEight’s GitHub.\n Load Libraries and Data library(httr) library(tidyverse) library(dplyr) library(ggplot2) library(ggridges) library(ggrepel) library(viridis) library(lubridate) library(RColorBrewer) library(devtools) library(knitr) library(cr) set_cr_theme(font = \u0026quot;lato\u0026quot;) data \u0026lt;- read.csv(\u0026quot;data/mentions.csv\u0026quot;, header = T) #read.csv((\u0026quot;https://raw.githubusercontent.com/fivethirtyeight/data/master/media-mentions-2020/cable_weekly.csv\u0026quot;), header=T) data \u0026lt;- data %\u0026gt;% mutate(date = as.Date(date, \u0026quot;%m/%d/%y\u0026quot;)) The dataset contains information on 22 presidential candidates, recording weekly the number of clips which mention a presidential candidate (matched_clips) and dividing them by the total number of clips that week (total_clips) to reveal the percent (pct_of_all_candidate_clips) of clips which mention that candidate.\n  name date pct_of_all_candidate_clips matched_clips total_clips    John Delaney 2018-12-30 0.0039432 5 76029  John Delaney 2019-01-06 0.0019589 2 82964  John Delaney 2019-01-13 0.0081566 5 82521  John Delaney 2019-01-20 0.0020182 2 83649  John Delaney 2019-01-27 0.0015723 3 80994  John Delaney 2019-02-03 0.0006901 1 79183    Of interest to us is the name of each candidate and the percent (pct_of_all_candidate_clips) of media mentions they receive on a weekly basis.\n Analysis We can begin with a simple analysis of which candidates are discussed most frequently by the media by averaging their weekly proportion of mentions in the media.\ndata %\u0026gt;% group_by(name) %\u0026gt;% summarise(pct_of_all_candidate_clips = mean(pct_of_all_candidate_clips)*100) %\u0026gt;% top_n(12, wt = pct_of_all_candidate_clips) %\u0026gt;% ggplot(aes(x=reorder(name,pct_of_all_candidate_clips),y=pct_of_all_candidate_clips)) + geom_col(show.legend=FALSE) + coord_flip() + fix_bars() + labs(x=element_blank(), y=\u0026quot;Percent of Media Mentions\u0026quot;, title=\u0026quot;Average Proportion of Media Coverage on a Weekly Basis\u0026quot;) Somewhat unsurprisingly. Joe Biden and Bernie Sanders lead the pack in media attention. Joe Biden tends to receive significantly more media attention than the average candidate (a weekly average of 0.9% of overall media content compared to 0.14% for the average candidate).\nHow has that coverage changed over time?\ndata %\u0026gt;% group_by(name) %\u0026gt;% filter(mean(pct_of_all_candidate_clips) \u0026gt; .06) %\u0026gt;% # filter out unpopular candidates for plot clarity ggplot(aes(x=as.Date(date),y=pct_of_all_candidate_clips*100,group=name, color=name)) + geom_point() + geom_smooth(se = FALSE, show.legend = FALSE) + # geom_text(data = subset(data, as.numeric(date) == 21 \u0026amp; mean(pct_of_all_candidate_clips) \u0026gt; .05), # aes(x = 21, label = name, color = \u0026quot;#000000\u0026quot;), hjust = -.05, # show.legend = FALSE) + geom_label_repel(data=subset(data, pct_of_all_candidate_clips\u0026gt;.6), label = \u0026quot;Lucy Flores accuses Biden of \\n inappropriate touching\u0026quot;, nudge_x = -25, nudge_y=-5, show.legend = FALSE, color=\u0026quot;black\u0026quot;) + geom_label_repel(data=subset(data, pct_of_all_candidate_clips \u0026gt; .58 \u0026amp; pct_of_all_candidate_clips \u0026lt;.6), label = \u0026quot;Joe Biden announces candidacy\u0026quot;, nudge_x = -5, nudge_y=-7, show.legend = FALSE, color=\u0026quot;black\u0026quot;) + # theme(axis.text.x = element_text(angle = 65, hjust = 1)) + # coord_cartesian(clip = \u0026#39;off\u0026#39;) + # # scale_x_discrete(breaks = c(\u0026quot;1/20/19\u0026quot;, \u0026quot;2/10/19\u0026quot;,\u0026quot;3/10/19\u0026quot;,\u0026quot;3/31/19\u0026quot;,\u0026quot;4/28/19\u0026quot;), # # labels = c(\u0026quot;January\u0026quot;, \u0026quot;February\u0026quot;, \u0026quot;March\u0026quot;, \u0026quot;April\u0026quot;, \u0026quot;May\u0026quot;)) + # # theme(plot.margin = margin(5.5, 100, 5.5, 5.5)) + labs(x=element_blank(), y=\u0026quot;Percent of Media Mentions\u0026quot;, title=\u0026quot;Media Mentions of Candidates Over Time\u0026quot;) + scale_color_discrete(name=\u0026quot;Candidate\u0026quot;, limits = c(\u0026quot;Joe Biden\u0026quot;, \u0026quot;Bernie Sanders\u0026quot;, \u0026quot;Elizabeth Warren\u0026quot;, \u0026quot;Kamala Harris\u0026quot;, \u0026quot;Beto O\u0026#39;Rourke\u0026quot;, \u0026quot;Cory Booker\u0026quot;)) Evidently, much of Joe Biden’s popularity in the media can be explained by a few large spikes in weekly media mentions. We can explore the distribution of weekly media mentions using a visualization known as a density ridge plot.\ndata %\u0026gt;% group_by(name) %\u0026gt;% filter(mean(pct_of_all_candidate_clips) \u0026gt; 0.1) %\u0026gt;% ungroup() %\u0026gt;% ggplot(aes(x = pct_of_all_candidate_clips*100, y = reorder(name,pct_of_all_candidate_clips))) + geom_density_ridges(aes(point_colour=name), show.legend = FALSE, alpha = .2, point_alpha = 1, jittered_points = TRUE) + labs(x = \u0026quot;Percent of Media Mentions\u0026quot;, y=element_blank(), title=\u0026quot;Media Mentions of Each Candidate\u0026quot;, subtitle=\u0026quot;With density ridges depicting average mentions on a weekly basis\u0026quot;)  This plot illustrates that most candidates enjoy the same levels of media coverage from one week to another. Joe Biden, however, often has weeks in which he receives much more attention than usual, as evidenced by his small peaks throughout the plot. Bernie Sanders, Kamala Harris, and Beto O’Rourke also experienced a few jumps in attention, likely when they announced their candidacy for the presidency.\nThis raises an interesting question: when did candidates experience the most drastic changes in media attention? For example, were there any weeks in which a candidate who normally enjoys nearly no media attention began to get a lot of it?\nWe can answer this question by calculating the difference between one week’s coverage and the prior week’s coverage (using the lag function).\ndata %\u0026gt;% group_by(name) %\u0026gt;% mutate(change = (pct_of_all_candidate_clips-(dplyr::lag(pct_of_all_candidate_clips, n=1, default=NA)))) %\u0026gt;% filter(change \u0026gt;.2 | change \u0026lt; -.2) %\u0026gt;% ggplot(aes(x=reorder(as.factor(date),change),y=change*100, fill=name)) + geom_col() + scale_fill_discrete(name=\u0026quot;Candidate\u0026quot;) + theme(axis.text.x = element_text(angle = 30, hjust = 1)) + labs(x=element_blank(), y=\u0026quot;Percent Change\u0026quot;, title=\u0026quot;Largest Differences in Weekly Media Mentions\u0026quot;, subtitle=\u0026quot;Subtracting a given week\u0026#39;s % mentions from the week prior\u0026quot;) Unsurprisingly, the bars tend to mirror one another. If a candidate enjoys a steep increase in media attention one week, they are likely to see a correlated drop in the following week (if that week were really a spike in attention). The plot suggests that Joe Biden’s announcement (on April 25th) led to the most dramatic change in media attention in the 2020 cycle so far. Bernie Sanders also witnessed a spike in attention in the week following his announcement on February 19th. The same is true for the other candidates included in this plot.\nFinally, I am interested in who is “winning” the race for media attention. Although a previous plot has shown media attention over time, this data can be somewhat hard to digest and interpret as so many candidates crowd the lower bound of the data (as they receive little media attention compared to Joe Biden).\nBy constructing a bump chart, I am able to depict the rank of each candidate in terms of their media attention in a given week. This type of visualization assigns each candidate a categorical rank and makes their progress throughout the campaign easier to visualize.\nAs an added benefit, this plot was difficult to construct and so it was rewarding to finally finish.\n# create extended color palette for 22 candidates nb.cols \u0026lt;- 22 mycolors \u0026lt;- colorRampPalette(brewer.pal(8, \u0026quot;RdYlBu\u0026quot;))(nb.cols) show.top.n \u0026lt;- 10 # give each candidate a ranking for each week data \u0026lt;- data %\u0026gt;% group_by(date) %\u0026gt;% arrange(date, desc(pct_of_all_candidate_clips), name) %\u0026gt;% mutate(rank = row_number()) %\u0026gt;% ungroup() # filter most recent data so as to make the plot more digestible recentdata \u0026lt;- data %\u0026gt;% mutate(date = as.Date(date, \u0026quot;%m/%d/%y\u0026quot;)) %\u0026gt;% filter(date \u0026gt; \u0026quot;2019-03-01\u0026quot;) # for axis labels, create ranking at the start and end of the analysis finranking \u0026lt;- recentdata %\u0026gt;% filter(date==\u0026quot;2019-05-19\u0026quot;) %\u0026gt;% select(date,name,rank) startranking \u0026lt;- recentdata %\u0026gt;% filter(date==\u0026quot;2019-03-03\u0026quot;) %\u0026gt;% select(date,name,rank) # and plot! recentdata %\u0026gt;% ggplot(aes(x=date, y=rank, group=name, label=name)) + geom_line(aes(color=name, alpha = 1), size = 2) + geom_point(aes(color = name, alpha = 1), size = 4) + geom_point(color = \u0026quot;#FFFFFF\u0026quot;, size = 1) + scale_fill_manual(values = mycolors) + scale_y_reverse(breaks = 1:show.top.n) + scale_x_date(expand = c(0,29)) + coord_cartesian(ylim = c(1,show.top.n)) + geom_text(data = subset(startranking), size=3, aes(x = date, hjust = 1.2)) + geom_text(data = subset(finranking), size=3, aes(x = date, hjust = -.2)) + # scale_color_brewer(palette = \u0026quot;Paired\u0026quot;) + theme(line = element_blank(), rect = element_blank(), axis.text = element_blank(), axis.title = element_blank(), axis.ticks.length = unit(0, \u0026quot;pt\u0026quot;), axis.ticks.length.x = NULL, axis.ticks.length.x.top = NULL, axis.ticks.length.x.bottom = NULL, axis.ticks.length.y = NULL, axis.ticks.length.y.left = NULL, axis.ticks.length.y.right = NULL, legend.box = NULL, legend.position = \u0026quot;none\u0026quot;) + labs(x = element_blank(), y = \u0026quot;Rank\u0026quot;, title = \u0026quot;The Race for Media Attention\u0026quot;, subtitle = \u0026quot;Candidates ranked by weekly media mentions\u0026quot;) Let’s focus on the meteoric rise of Pete Buttigieg:\npetedata \u0026lt;- recentdata %\u0026gt;% mutate(pete = ifelse(name == \u0026quot;Pete Buttigieg\u0026quot;, 1, 0)) petedata %\u0026gt;% ggplot(aes(x=date, y=rank, group=name, label=name)) + # pete\u0026#39;s line geom_line(aes(color = \u0026quot;#1089FF\u0026quot;), data = subset (petedata, pete == 1), size = 2, show.legend = FALSE) + # everyone else\u0026#39;s line geom_line(aes(alpha = 1), data = subset(petedata, pete != 1), size = .5, show.legend = FALSE) + geom_point(aes(fill = \u0026quot;grey80\u0026quot;, alpha = 1), data = subset(petedata, pete == 1), size = 4) + geom_point(aes(alpha = 1), data = subset(petedata, pete != 1), size = 2) + geom_point(color = \u0026quot;#FFFFFF\u0026quot;, size = 1) + # scale_fill_manual(values = mycolors) + scale_y_reverse(breaks = 1:show.top.n) + scale_x_date(expand = c(0,29)) + coord_cartesian(ylim = c(show.top.n, 1)) + geom_text(data = subset(startranking), size=3, aes(x = date, hjust = 1.2)) + geom_text(data = subset(finranking), size=3, aes(x = date, hjust = -.2)) + # scale_fill_brewer(palette = \u0026quot;Dark2\u0026quot;) + theme(line = element_blank(), rect = element_blank(), axis.text = element_blank(), axis.title = element_blank(), axis.ticks.length = unit(0, \u0026quot;pt\u0026quot;), axis.ticks.length.x = NULL, axis.ticks.length.x.top = NULL, axis.ticks.length.x.bottom = NULL, axis.ticks.length.y = NULL, axis.ticks.length.y.left = NULL, axis.ticks.length.y.right = NULL, legend.box = NULL, legend.position = \u0026quot;none\u0026quot;) + labs(x = element_blank(), y = \u0026quot;Rank\u0026quot;, title = \u0026quot;Out of Nowhere\u0026quot;, subtitle = \u0026quot;Pete Buttigieg\u0026#39;s Rapid Rise in Media Mentions\u0026quot;) Some takeaways:\nBernie Sanders and Joe Biden consistently receive the most attention from the media. The most stark increase in media mentions can be seen in the rise of Pete Buttigieg, who began not even in the top 10 but now receives the third most media mentions of any candidate. Cory Booker and John Hickenlooper have all but disappeared from the media, while most other candidates remain in a place similar to where they began.   Next Steps Future work could capitalize upon this analysis by looking at the content of media coverage of candidates. In similar work, I have performed preliminary sentiment analysis on the Tweets of presidential candidates. Other researchers have shown that media coverage of female presidential candidates tends to be more negative than coverage of male candidates. Continuing this work with a larger dataset could reveal interesting insights about the relationship between media, politics, and sexism.\n ","date":1559174400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"fa5528595dc8ab84f2602c845be60f15","permalink":"/post/media-mentions/","publishdate":"2019-05-30T00:00:00Z","relpermalink":"/post/media-mentions/","section":"post","summary":"How has the media's coverage of 2020 presidential candidates changed over time? Who is winning the race for media attention?","tags":["r","visualization","animation","gganimate"],"title":"The Race for Media Attention","type":"post"},{"authors":["Connor Rothschild"],"categories":["R"],"content":" The goal of this project is to explore trends in STEM enrollment for different populations. Specifically, it asks: Are traditionally underrepresented groups more likely to migrate into or out of STEM majors? What discrepancies are present between different demographic groups?\nlibrary(readxl) library(tidyverse) library(tidyr) library(knitr) library(cr) conflicted::conflict_prefer(\u0026quot;filter\u0026quot;, \u0026quot;dplyr\u0026quot;) set_cr_theme(font = \u0026quot;lato\u0026quot;) The Data The dataset for this project comes from data.world and contains the enrollment numbers for undergraduates nationwide.\nundergradenrollment \u0026lt;- read_excel(\u0026quot;data/undergradenrollment.xlsx\u0026quot;) I modified that data in Excel to make it more suitable for this project. The head of that data:\nhead(undergradenrollment) %\u0026gt;% kable()   year undergrads female male white asian black hispanic nativeamerican pacificislander multiracial foreignnational firstyearundergrads firstyearfemale firstyearmale firstyearwhite firstyearasian firstyearblack firstyearhispanic firstyearnativeamerican firstyearpacificislander firstyearmultiracial firstyearforeignnational    Class of 2006 405489 69869 335620 277921 43902 23414 36389 2598 NA NA 21265 100228 17047 86787 72471 10421 7619 8403 642 NA NA 4278  Class of 2007 431910 74258 357652 295358 47059 24074 39448 2523 NA NA 23448 110558 16896 86465 72547 10145 7374 8268 696 NA NA 4331  Class of 2008 442952 77671 365281 301483 47738 24771 41919 2629 NA NA 24412 111006 16238 84173 70732 9281 7212 8338 623 NA NA 4225  Class of 2009 468139 83988 384151 315240 50293 25189 47219 2850 NA NA 27348 114704 16751 83477 69369 9796 7112 8773 715 NA NA 4463  Class of 2010 488435 88063 400372 321558 51057 25996 50051 2665 737 5961 30410 119144 18617 91941 76071 11200 7224 9452 729 NA NA 5882  Class of 2011 511306 93633 417673 329348 54403 26989 54245 2554 1093 8819 33855 121766 19342 91664 75508 11106 7338 10282 765 NA NA 6007    The following command collapses the “undergradenrollment” file into a few summary statistics:\nThe proportion of a class that is of a certain demographic (female, Black, Hispanic) The change in that proportion between that class’s first year (matriculation) and their final year (graduation)  It then uses the gather function to make that data easier to analyze.\ndata \u0026lt;- undergradenrollment %\u0026gt;% mutate(propfemale = female/undergrads*100, firstyearpropfemale = firstyearfemale/firstyearundergrads*100) %\u0026gt;% mutate(femalegrowth = propfemale-firstyearpropfemale) %\u0026gt;% mutate(prophispanic = hispanic/undergrads*100, firstyearprophispanic = firstyearhispanic/firstyearundergrads*100) %\u0026gt;% mutate(hispanicgrowth = prophispanic-firstyearprophispanic) %\u0026gt;% mutate(propblack = black/undergrads*100, firstyearpropblack = firstyearblack/firstyearundergrads*100) %\u0026gt;% mutate(blackgrowth = propblack-firstyearpropblack) %\u0026gt;% select(year,femalegrowth,blackgrowth,hispanicgrowth,propfemale,prophispanic,propblack) %\u0026gt;% gather(\u0026quot;type\u0026quot;, \u0026quot;growth\u0026quot;, 2:4) %\u0026gt;% gather(\u0026quot;proportiontype\u0026quot;,\u0026quot;proportion\u0026quot;,2:4) The structure of that new dataset:\nhead(data) %\u0026gt;% kable()   year type growth proportiontype proportion    Class of 2006 femalegrowth 0.2225791 propfemale 17.23080  Class of 2007 femalegrowth 1.9104575 propfemale 17.19293  Class of 2008 femalegrowth 2.9068189 propfemale 17.53486  Class of 2009 femalegrowth 3.3371497 propfemale 17.94083  Class of 2010 femalegrowth 2.4039957 propfemale 18.02963  Class of 2011 femalegrowth 2.4279519 propfemale 18.31252    summary(data) %\u0026gt;% kable()    year type growth proportiontype proportion     Length:72 Length:72 Min. :-1.8274 Length:72 Min. : 5.014   Class :character Class :character 1st Qu.:-0.7427 Class :character 1st Qu.: 5.588   Mode :character Mode :character Median : 1.7827 Mode :character Median :10.167   NA NA Mean : 1.0458 NA Mean :11.150   NA NA 3rd Qu.: 2.3560 NA 3rd Qu.:17.307   NA NA Max. : 3.3371 NA Max. :19.205     Plots and Analysis I am first curious how enrollment has changed for each group in my analysis. The following plots enrollment for different underrepresented groups as a proportion of overall enrollment in STEM majors at the undergraduate level.\nggplot(data=data, mapping = aes(x=year,y=proportion, colour=proportiontype, group=proportiontype)) + geom_point() + geom_line() + ggtitle(\u0026quot;Demographic Proportion of Overall Enrollment in STEM Majors\u0026quot;, subtitle=\u0026quot;Over time\u0026quot;) + xlab(\u0026quot;Class\u0026quot;) + ylab(\u0026quot;Percent of Overall Class\u0026quot;) + theme_minimal() + scale_color_discrete(name=\u0026quot;Demographic\u0026quot;, breaks=c(\u0026quot;propblack\u0026quot;,\u0026quot;propfemale\u0026quot;,\u0026quot;prophispanic\u0026quot;), label=c(\u0026quot;Black\u0026quot;,\u0026quot;Female\u0026quot;,\u0026quot;Hispanic\u0026quot;)) + theme(axis.text.x = element_text(angle = 90)) Of the traditionally underrepresented groups, women fare the best in STEM. But even at their peak, they only held 19% of seats in STEM classrooms.\nNext, I am curious how these shifts vary from one graduation class to another. In other words, which classes experience the greatest shifts in representation throughout their time in university?\nI explore this by mutating the data to include a new variable: growth. This variable (which may be more accurately be named “change”) examines the difference between the underrepresented proportion of STEM enrollment at the time of graduation and the time of matriculation. If women were 19% of their class’s STEM majors at time of matriculation in 2015 and 17% of their class’s STEM majors at time of graduation, growth would be 2% (19%-17%).\nWe can explore these changes by graduation year:\ndata %\u0026gt;% distinct(year,type,.keep_all=TRUE) %\u0026gt;% ggplot(aes(fill=type, y=growth, x=year)) + geom_bar(position=\u0026quot;dodge\u0026quot;, stat=\u0026quot;identity\u0026quot;) + xlab(\u0026quot;Class\u0026quot;) + ylab(\u0026quot;Percent Change\u0026quot;) + theme_minimal() + ggtitle(\u0026quot;Percent Change in Proportion of Overall STEM Class\u0026quot;, subtitle=\u0026quot;Between time of matriculation and time of graduation\u0026quot;) + scale_fill_discrete(name=\u0026quot;Demographic\u0026quot;, label=c(\u0026quot;Black\u0026quot;,\u0026quot;Female\u0026quot;,\u0026quot;Hispanic\u0026quot;)) + theme(axis.text.x = element_text(angle = 90)) It seems as if women experience the greatest growth in STEM enrollment during their time as undergraduates, while Black students tend to migrate out of STEM majors.\nWe can break that down group-by-group.\ndata %\u0026gt;% distinct(year,type,.keep_all=TRUE) %\u0026gt;% filter(type==\u0026quot;blackgrowth\u0026quot;) %\u0026gt;% ggplot(mapping=aes(x=year,y=growth)) + geom_col(aes(fill=growth)) + scale_fill_gradient() + ylab(\u0026quot;Percent Attrition\u0026quot;) + xlab(\u0026quot;Class\u0026quot;) + ggtitle(\u0026quot;Percent Change in Black STEM Undergrads\u0026quot;, subtitle = \u0026quot;Between time of matriculation and time of graduation\u0026quot;) + labs(fill=\u0026quot;Attrition\u0026quot;) + theme_minimal() + theme(axis.text.x = element_text(angle = 90)) data %\u0026gt;% distinct(year,type,.keep_all=TRUE) %\u0026gt;% filter(type==\u0026quot;femalegrowth\u0026quot;) %\u0026gt;% ggplot(mapping=aes(x=year,y=growth)) + geom_col(aes(fill=growth)) + scale_fill_gradient() + ylab(\u0026quot;Percent Growth\u0026quot;) + xlab(\u0026quot;Class\u0026quot;) + ggtitle(\u0026quot;Percent Change in Female STEM Undergrads\u0026quot;, subtitle = \u0026quot;Between time of matriculation and time of graduation\u0026quot;) + labs(fill=\u0026quot;Growth\u0026quot;) + theme(axis.text.x = element_text(angle = 90)) data %\u0026gt;% distinct(year,type,.keep_all=TRUE) %\u0026gt;% filter(type==\u0026quot;hispanicgrowth\u0026quot;) %\u0026gt;% ggplot(mapping=aes(x=year,y=growth)) + geom_col(aes(fill=growth)) + scale_fill_gradient() + ylab(\u0026quot;Percent Growth\u0026quot;) + xlab(\u0026quot;Class\u0026quot;) + ggtitle(\u0026quot;Percent Change in Hispanic STEM Undergrads\u0026quot;, subtitle = \u0026quot;Between time of matriculation and time of graduation\u0026quot;) + labs(fill=\u0026quot;Growth\u0026quot;) + theme(axis.text.x = element_text(angle = 90)) Here are the previous graphs, faceted:\nlabels \u0026lt;- c(blackgrowth = \u0026quot;Black\u0026quot;, femalegrowth = \u0026quot;Female\u0026quot;, hispanicgrowth=\u0026quot;Hispanic\u0026quot;) data %\u0026gt;% distinct(year,type,.keep_all=TRUE) %\u0026gt;% ggplot(mapping=aes(x=year,y=growth)) + geom_col(aes(fill=growth)) + ylab(\u0026quot;Percent Change\u0026quot;) + xlab(\u0026quot;Class\u0026quot;) + ggtitle(\u0026quot;Percent Change in Proportion of STEM Undergrads\u0026quot;, subtitle = \u0026quot;Between time of matriculation and time of graduation\u0026quot;) + labs(fill=\u0026quot;Percent\\nChange\u0026quot;) + facet_grid(. ~ type, labeller=labeller(type = labels)) + scale_x_discrete(labels = c(\u0026quot;Class of 2006\u0026quot; = \u0026quot;2006\u0026quot;, \u0026quot;Class of 2007\u0026quot; = \u0026quot;2007\u0026quot;, \u0026quot;Class of 2008\u0026quot; = \u0026quot;2008\u0026quot;, \u0026quot;Class of 2009\u0026quot; = \u0026quot;2009\u0026quot;, \u0026quot;Class of 2010\u0026quot; = \u0026quot;2010\u0026quot;, \u0026quot;Class of 2011\u0026quot; = \u0026quot;2011\u0026quot;, \u0026quot;Class of 2012\u0026quot; = \u0026quot;2012\u0026quot;, \u0026quot;Class of 2013\u0026quot; = \u0026quot;2013\u0026quot;)) + theme(axis.text.x = element_text(angle = 90))  Summaries and Takeaways The decision to migrate into or out of STEM majors is both an individual choice and one shaped by institutional factors. In the face of demographic discrepancies, universities may or may not make changes to make STEM fields more accessible to underrepresented groups.\nThe data paint a neutral picture of trends in STEM. This analysis may suggest something about individual choices; it may also suggest that universities are not doing enough to make STEM majors accessible to Black students. However, it is promising that women and Hispanic students are able to, and often choose to, migrate into STEM majors.\nThere does not seem to be a temporal dynamic to these decisions. Although some classes (the Class of 2009) were more than others likely to migrate into STEM majors, no trend makes itself apparent year-by-year.\nThis analysis may suggest that more can be done to bring women and racial minorities into STEM, or it may simply present the product of individual decisions on the part of underrepresented groups.\n ","date":1552262400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"e2a91d84bd768c58f42de6c2084abb14","permalink":"/post/stem-igration/","publishdate":"2019-03-11T00:00:00Z","relpermalink":"/post/stem-igration/","section":"post","summary":"Are traditionally underrepresented groups more likely to migrate into or out of STEM majors?","tags":["r","visualization"],"title":"STEMigration: Leaving and Entering STEM Fields During College","type":"post"},{"authors":["Connor Rothschild"],"categories":["R"],"content":" The goal of this project is to understand the relationship between income, education, and automation. It asks the following: Is a given job’s income correlated to its likelihood of automation? Are jobs which are predominantly less educated more or less likely to be automated? How many workers are in the industries that will be automated?\nlibrary(ggplot2) library(ggthemes) library(dplyr) library(ggrepel) library(tools) library(readxl) library(tidyverse) library(knitr) library(cr) conflicted::conflict_prefer(\u0026quot;filter\u0026quot;, \u0026quot;dplyr\u0026quot;) options(scipen=999) set_cr_theme(font = \u0026quot;lato\u0026quot;) Load datasets: There are three datasets for this project.\nEducational attainment broke down by occupation, provided by BLS here\n Salaries, median hourly/annual wages broke down by occupation, provided by BLS here\n Risk of automation broken down by occupation, provided by Carl Benedikt Frey and Michael A. Osborne (but compiled here)\n  education \u0026lt;- read_excel(\u0026quot;data/education.xlsx\u0026quot;, skip=1) salary \u0026lt;- read_excel(\u0026quot;data/national_M2017_dl.xlsx\u0026quot;) automation \u0026lt;- read_excel(\u0026quot;data/raw_state_automation_data.xlsx\u0026quot;)  Analysis I’ll begin by finding which occupations contribute most to the American economy (in USD).\nsalary1 \u0026lt;- salary %\u0026gt;% group_by(OCC_TITLE) %\u0026gt;% mutate(natlwage = TOT_EMP * as.numeric(A_MEAN)) %\u0026gt;% filter(!is.na(TOT_EMP)) %\u0026gt;% filter(!is.na(A_MEAN)) %\u0026gt;% filter(!is.na(A_MEDIAN)) salary1$A_MEDIAN = as.numeric(as.character(salary1$A_MEDIAN)) salary2 \u0026lt;- select(salary1, OCC_TITLE, TOT_EMP, A_MEDIAN, natlwage) %\u0026gt;% distinct() options(scipen=999) salary2 %\u0026gt;% arrange(desc(natlwage)) %\u0026gt;% head() %\u0026gt;% kable()   OCC_TITLE TOT_EMP A_MEDIAN natlwage    All Occupations 142549250 37690 7215843035000  Management Occupations 7280330 102590 872984370300  Office and Administrative Support Occupations 21965480 34740 833589966000  Healthcare Practitioners and Technical Occupations 8506740 64770 687004322400  Sales and Related Occupations 14522580 27020 590778554400  Business and Financial Operations Occupations 7472750 67710 570395007500    Management occupations contribute the most, followed by office and administrative support, healthcare practictioners and technical occupations.\nThis is a quick vizualization which represents the relationship between a job’s median wage and the number of Americans which have that job.\nsalary2 %\u0026gt;% filter(TOT_EMP \u0026lt; 15000000) %\u0026gt;% ggplot(mapping=aes(x=TOT_EMP, y=A_MEDIAN)) + geom_point(alpha=1/3, col=\u0026quot;red\u0026quot;) + theme_bw() + ggtitle(\u0026quot;Median Wage vs Total Employment\u0026quot;) + xlab(\u0026quot;Number of Americans in a Given Job\u0026quot;) + ylab(\u0026quot;Median Wage of a Given Job\u0026quot;)  We now have three data points:\nThe name of an occupation\n The annual median wage of that occupation\n The amount it contributes to the American economy (or, more specifically, the amount workers are paid as an entire occupation for their work, annually)\n  Next, I want to cross-reference the salary data with the education data.\neducation1 \u0026lt;- education %\u0026gt;% select(-...2) education1 \u0026lt;- plyr::rename(education1, c(\u0026quot;2016 National Employment Matrix title and code\u0026quot; = \u0026quot;occupation\u0026quot;, \u0026quot;Less than high school diploma\u0026quot; = \u0026quot;lessthanhs\u0026quot;, \u0026quot;High school diploma or equivalent\u0026quot; = \u0026quot;hsdiploma\u0026quot;, \u0026quot;Some college, no degree\u0026quot; = \u0026quot;somecollege\u0026quot;, \u0026quot;Associate\u0026#39;s degree\u0026quot; = \u0026quot;associates\u0026quot;, \u0026quot;Bachelor\u0026#39;s degree\u0026quot; = \u0026quot;bachelors\u0026quot;, \u0026quot;Master\u0026#39;s degree\u0026quot; = \u0026quot;masters\u0026quot;, \u0026quot;Doctoral or professional degree\u0026quot; = \u0026quot;professional\u0026quot;)) education2 \u0026lt;- education1 %\u0026gt;% group_by(occupation) %\u0026gt;% mutate(hsorless = lessthanhs + hsdiploma, somecollegeorassociates = somecollege + associates, postgrad = masters + professional) education2 \u0026lt;- education2 %\u0026gt;% drop_na() Next, I want to join education2 and salary2 to start analysis of education’s effect on salary.\nsalary2 \u0026lt;- plyr::rename(salary2, c(\u0026quot;OCC_TITLE\u0026quot; = \u0026quot;occupation\u0026quot;)) salary2$occupation \u0026lt;- tolower(salary2$occupation) education2$occupation \u0026lt;- tolower(education2$occupation) edsal \u0026lt;- merge(as.data.frame(education2), as.data.frame(salary2), by=\u0026quot;occupation\u0026quot;) %\u0026gt;% drop_na() head(edsal) %\u0026gt;% kable()    occupation lessthanhs hsdiploma somecollege associates bachelors masters professional hsorless somecollegeorassociates postgrad TOT_EMP A_MEDIAN natlwage    1 accountants and auditors 0.0 4.0 7.6 9.2 55.6 20.8 2.8 4.0 16.8 23.6 1241000 69350 96698720000  3 actuaries 0.0 0.0 1.2 1.5 62.1 24.9 10.3 0.0 2.7 35.2 19210 101560 2206268500  4 adhesive bonding machine operators and tenders 21.6 49.2 21.5 2.2 4.9 0.5 0.0 70.8 23.7 0.5 15860 32710 549231800  5 administrative law judges, adjudicators, and hearing officers 0.2 0.4 0.6 0.5 5.0 4.4 88.9 0.6 1.1 93.3 14480 94790 1423094400  6 administrative services managers 2.1 17.9 26.1 12.1 29.7 10.3 1.7 20.0 38.2 12.0 270100 94020 27922938000  7 adult basic and secondary education and literacy teachers and instructors 1.8 10.2 18.4 8.5 35.9 20.5 4.7 12.0 26.9 25.2 60670 52100 3446056000    At this point I’m realizing that having the educational breakdown (# of Bachelor’s degrees, PhD’s, etc.) per job is interesting but may not be able to reveal a lot of key insights.\nSo, I’m going to introduce a fourth dataset: the typical education of a worker in a given occupation, also provided by BLS and found here.\ntypicaleducation \u0026lt;- read_excel(\u0026quot;data/typicaleducation.xlsx\u0026quot;) typicaleducation2 \u0026lt;- typicaleducation %\u0026gt;% select(occupation,typicaled,workexp) typicaleducation2 \u0026lt;- typicaleducation2 %\u0026gt;% drop_na() typicaleducation2$occupation \u0026lt;- tolower(typicaleducation2$occupation) edsal2 \u0026lt;- merge(as.data.frame(edsal), as.data.frame(typicaleducation2), by=\u0026quot;occupation\u0026quot;) head(edsal2) %\u0026gt;% kable()   occupation lessthanhs hsdiploma somecollege associates bachelors masters professional hsorless somecollegeorassociates postgrad TOT_EMP A_MEDIAN natlwage typicaled workexp    accountants and auditors 0.0 4.0 7.6 9.2 55.6 20.8 2.8 4.0 16.8 23.6 1241000 69350 96698720000 Bachelor’s degree None  actuaries 0.0 0.0 1.2 1.5 62.1 24.9 10.3 0.0 2.7 35.2 19210 101560 2206268500 Bachelor’s degree None  adhesive bonding machine operators and tenders 21.6 49.2 21.5 2.2 4.9 0.5 0.0 70.8 23.7 0.5 15860 32710 549231800 High school diploma or equivalent None  administrative law judges, adjudicators, and hearing officers 0.2 0.4 0.6 0.5 5.0 4.4 88.9 0.6 1.1 93.3 14480 94790 1423094400 Doctoral or professional degree 5 years or more  administrative services managers 2.1 17.9 26.1 12.1 29.7 10.3 1.7 20.0 38.2 12.0 270100 94020 27922938000 Bachelor’s degree Less than 5 years  adult basic and secondary education and literacy teachers and instructors 1.8 10.2 18.4 8.5 35.9 20.5 4.7 12.0 26.9 25.2 60670 52100 3446056000 Bachelor’s degree None    This data allows us to ask: What is the median wage for each typical level of education?\nedsal3 \u0026lt;- edsal2 %\u0026gt;% group_by(typicaled) %\u0026gt;% summarise(medianwage = mean(A_MEDIAN)) legend_ord \u0026lt;- levels(with(edsal3, reorder(typicaled, medianwage))) ggplot(data=edsal3, aes(x = reorder(typicaled, medianwage), y = medianwage)) + geom_col(aes(fill=typicaled)) + ggtitle(\u0026quot;Median Annual Income by Education Level\u0026quot;) + xlab(\u0026quot;Education Level\u0026quot;)+ ylab(\u0026quot;Median Annual Income\u0026quot;) + labs(fill=\u0026quot;Education Level\u0026quot;) + scale_fill_discrete(breaks=legend_ord) + theme_minimal() + theme(axis.text.x=element_blank()) The results are unsurpising: more educated people on average earn more.\nLastly, I bring in the automation data.\nautomationwstates \u0026lt;- automation %\u0026gt;% select(-soc) automation1 \u0026lt;- automationwstates %\u0026gt;% select(occupation,probability,total) head(automation) %\u0026gt;% kable()   soc occupation probability alabama alaska arizona arkansas california colorado connecticut delaware district_of_columbia florida georgia hawaii idaho illinois indiana iowa kansas kentucky louisiana maine maryland massachusetts michigan minnesota mississippi missouri montana nebraska nevada new_hampshire new_jersey new_mexico new_york north_carolina north_dakota ohio oklahoma oregon pennsylvania rhode_island south_carolina south_dakota tennessee texas utah vermont virginia washington west_virginia wisconsin wyoming total    11-1011 Chief Executives 0.015 1030 760 5750 2710 31150 880 1410 340 2840 14120 6750 1840 1400 17440 4950 2050 4410 3440 1010 920 1800 11020 6260 7490 940 5180 600 690 1410 940 700 70 15410 4310 920 5340 6370 2650 9230 390 3400 560 5460 5890 3650 280 6320 5910 980 3740 160 223270  11-1021 General and Operations Managers 0.160 26930 6490 43300 20680 261780 41540 33280 4080 26610 77340 90520 11070 12250 121040 49210 25900 19620 26190 29920 12360 47850 71880 58040 41480 24110 41440 4490 14420 17480 11030 44800 15550 162870 53770 7010 64710 27400 32350 70430 6640 31780 3730 44400 168610 36200 2760 52380 43760 10200 32350 4840 2188870  2011-11-01 Advertising and Promotions Managers 0.039 50 40 470 110 3760 480 300 0 220 750 820 200 160 3670 290 230 230 270 320 130 460 1290 650 610 150 390 30 80 280 150 630 190 5130 450 70 460 200 0 570 100 270 0 670 1210 380 40 240 640 40 200 0 28080  2021-11-01 Marketing Managers 0.014 530 200 4790 1090 33390 3060 4970 590 1280 7600 7140 540 860 14030 2870 1920 1470 1490 920 810 2980 11790 3870 7800 470 2590 130 1060 1640 1170 11260 350 16500 5650 310 5350 1420 4830 6250 550 1710 60 3400 9570 2320 380 3840 5830 260 2980 30 205900  2022-11-01 Sales Managers 0.013 2510 400 10650 2650 69180 4570 7040 860 1180 13560 15460 2470 2200 24150 5770 3350 3250 3420 3560 980 5230 14860 10090 12590 1460 5480 190 1930 3350 1750 12840 1200 20170 6750 710 11410 3890 6220 8930 850 3540 300 8890 22310 3360 480 5360 7390 600 5730 180 365250  2031-11-01 Public Relations and Fundraising Managers 0.015 400 150 1240 300 7010 960 980 210 4360 1710 1470 360 200 3830 870 960 480 630 310 420 1350 4200 1300 1880 270 1020 140 580 470 470 1900 180 6040 1100 170 1790 720 1470 1640 260 520 0 870 3680 380 210 1250 2100 130 1010 0 63950    Next, I visualize the probability of automation vs total employment:\nautomation1 %\u0026gt;% ggplot(mapping=aes(x=total, y=probability)) + geom_point(alpha=1/3, col=\u0026quot;blue\u0026quot;) + theme_bw() + ggtitle(\u0026quot;Probability of Automation vs Total Employment\u0026quot;) + xlab(\u0026quot;Number of Americans in a Given Job\u0026quot;) + ylab(\u0026quot;Probability of Automation\u0026quot;) + geom_label_repel(data=subset(automation1, total \u0026gt; 4000000), aes(total, probability,label=occupation), label.size=.5, label.r=.05, size=2.5, nudge_y = .05, nudge_x= -10000) There doesn’t seem to be a huge relationship between automation and number of employees, however there is some concentration at each of the poles.\nSome final data cleaning, and the merge of the final dataset:\nautomation1$occupation \u0026lt;- str_replace_all(automation1$occupation, \u0026quot;;\u0026quot;, \u0026quot;,\u0026quot;) automation1$occupation \u0026lt;- tolower(automation$occupation) data \u0026lt;- merge(as.data.frame(edsal2), as.data.frame(automation1), by=\u0026quot;occupation\u0026quot;) We can create an initial visualization of the relationship between automation risk and education level.\nautovsedu \u0026lt;- data %\u0026gt;% group_by(typicaled) %\u0026gt;% summarise(medianwage = mean(A_MEDIAN), averageprobability = mean(probability)) legend_ord2 \u0026lt;- levels(with(autovsedu, reorder(typicaled, -averageprobability))) ggplot(data=autovsedu, aes(x = reorder(typicaled, -averageprobability), y = averageprobability)) + geom_col(aes(fill=typicaled)) + ggtitle(\u0026quot;Likelihood of Job Automation by Education Level\u0026quot;) + xlab(\u0026quot;Education Level\u0026quot;)+ ylab(\u0026quot;Likelihood of Job Automation\u0026quot;) + labs(fill=\u0026quot;Education Level\u0026quot;) + scale_fill_discrete(breaks=legend_ord2) + theme_minimal() + theme(axis.text.x=element_blank()) There is a rather clear correlation between level of education and automation risk: those who are more educated are better protected from automation.\nWe can then visualize this relationship by individual occupation:\nggplot(data=data) + geom_point(mapping=aes(x=A_MEDIAN, y=probability, size=TOT_EMP, alpha=1/10, col=typicaled))+ scale_size(range = c(1, 20)) + ylim(-.01,1) + xlab(\u0026quot;Median Income\u0026quot;) + ylab(\u0026quot;Probability of Automation\u0026quot;) + ggtitle(\u0026quot;Likelihood of Job Automation vs Median Income\u0026quot;) + labs(size=\u0026quot;Total Employment\u0026quot;, col=\u0026quot;Education Level\u0026quot;) + labs(alpha=NULL) + guides(alpha=FALSE) + theme(legend.text = element_text(colour=\u0026quot;black\u0026quot;, size = 10)) + guides(col = guide_legend(override.aes = list(size=5))) + theme_minimal() With labels, a final look:\ndata$occupation \u0026lt;- toTitleCase(data$occupation) ggplot(data=data) + geom_point(mapping=aes(x=A_MEDIAN, y=probability, size=TOT_EMP, alpha=0.05, col=typicaled))+ geom_smooth(aes(x=A_MEDIAN, y=probability), method=\u0026quot;lm\u0026quot;, se=FALSE) + scale_size(range = c(1, 20)) + ylim(-.05,1.05) + xlim(25000,200000) + xlab(\u0026quot;Median Income\u0026quot;) + ylab(\u0026quot;Probability of Automation\u0026quot;) + ggtitle(\u0026quot;Likelihood of Job Automation vs Median Income\u0026quot;) + labs(size=\u0026quot;Total Employment\u0026quot;, col=\u0026quot;Typical Education Level\u0026quot;) + labs(alpha=NULL) + guides(alpha=FALSE) + theme(legend.text = element_text(colour=\u0026quot;black\u0026quot;, size = 10)) + guides(col = guide_legend(override.aes = list(size=5))) + theme_minimal() + geom_label_repel(aes(A_MEDIAN,probability,label=occupation),subset(data, A_MEDIAN \u0026gt; 175000 \u0026amp; probability \u0026lt; .05), label.size=.5, label.r=.05, size=2.5, nudge_y = .05, nudge_x= -10000) + geom_label_repel(aes(A_MEDIAN,probability,label=occupation),subset(data, A_MEDIAN == 21030), label.size=.1, label.r=.01, size=1, nudge_y = 0,nudge_x=0) + geom_label_repel(aes(A_MEDIAN,probability,label=occupation),subset(data, A_MEDIAN == 24540), label.size=.1, label.r=.01, size=1, nudge_y = 0,nudge_x=0) + geom_label_repel(aes(A_MEDIAN,probability,label=occupation),subset(data, A_MEDIAN \u0026gt; 100000 \u0026amp; probability \u0026gt; .90), label.size=.5, label.r=.05, size=2.5, nudge_y = -.05,nudge_x=10000) + annotate(\u0026quot;text\u0026quot;, x = 165000, y = 1.03, label = \u0026quot;Highest salary,\\n highest automation risk\u0026quot;, size=3, fontface=2) + annotate(\u0026quot;text\u0026quot;, x = 165000, y = -0.035, label = \u0026quot;Highest salary,\\n lowest automation risk\u0026quot;, size=3, fontface=2) + annotate(\u0026quot;text\u0026quot;, x = 45000, y = -0.035, label = \u0026quot;Lowest salary,\\n lowest automation risk\u0026quot;, size=3, fontface=2) + annotate(\u0026quot;text\u0026quot;, x = 45000, y = 1.03, label = \u0026quot;Lowest salary,\\n highest automation risk\u0026quot;, size=3, fontface=2) Conclusions Using the dataset I’ve used in this project, researchers Carl Frey and Michael Osborne predicted that 47% of jobs are at risk of automation over the next couple decades.\nThe visuals above suggest that the ills of automation may not be evenly distributed across jobs.\nLess educated workers are more likely to face job loss as a product of automation. Those with high school diplomas or less (green bubbles) find themself concentrated near the top of the y-axis, while those with Bachelor’s degrees or higher on average face a lower risk of automation.\nA job’s salary is also predictive of automation probability. As the median income of a profession increases, the likelihood of automation displacing its workers decreases.\nAutomation’s impact on work necessitates a policy response. The fact that automation will differentially impact different industries reminds us that this public policy will have to be strategic and thoughtful.\n  ","date":1525910400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"72da75ddedd2f084309255f615992d78","permalink":"/post/automation/","publishdate":"2018-05-10T00:00:00Z","relpermalink":"/post/automation/","section":"post","summary":"Automation and its impact on jobs.","tags":["r","visualization"],"title":"Automation and Its Impact on Jobs","type":"post"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"859b421588f574bbe4d8a9b025fe860b","permalink":"/project/automation-d3/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/automation-d3/","section":"project","summary":"A D3 scatterplot depicting the relationship between education, income, and the likelihood of job loss.","tags":["D3","For Fun"],"title":"Automation and Its Impact on Jobs","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"6b603c4ef060d455fe2b218b375c264c","permalink":"/project/bible-babies/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/bible-babies/","section":"project","summary":"Using {gganimate} to explore popular Biblically-inspired baby names over time.","tags":["R","For Fun"],"title":"Bible Babies","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"ec1659cf6e27f630421178bc2f8f0496","permalink":"/project/map-springfield/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/map-springfield/","section":"project","summary":"Recreating popular streetmaps exclusively in R.","tags":["R","For Fun"],"title":"Build Your Own Streetmap in R","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591892765,"objectID":"297f3af42104cda36321cace25b5f843","permalink":"/project/state-police-spending/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/state-police-spending/","section":"project","summary":"An exploration of state police budgets, and what else those budgets could buy.","tags":["D3.js","JavaScript","For Fun"],"title":"How Much Does Your State Spend on the Police?","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"59c43898efb69054755207d00042b93e","permalink":"/project/born-again-kanye/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/born-again-kanye/","section":"project","summary":"How the release of Jesus is King ushered in a new era in Kanye West’s discography.","tags":["D3","For Fun"],"title":"Kanye West's Rebirth: How Being Reborn has Changed Kanye's Music","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"8e5a60edec81c66770dadf58a24a870f","permalink":"/project/map-houston-homicides/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/map-houston-homicides/","section":"project","summary":"An exploration of homicides in Houston. Winner of the Houston track at the 2020 Rice Datathon.","tags":["Mapbox","For Fun"],"title":"Mapping Houston Homicides","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"28990e81924ac76c4b76a86a50662c26","permalink":"/project/map-missing-migrants/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/map-missing-migrants/","section":"project","summary":"Since 2014, over 34,000 migrants have died or went missing on their journeys to a better life. Where?","tags":["Mapbox","For Fun"],"title":"Mapping Missing Migrants","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"213e9cd0858a08def64e9b56dd887f81","permalink":"/project/map-opioids/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/map-opioids/","section":"project","summary":"An interactive, animated D3.js map visualization depicting opioid-involved overdose deaths in the US, from 1999 to 2017","tags":["D3.js","For Fun"],"title":"Mapping Opioid-Involved Overdose Deaths","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"36ecdc629895831aff2069177709ce33","permalink":"/project/police-killings-waffle/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/police-killings-waffle/","section":"project","summary":"Each square represents one person who was killed by police between 2013 and 2018. Explore them for yourself.","tags":["D3","For Fun"],"title":"Police Killings in the United States, 2013-2018.","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"159009cf60007374c866f339a87461d3","permalink":"/project/tt-replication/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/tt-replication/","section":"project","summary":"Using R to recreate publication-quality visuals.","tags":["R","For Fun"],"title":"Replicating Plots in R (Tidy Tuesday)","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"f002e76c2685e02494620d618114e8b4","permalink":"/project/r-scrollytell/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/r-scrollytell/","section":"project","summary":"An interactive scrollytelling visualization, built exclusively in R Shiny.","tags":["R","For Fun"],"title":"Scrollytelling in R: Automation and Its Impact on Jobs","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"2c15494a01aa2616935d7c0c547fee50","permalink":"/project/tx-vaccination-rates/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/tx-vaccination-rates/","section":"project","summary":"An animated 3d map built in R using {rayshader}.","tags":["R","For Fun"],"title":"Texas Vaccination Rates","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1593032970,"objectID":"c2a1c46f6c7693d395304f94a7431516","permalink":"/project/death-rebirth-kanye/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/death-rebirth-kanye/","section":"project","summary":"My final project for DSCI 304, Effective Data Visualization","tags":["R","For Fun"],"title":"The Birth, Death, and Rebirth of Kanye West","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"dff0d3219af6579ed6d0d35147eade90","permalink":"/project/race-for-media-attention/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/race-for-media-attention/","section":"project","summary":"A D3.js bar chart race depicting media mentions of 2020 presidential candidates over time. Built in Observable.","tags":["D3.js","For Fun"],"title":"The Race for Media Attention","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"c50f111c835e93039a9201b37875127f","permalink":"/project/tt-powerlifting/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/tt-powerlifting/","section":"project","summary":"Animated dumbbell plots using {gganimate} depicting sex differences in international powerlifting.","tags":["R","For Fun"],"title":"Tidy Tuesday: Powerlifting","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"9682d59ab4109e2c9b7b9a3d03533e9f","permalink":"/project/tpl-theme/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/tpl-theme/","section":"project","summary":"My first R package, a toolkit to create publication-ready visuals in the style of the Texas Policy Lab.","tags":["R","For Work"],"title":"TPL Themes","type":"project"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1591028008,"objectID":"2a79a4cce92f57da2c5d5ddcc4c57556","permalink":"/project/the-office/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/project/the-office/","section":"project","summary":"Using transcript data to analyze whose winning the Office popularity content.","tags":["D3.js","For Fun"],"title":"Who is the Most Popular Character in The Office?","type":"project"}]